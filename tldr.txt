# Archive a file or folder
7z a {{archived.7z}} {{path/to/file}}

# Encrypt an existing archive (including headers)
7z a {{encrypted.7z}} -p{{password}} -mhe {{archived.7z}}

# Extract an existing 7z file with original directory structure
7z x {{archived.7z}}

# Extract an archive with user-defined output path
7z x {{archived.7z}} -o{{path/to/output}}

# Archive using a specific archive type
7z a -t {{zip|gzip|bzip2|tar|...}} {{archived.7z}} {{path/to/file}}

# List available archive types
7z i

# List the contents of an archive file
7z l {{archived.7z}}

# Archive a file or folder
7za a {{archived.7z}} {{path/to/file}}

# Extract an existing 7z file with original directory structure
7za x {{archived}}

# Archive using a specific archive type
7za a -t{{zip|gzip|bzip2|tar|...}} {{archived}} {{path/to/file}}

# List available archive types
7za i

# List the contents of an archive file
7za l {{archived}}

# Archive a file or folder
7zr a {{archived.7z}} {{path/to/file}}

# Extract an existing 7z file with original directory structure
7zr x {{archived.7z}}

# List the contents of an archive file
7zr l {{archived.7z}}

# Execute 100 HTTP GET requests to given URL
ab -n 100 {{url}}

# Execute 100 HTTP GET requests, processing up to 10 requests concurrently, to given URL
ab -n 100 -c 10 {{url}}

# Find files containing "foo"
ack {{foo}}

# Find files in a specific language
ack --ruby {{each_with_object}}

# Count the total number of matches for the term "foo"
ack -ch {{foo}}

# Show the file names containing "foo" and number of matches in each file
ack -cl {{foo}}

# Check whether the adb server process is running and start it
adb start-server

# Terminate the adb server process
adb kill-server

# Start a remote shell in the target emulator/device instance
adb shell

# Push an Android application to an emulator/device
adb install -r {{path/to/file.apk}}

# Copy a file/folder from the target device
adb pull {{path/to/device_file_or_folder}} {{path/to/local_destination_folder}}

# Copy a file/folder to the target device
adb push {{path/to/local_file_or_folder}} {{path/to/device_destination_folder}}

# Get a list of connected devices
adb devices

# Find files containing "foo", and print the line matches in context
ag {{foo}}

# Find files containing "foo" in a specific directory
ag {{foo}} {{path/to/folder}}

# Find files containing "foo", but only list the filenames
ag -l {{foo}}

# Find files containing "FOO" case-insensitively, and print only the match, rather than the whole line
ag -i -o {{FOO}}

# Find "foo" in files with a name matching "bar"
ag {{foo}} -G {{bar}}

# Find files whose contents match a regular expression
ag '{{^ba(r|z)$}}'

# Find files with a name matching "foo"
ag -g {{foo}}

# Wait for message and display when received
airpaste

# Send text
echo {{text}} | airpaste

# Send file
airpaste < {{path/to/file}}

# Receive file
airpaste > {{path/to/file}}

# Create/Join channel
airpaste {{channel_name}}

# Create a generic alias
alias {{word}}="{{command}}"

# View the command associated to a given alias
alias {{word}}

# Remove an aliased command
unalias {{word}}

# List all aliased words
alias -p

# Turn rm into an interactive command
alias {{rm}}="{{rm -i}}"

# Create `la` as a shortcut for `ls -a`
alias {{la}}="{{ls -a}}"

# Install a role
ansible-galaxy install {{username.role_name}}

# Remove a role
ansible-galaxy remove {{username.role_name}}

# List installed roles
ansible-galaxy list

# Search for a given role
ansible-galaxy search {{role_name}}

# Create a new role
ansible-galaxy init {{role_name}}

# Run tasks in playbook
ansible-playbook {{playbook}}

# Run tasks in playbook with custom host inventory
ansible-playbook {{playbook}} -i {{inventory_file}}

# Run tasks in playbook with extra variables defined via the command line
ansible-playbook {{playbook}} -e "{{variable1}}={{value1}} {{variable2}}={{value2}}"

# Run tasks in playbook with extra variables defined in a json file
ansible-playbook {{playbook}} -e "@{{variables.json}}"

# List hosts belonging to a group
ansible {{group}} --list-hosts

# Ping a group of hosts by invoking the ping module
ansible {{group}} -m ping

# Display facts about a group of hosts by invoking the setup module
ansible {{group}} -m setup

# Execute a command on a group of hosts by invoking command module with arguments
ansible {{group}} -m command -a '{{my_command}}'

# Execute a command with administrative privileges
ansible {{group}} --become --ask-become-pass -m command -a '{{my_command}}'

# Execute a command using a custom inventory file
ansible {{group}} -i {{inventory_file}} -m command -a '{{my_command}}'

# Create random passwords (default password length is 8)
apg

# Create a password with at least 1 symbol (S), 1 number (N), 1 uppercase (C), 1 lowercase (L)
apg -M SNCL

# Create a password with 16 characters
apg -m {{16}}

# Create a password with maximum length of 16
apg -x {{16}}

# Create a password that doesn't appear in a dictionary (the dictionary file has to be provided)
apg -r {{dictionary_file}}

# Install packages from http://atom.io/packages and themes from http://atom.io/themes
apm install {{package_name}}

# Remove packages/themes
apm remove {{package_name}}

# Upgrade packages/themes
apm upgrade {{package_name}}

# Search for keyword
apropos {{regular_expression}}

# Search without restricting output to terminal width
apropos -l {{regular_expression}}

# Extract all members from an archive
ar -x {{libfoo.a}}

# List the members of an archive
ar -t {{libfoo.a}}

# Replace or add files to an archive
ar -r {{libfoo.a}} {{foo.o}} {{bar.o}} {{baz.o}}

# Insert an object file index (equivalent to using `ranlib`)
ar -s {{libfoo.a}}

# Create an archive with files and an accompanying object file index
ar -rs {{libfoo.a}} {{foo.o}} {{bar.o}} {{baz.o}}

# Download a URI to a file
aria2c {{url}}

# Download from multiple sources
aria2c {{url_1}} {{url_2}}

# Download the URIs listed in a file
aria2c -i {{filename}}

# Download with multiple connections
aria2c -s {{connections_num}} {{url}}

# FTP download with username and password
aria2c --ftp-user={{username}} --ftp-passwd={{password}} {{url}}

# Limit download speed in bytes/s
aria2c --max-download-limit={{speed}} {{url}}

# Show current arp table
arp -a

# Clear the entire cache
sudo arp -a -d

# Delete a specific entry
arp -d {{address}}

# Create an entry
arp -s {{address}} {{mac_address}}

# Archive a file or folder
asar pack {{path/to/file}} {{archived.asar}}

# Extract an archive
asar extract {{archived.asar}}

# Extract a specific file from an archive
asar extract-file {{archived.asar}} {{file}}

# List the contents of an archive file
asar list {{archived.asar}}

# List all supported import formats
assimp listext

# List all supported export formats
assimp listexport

# Convert a file to one of the supported output formats, using the default parameters
assimp export {{input_file.stl}} {{output_file.obj}}

# Convert a file using custom parameters (the dox_cmd.h file in assimp's source code lists available parameters)
assimp export {{input_file.stl}} {{output_file.obj}} {{parameters}}

# Display a summary of a 3D file's contents
assimp info {{path/to/file}}

# List all supported subcommands ("verbs")
assimp help

# Get help on a specific subcommand (e.g. the parameters specific to it)
assimp {{subcommand}} --help

# Apply the default style of 4 spaces per indent and no formatting changes
astyle {{source_file}}

# Apply the java style with attached braces
astyle --style=java {{path/to/file}}

# Apply the allman style with broken braces
astyle --style=allman {{path/to/file}}

# Apply a custom indent using spaces. Choose between 2 and 20 spaces
astyle --indent=spaces={{number_of_spaces}} {{path/to/file}}

# Apply a custom indent using tabs. Choose between 2 and 20 tabs
astyle --indent=tab={{number_of_tabs}} {{path/to/file}}

# Execute commands from standard input in 5 minutes (press `Ctrl + D` after entering commands)
at now + 5 minutes

# Execute a command from standard input at 10:00 AM today
echo "{{./make_db_backup.sh}}" | at 1000

# Execute commands from a given file next Tuesday
at -f {{path/to/file}} 9:30 PM Tue

# Open a file or folder
atom {{path/to/file_or_folder}}

# Open a file or folder in a new window
atom -n {{path/to/file_or_folder}}

# Open a file or folder in an existing window
atom --add {{path/to/file_or_folder}}

# Open atom in safe mode (does not load any additional packages)
atom --safe

# Prevent atom from forking into the background, keeping atom attached to the terminal
atom --foreground

# Show the current user's scheduled jobs
atq

# Show jobs from queue named 'a' (queues have single-character names)
atq -q {{a}}

# Show jobs of all users (run as super user)
sudo atq

# Remove job number 10
atrm {{10}}

# Remove many jobs, separated by spaces
atrm {{15}} {{17}} {{22}}

# Remove unused variables from a single file and display the diff
autoflake --remove-unused-variables {{file.py}}

# Remove unused imports from multiple files and display the diffs
autoflake --remove-all-unused-imports {{file1.py}} {{file2.py}} {{file3.py}}

# Remove unused variables from a file, overwriting the file
autoflake --remove-unused-variables --in-place {{file.py}}

# Remove unused variables recursively from all files in a directory, overwriting each file
autoflake --remove-unused-variables --in-place --recursive {{path/to/directory}}

# Jump to a directory that contains the given pattern
j {{pattern}}

# Jump to a sub-directory (child) of the current directory that contains the given pattern
jc {{pattern}}

# Open a directory that contains the given pattern in the operating system file manager
jo {{pattern}}

# Remove non-existing directories from the autojump database
j --purge

# Show the entries in the autojump database
j -s

# Open an SSH session, restarting when a monitoring port fails return data
autossh -M {{monitor_port}} {{ssh_command}}

# Open an SSH session which forwards a local port to a remote one, restarting if necessary
autossh -M {{monitor_port}} -L {{local_port}}:localhost:{{remote_port}} {{user}}@{{host}}

# Fork before executing ssh (runs in the background) and don't open a remote shell
autossh -f -M {{monitor_port}} -N {{ssh_command}}

# Run autossh in the background, with no monitoring port, instead relying on SSH keep-alives every 10 seconds to detect failure
autossh -f -M 0 -N -o "ServerAliveInterval 10" -o "ServerAliveCountMax 3"  {{ssh_command}}

# Run autossh in the background, with no monitoring port, no remote shell, exiting if the port forward fails
autossh -f -M 0 -N -o "ServerAliveInterval 10" -o "ServerAliveCountMax 3" -o ExitOnForwardFailure=yes -L {{local_port}}:localhost:{{remote_port}} {{user}}@{{host}}

# Run autossh in the background with debug output logged to a file and ssh verbose output logged to a second file
AUTOSSH_DEBUG=1 AUTOSSH_LOGFILE={{log_file}} autossh -f -M {{monitor_port}} -v -E {{ssh_log_file}} {{ssh_command}}

# Read AVR microcontroller
avrdude -p {{AVR_device}} -c {{programmer}} -U flash:r:{{file.hex}}:i

# Write AVR microcontroller
avrdude -p {{AVR_device}} -c {{programmer}} -U flash:w:{{file.hex}}

# List available AVR devices
avrdude -p \?

# List available AVR programmers
avrdude -c \?

# Print the fifth column (a.k.a. field) in a space-separated file
awk '{print $5}' {{filename}}

# Print the second column of the lines containing "something" in a space-separated file
awk '/{{something}}/ {print $2}' {{filename}}

# Print the last column of each line in a file, using a comma (instead of space) as a field separator
awk -F ',' '{print $NF}' {{filename}}

# Sum the values in the first column of a file and print the total
awk '{s+=$1} END {print s}' {{filename}}

# Sum the values in the first column and pretty-print the values and then the total
awk '{s+=$1; print $1} END {print "--------"; print s}' {{filename}}

# Print every third line starting from the first line
awk 'NR%3==1' {{filename}}

# Show files in a bucket
aws s3 ls {{bucket_name}}

# Sync files and folders from local to bucket
aws s3 sync {{path/to/files}} s3://{{bucket_name}}

# Sync files and folders from bucket to local
aws s3 sync s3://{{bucket_name}} {{path/to/target}}

# Sync files and folders with exclusions
aws s3 sync {{path/to/files}} s3://{{bucket_name}} --exclude {{path/to/file}} --exclude {{path/to/folder}}/*

# Remove file from bucket
aws s3 rm s3://{{bucket}}/{{path/to/file}}

# Preview changes only
aws s3 {{any_command}} --dryrun

# Download a URL to a file
axel {{url}}

# Download and specify filename
axel {{url}} -o {{filename}}

# Download with multiple connections
axel -n {{connections_num}} {{url}}

# Search for mirrors
axel -S {{mirrors_num}} {{url}}

# Limit download speed (bytes per second)
axel -s {{speed}} {{url}}

# Calculate the BLAKE2 checksum for a file
b2sum {{filename1}}

# Calculate BLAKE2 checksums for multiple files
b2sum {{filename1}} {{filename2}}

# Read a file of BLAKE2 sums and filenames and verify all files have matching checksums
b2sum -c {{filename.b2}}

# Calculate the BLAKE2 checksum from stdin
{{somecommand}} | shasum

# Transpile a specified input file and output to stdout
babel {{path/to/file}}

# Transpile a specified input file and output to a specific file
babel {{path/to/input_file}} --out-file {{path/to/output_file}}

# Transpile the input file every time it is changed
babel {{path/to/input_file}} --watch

# Transpile a whole directory of files
babel {{path/to/input_directory}}

# Ignore specified comma-separated files in a directory
babel {{path/to/input_directory}} --ignore {{ignored_files}}

# Transpile and output as minified JavaScript
babel {{path/to/input_file}} --minified

# Choose a set of presets for output formatting
babel {{path/to/input_file}} --presets {{presets}}

# Output all available options
babel --help

# Search a disk for bad blocks by using a non-destructive read-only test
sudo badblocks {{/dev/sda}}

# Search an unmounted disk for bad blocks with a non-destructive read-write test
sudo badblocks -n {{/dev/sda}}

# Search an unmounted disk for bad blocks with a destructive write test
sudo badblocks -w {{/dev/sda}}

# Print the text message as a large banner (quotes are optional)
banner {{"Hello World"}}

# Print the text message as a banner with a width of 50 characters
banner -w {{50}} {{"Hello World"}}

# Read text from stdin
banner

# Encode a file
base32 {{filename}}

# Decode a file
base32 -d {{filename}}

# Encode from stdin
{{somecommand}} | base32

# Decode from stdin
{{somecommand}} | base32 -d

# Encode a file
base64 {{filename}}

# Decode a file
base64 -d {{filename}}

# Encode from stdin
{{somecommand}} | base64

# Decode from stdin
{{somecommand}} | base64 -d

# Show only the file name from a path
basename {{path/to/file}}

# Show only the file name from a path, with a suffix removed
basename {{path/to/file}} {{suffix}}

# Start interactive shell
bash

# Execute a command
bash -c "{{command}}"

# Run commands from a file
bash {{file.sh}}

# Run commands from a file, logging all commands executed to the terminal
bash -x {{file.sh}}

# Run commands from STDIN
bash -s

# Print the version information of bash (use `echo $BASH_VERSION` to show just the version string)
bash --version

# Print the contents of a file to the standard output
bat {{file}}

# Concatenate several files into the target file
bat {{file1}} {{file2}} > {{target_file}}

# Append several files into the target file
bat {{file1}} {{file2}} >> {{target_file}}

# Number all output lines
bat -n {{file}}

# Syntax highlight a json file
bat --language json {{file.json}}

# Display all supported languages
bat --list-languages

# Execute a command from standard input
echo "{{./make_db_backup.sh}}" | batch

# Execute commands from a given file
batch -f {{path/to/file}}

# Execute commands from standard input (press `Ctrl + D` when finished)
batch

# Run calculator in interactive mode using the standard math library
bc -l

# Calculate the result of an expression
bc <<< "(1 + 2) * 2 ^ 2"

# Calculate expression and force number of decimal places to 10
bc <<< "scale=10; 5 / 3"

# Calculate expression with sine and cosine using mathlib
bc -l <<< "s(1) + c(1)"

# Start beanstalkd, listening on port 11300
beanstalkd

# Start beanstalkd listening on a custom port and address
beanstalkd -l {{ip_address}} -p {{port_number}}

# Persist work queues by saving them to disk
beanstalkd -b {{path/to/persistence_directory}}

# Sync to the persistence directory every 500 milliseconds
beanstalkd -b {{path/to/persistence_directory}} -f {{500}}

# Intersect two files with respect to the sequences' strand and save the result to {{path/to/output_file}}
bedtools intersect -a {{path/to/file_1}} -b {{path/to/file_2}} -s > {{path/to/output_file}}

# Intersect two files with a left outer join, i.e. report each feature from {{file_1}} and NULL if no overlap with {{file_2}}
bedtools intersect -a {{path/to/file_1}} -b {{path/to/file_2}} -lof > {{path/to/output_file}}

# Using more efficient algorithm to intersect two pre-sorted files
bedtools intersect -a {{path/to/file_1}} -b {{path/to/file_2}} -sorted > {{path/to/output_file}}

# Group file {{path/to/file}} based on the first three and the fifth column and summarize the sixth column by summing it up
bedtools groupby -i {{path/to/file}} -c 1-3,5 -g 6 -o sum

# Convert bam-formated file to a bed-formated one
bedtools bamtobed -i {{path/to/file}}.bam > {{path/to/file}}.bed

# Find for all features in {{file_1}}.bed the closest one in {{file_2}}.bed and write their distance in an extra column (input files must be sorted)
bedtools closest -a {{path/to/file_1}}.bed -b {{path/to/file_2}}.bed -d

# Resume most recently suspended job and run it in the background
bg

# Resume a specific job (use `jobs -l` to get its ID) and run it in the background
bg {{job_id}}

# Render all frames of an animation in the background, without loading the UI (output is saved to `/tmp`)
blender -b {{filename}}.blend -a

# Render an animation using a specific image naming pattern, in a path relative (`//`) to the .blend file
blender -b {{filename}}.blend -o //{{render/frame_###.png}} -a

# Render the 10th frame of an animation as a single image, saved to an existing folder (absolute path)
blender -b {{filename}}.blend -o {{/path/to/output_folder}} -f {{10}}

# Render the second last frame in an animation as a JPEG image, saved to an existing folder (relative path)
blender -b {{filename}}.blend -o //{{output_folder}} -F {{JPEG}} -f {{-2}}

# Render the animation of a specific scene, starting at frame 10 and ending at frame 500
blender -b {{filename}}.blend -S {{scene_name}} -s {{10}} -e {{500}} -a

# Render an animation at a specific resolution, by passing a Python expression
blender -b {{filename}}.blend --python-expr '{{import bpy; bpy.data.scenes[0].render.resolution_percentage = 25}}' -a

# Start an interactive Blender session in the terminal with a python console (do `import bpy` after starting)
blender -b --python-console

# Create a blockmap from image file
bmaptool create -o {{blockmap.bmap}} {{source.img}}

# Copy an image file into sdb
bmaptool copy --bmap {{blockmap.bmap}} {{source.img}} {{/dev/sdb}}

# Copy a compressed image file into sdb
bmaptool copy --bmap {{blockmap.bmap}} {{source.img.gz}} {{/dev/sdb}}

# Copy an image file into sdb without using a blockmap
bmaptool copy --nobmap {{source.img}} {{/dev/sdb}}

# Start a REPL session either with the project or standalone
boot repl

# Build a single "uberjar"
boot jar

# Learn about a command
boot cljs --help

# Generate scaffolding for a new project based on a template
boot --dependencies boot/new new --template {{template_name}} --name {{project_name}}

# Build for development (if using the boot/new template)
boot dev

# Build for production (if using the boot/new template)
boot prod

# Initialise a (local) repository
borg init {{/path/to/repo_folder}}

# Backup a folder into the repository, creating an archive called "Monday"
borg create --progress {{/path/to/repo_folder}}::{{Monday}} {{/path/to/source_folder}}

# List all archives in a repository
borg list {{/path/to/repo_folder}}

# Extract a specific folder from the "Monday" archive in a remote repository, excluding all *.ext files
borg extract {{user}}@{{host}}:{{/path/to/repo_folder}}::{{Monday}} {{path/to/target_folder}} --exclude '{{*.ext}}'

# Prune a repository by deleting all archives older than 7 days, listing changes
borg prune --keep-within {{7d}} --list {{/path/to/repo_folder}}

# Mount a repository as a FUSE filesystem
borg mount {{/path/to/repo_folder}}::{{Monday}} {{/path/to/mountpoint}}

# Display help on creating archives
borg create --help

# Create local alias for director
bosh alias-env {{environment_name}} -e {{ip_address|url}} --ca-cert {{ca_certificate}}

# List environments
bosh environments

# Login to the director
bosh login -e {{environment}} 

# List deployments
bosh -e {{environment}} deployments

# List environment virtual machines
bosh -e {{environment}} vms -d {{deployment}}

# Ssh into virtual machine
bosh -e {{environment}} ssh {{virtual_machine}} -d {{deployment}}

# Upload stemcell
bosh -e {{environment}} upload-stemcell {{stemcell_file|url}}

# Show current cloud config
bosh -e {{environment}} cloud-config

# Install a project's dependencies, listed in its bower.json
bower install

# Install one or more packages to the bower_components directory
bower install {{package}} {{package}}

# Uninstall packages locally from the bower_components directory
bower uninstall {{package}} {{package}}

# List local packages and possible updates
bower list

# Display help information about a bower command
bower help {{command}}

# Create a bower.json file for your package
bower init

# Install a specific dependency version, and add it to bower.json
bower install {{local_name}}={{package}}#{{version}} --save

# Build a new Phar file
box build

# Build a new Phar file using a specific config file
box build -c {{path/to/config}}

# Display information about the PHAR PHP extension
box info

# Display information about a specific Phar file
box info {{path/to/phar_file}}

# Validate the first found config file in the working directory
box validate

# Verify the signature of a specific Phar file
box verify {{path/to/phar_file}}

# Display all available commands and options
box help

# Start a server from a specific directory
browser-sync start --server {{path/to/directory}} --files {{path/to/directory}}

# Start a server from local directory, watching all css files in some directory
browser-sync start --server --files '{{path/to/directory/*.css}}'

# Create configuration file
browser-sync init

# Start browser-sync from config file
browser-sync start --config {{config_file}}

# Install all gems defined in the gemfile expected in the working directory
bundle install

# Update all gems by the rules defined in the gemfile and regenerate gemfile.lock
bundle update

# Update one specific gem defined in the gemfile
bundle update --source {{gemname}}

# Create a new gem skeleton
bundle gem {{gemname}}

# Initialize a backup repository in the specified local directory
bup -d {{path/to/repository}} init

# Prepare a given folder before taking a backup
bup -d {{path/to/repository}} index {{path/to/folder}}

# Backup a folder to the repository
bup -d {{path/to/repository}} save -n {{backup_name}} {{path/to/folder}}

# Show the backup snapshots currently stored in the repository
bup -d {{path/to/repository}} ls

# Restore a specific backup snapshot to a target directory
bup -d {{path/to/repository}} restore -C {{path/to/target_directory}} {{backup_name}}

# Compile source file(s) and create an executable
c99 {{file.c}}

# Compile source file(s) and create an executable with a custom name
c99 -o {{executable_name}} {{file.c}}

# Compile source file(s) and create object file(s)
c99 -c {{file.c}}

# Compile source file(s), link with object file(s), and create an executable
c99 {{file.c}} {{file.o}}

# Search and list packages from Hackage
cabal list {{search_string}}

# Show information about a package
cabal info {{package_name}}

# Download and install a package
cabal install {{package_name}}

# Create a new Haskell project in the current directory
cabal init

# Build the project in the current directory
cabal build

# Run tests of the project in the current directory
cabal test

# Start a server to distribute ebooks. Access at http://localhost:8080
calibre-server

# Start server on different port. Access at http://localhost:port
calibre-server --port {{port}}

# Password protect the server
calibre-server --username {{username}} --password {{password}}

# List ebooks in the library with additional information
calibredb list

# Search for ebooks displaying additional information
calibredb list --search {{search_term}}

# Search for just ids of ebooks
calibredb search {{search_term}}

# Add one or more ebooks to the library
calibredb add {{file1 file2 …}}

# Remove one or more ebooks from the library. You need ebook-ids (see above)
calibredb remove {{id1 id2 …}}

# Search for crates
cargo search {{search_string}}

# Install a crate
cargo install {{crate_name}}

# List installed crates
cargo install --list

# Create a new binary Rust project in the current directory
cargo init --bin

# Create a new library Rust project in the current directory
cargo init

# Build the Rust project in the current directory
cargo build

# Build with multiple parallel jobs
cargo build -j {{jobs}}

# Match a variable against string literals to decide which command to run
case {{$tocount}} in {{words}}) {{wc -w README}}; ;; {{lines}}) {{wc -l README}}; ;; esac

# Combine patterns with |, use * as a fallback pattern
case {{$tocount}} in {{[wW]|words}}) {{wc -w README}}; ;; {{[lL]|lines}}) {{wc -l README}}; ;; *) {{echo "what?"}}; ;; esac

# Print the contents of a file to the standard output
cat {{file}}

# Concatenate several files into the target file
cat {{file1}} {{file2}} > {{target_file}}

# Append several files into the target file
cat {{file1}} {{file2}} >> {{target_file}}

# Number all output lines
cat -n {{file}}

# Go to the given directory
cd {{path/to/directory}}

# Go to home directory of current user
cd

# Go up to the parent of the current directory
cd ..

# Go to the previously chosen directory
cd -

# Change the owner of a file/folder
chgrp {{group}} {{path/to/file}}

# Recursively change the owner of a folder and its contents
chgrp -R {{group}} {{path/to/folder}}

# Change the owner of a symbolic link
chgrp -h {{user}} {{path/to/symlink}}

# Change the owner of a file/folder to match a reference file
chgrp --reference={{path/to/reference_file}} {{path/to/file}}

# Give the [u]ser who owns a file the right to e[x]ecute it
chmod u+x {{file}}

# Give the user rights to [r]ead and [w]rite to a file/directory
chmod u+rw {{file}}

# Remove executable rights from the [g]roup
chmod g-x {{file}}

# Give [a]ll users rights to read and execute
chmod a+rx {{file}}

# Give [o]thers (not in the file owner's group) the same rights as the group
chmod o=g {{file}}

# Change permissions recursively giving [g]roup and [o]thers the abililty to [w]rite
chmod -R g+w,o+w {{directory}}

# Change the owner user of a file/folder
chown {{user}} {{path/to/file}}

# Change the owner user and group of a file/folder
chown {{user}}:{{group}} {{path/to/file}}

# Recursively change the owner of a folder and its contents
chown -R {{user}} {{path/to/folder}}

# Change the owner of a symbolic link
chown -h {{user}} {{path/to/symlink}}

# Change the owner of a file/folder to match a reference file
chown --reference={{path/to/reference_file}} {{path/to/file}}

# Run command as new root directory
chroot {{/path/to/new/root}} {{command}}

# Specify user and group (ID or name) to use
chroot --userspec={{user:group}}

# Change shell
chsh -s {{path/to/shell_binary}} {{username}}

# Display a 32 bit checksum, size in bytes and filename
cksum {{filename}}

# Compile a source code file into an executable binary
clang {{input_source.c}} -o {{output_executable}}

# Activate output of all errors and warnings
clang {{input_source.c}} -Wall -o {{output_executable}}

# Include libraries located at a different path than the source file
clang {{input_source.c}} -o {{output_executable}} -I{{header_path}} -L{{library_path}} -l{{library_name}}

# Compile source code into LLVM Intermediate Representation (IR)
clang -S -emit-llvm {{file.c}} -o {{file.ll}}

# Clear the screen (equivalent to typing Control-L when using the bash shell)
clear

# Count all the lines of code in a directory
cloc {{/path/to/directory}}

# Count all the lines of code in a directory, displaying a progress bar during the counting process
cloc --progress=1 {{/path/to/directory}}

# Compare 2 directory structures and count the differences between them
cloc --diff {{/directory/one}} {{/directory/two}}

# Generate a Makefile and use it to compile a project in the same folder as the source
cmake && make

# Generate a Makefile and use it to compile a project in a separate "build" folder (out-of-source build)
cmake -H. -B{{build}} && make -C {{build}}

# Run cmake in interactive mode (it will ask for each variable, instead of using defaults)
cmake -i

# Render a Commonmark Markdown file to HTML
cmark --to html {{filename.md}}

# Convert data from standard input to latex
cmark --to latex

# Convert straight quotes to smart quotes
cmark --smart --to html {{filename.md}}

# Validate utf8 characters
cmark --validate-utf8 {{filename.md}}

# Find the byte number and line number of the first difference between the files
cmp {{file1}} {{file2}}

# Find the byte number and differing bytes of every difference
cmp -l {{file1}} {{file2}}

# Open VS Code
code

# Open the current directory in VS Code
code .

# Open a file or directory in VS Code
code {{path/to/file_or_folder}}

# Open a file or directory in the currently open VS Code window
code --reuse-window {{path/to/file_or_folder}}

# Run a script
coffee {{path/to/file.coffee}}

# Compile to JavaScript and save to a file with the same name
coffee --compile {{path/to/file.coffee}}

# Compile to JavaScript and save to a given output file
coffee --compile {{path/to/file.coffee}} --output {{path/to/file.js}}

# Run interactive REPL
coffee --interactive

# Watch script for changes and re-run script
coffee --watch {{path/to/file.coffee}}

# Format output for a 30 characters wide display
printf "header1 header2\nbar foo\n" | column -c {{30}}

# Specify column delimiter character for the -t option (i.e. "," for csv); default is whitespace
printf "header1,header2\nbar,foo\n" | column -s{{,}}

# Split columns automatically and auto-align in a tabular format
printf "header1 header2\nbar foo\n" | column -t

# Fill columns before filling rows
printf "header1\nbar\nfoobar\n" | column -c {{30}} -x

# Produce three tab-separated columns: lines only in first file, lines only in second file and common lines
comm {{file1}} {{file2}}

# Print only lines common to both files
comm -12 {{file1}} {{file2}}

# Print only lines common to both files, reading one file from stdin
cat {{file1}} | comm -12 - {{file2}}

# Get lines only found in first file, saving the result to a third file
comm -23 {{file1}} {{file2}} > {{file1_only}}

# Print lines only found in second file, when the files aren't sorted
comm -13 <(sort {{file1}}) <(sort {{file2}})

# Apply a function that performs autocompletion to a command
complete -F {{function}} {{command}}

# Apply a command that performs autocompletion to another command
complete -C {{autocomplete_command}} {{command}}

# Apply autocompletion without appending a space to the completed word
complete -o nospace -F {{function}} {{command}}

# Add a package as a dependency for this project, adding it to `composer.json`
composer require {{user/package_name}}

# Install all the dependencies in this project's `composer.json`
composer install

# Uninstall a package from this project, removing it as a dependency from `composer.json`
composer remove {{user/package_name}}

# Update all the dependencies in this project's `composer.json`
composer update

# Update composer to the latest version
composer self-update

# Create a new environment, installing named packages into it
conda create --name {{environment_name}} {{python=2.7 matplotlib}}

# List all environments
conda info --envs

# Load or unload an environment
source {{activate|deactivate}} {{environment_name}}

# Delete an environment (remove all packages)
conda remove --name {{environment_name}} --all

# Search conda channels for a package by name
conda search {{package_name}}

# Install packages into the current environment
conda install {{python=3.4 numpy}}

# List currently installed packages in current environment
conda list

# Delete unused packages and caches
conda clean --all

# Read a value from the key-value store
consul kv get {{key}}

# Store a new key-value pair
consul kv put {{key}} {{value}}

# Delete a key-value pair
consul kv delete {{key}}

# Check the Consul version
consul --version

# Show general help
consul --help

# Show help for a sub-command
consul {{sub-command}} --help

# Convert an image from JPG to PNG
convert {{image.jpg}} {{image.png}}

# Scale an image 50% its original size
convert {{image.png}} -resize 50% {{image2.png}}

# Scale an image keeping the original aspect ratio to a maximum dimension of 640x480
convert {{image.png}} -resize 640x480 {{image2.png}}

# Horizontally append images
convert {{image1.png}} {{image2.png}} {{image3.png}} +append {{image123.png}}

# Create a gif from a series of images with 100ms delay between them
convert {{image1.png}} {{image2.png}} {{image3.png}} -delay {{100}} {{animation.gif}}

# Test filename encoding conversion (don't actually change the filename)
convmv -f {{from_encoding}} -t {{to_encoding}} {{input_file}}

# Convert filename encoding and rename the file to the new encoding
convmv -f {{from_encoding}} -t {{to_encoding}} --notest {{input_file}}

# Create a cordova project
cordova create {{path}} {{package_name}} {{project_name}}

# Display the current workspace status
cordova info

# Add a cordova platform
cordova platform add {{platform}}

# Remove a cordova platform
cordova platform remove {{platform}}

# Add a cordova plugin
cordova plugin add {{pluginid}}

# Remove a cordova plugin
cordova plugin remove {{pluginid}}

# Start couchdb
couchdb

# Start couchdb interactive shell
couchdb -i

# Start couchdb as a background process
couchdb -b

# Kill the background process (Note: It will respawn if needed)
couchdb -k

# Shutdown the background process
couchdb -d

# Print an ASCII cow saying "Hello world!"
cowsay "Hello world!"

# List all available characters
cowsay -l

# Print an ASCII dragon saying "Hello!"
echo "Hello!" | cowsay -f dragon

# Print a stoned thinking ASCII cow
cowthink -s "I'm just a cow, not a great thinker ..."

# Copy a file to another location
cp {{path/to/file.ext}} {{path/to/copy.ext}}

# Copy a file into another folder, keeping the filename
cp {{path/to/file.ext}} {{path/to/target_parent_folder}}

# Copy a folder recursively to another location
cp -r {{path/to/folder}} {{path/to/copy}}

# Copy a folder recursively, in verbose mode (shows files as they are copied)
cp -vr {{path/to/folder}} {{path/to/copy}}

# Copy the contents of a folder into another folder
cp -r {{path/to/source_folder/*}} {{path/to/target_folder}}

# Copy text files to another location, in interactive mode (prompts user before overwriting)
cp -i {{*.txt}} {{path/to/target_folder}}

# Take a list of file names from standard input and add them [o]nto an archive in cpio's binary format
echo "{{file1}} {{file2}} {{file3}}" | cpio -o > {{archive.cpio}}

# Copy all files and folders in a directory and add them [o]nto an archive, in [v]erbose mode
find {{path/to/directory}} | cpio -ov > {{archive.cpio}}

# P[i]ck all files from an archive, generating [d]irectories where needed, in [v]erbose mode
cpio -idv < {{archive.cpio}}

# Recursively check the current folder, showing progress on the screen and logging error messages to a file
cppcheck . 2> cppcheck.log

# Recursively check a given folder, and don't print progress messages
cppcheck --quiet {{path/to/folder}}

# Check a given file, specifying which tests to perform (by default only errors are shown)
cppcheck --enable={{error|warning|style|performance|portability|information|all}} {{path/to/file.cpp}}

# List available tests, filtered by a given search pattern
cppcheck --errorlist | grep "{{search_pattern}}"

# Check a given file, ignoring specific tests
cppcheck --suppress={{test_id1}} --suppress={{test_id2}} {{path/to/file.cpp}}

# Check the current folder, providing paths for include files located outside it (e.g. external libraries)
cppcheck -I {{include/folder_1}} -I {{include/folder_2}} .

# Check a Microsoft Visual Studio project (`*.vcxproj`) or solution (`*.sln`)
cppcheck --project={{path/to/project.sln}}

# Run in a project's folder
cppclean {{path/to/project}}

# Run on a project where the headers are in the "inc1/" and "inc2/" folders
cppclean {{path/to/project}} --include-path={{inc1}} --include-path={{inc2}}

# Run on a specific file "main.cpp"
cppclean {{main.cpp}}

# Run on the current directory, excluding the "build" directory
cppclean {{.}} --exclude={{build}}

# Edit the crontab file for the current user
crontab -e

# View a list of existing cron jobs for current user
crontab -l

# Remove all cron jobs for the current user
crontab -r

# Sample job which runs at 10:00 every day. * means any value
0 10 * * * {{path/to/script.sh}}

# Sample job which runs every minute on the 3rd of April
* * 3 Apr * {{path/to/script.sh}}

# Sample job which runs at 02:30 every Friday
30 2 * * Fri {{path/to/script.sh}}

# Run a crystal file
crystal {{path/to/file.cr}}

# Compile a file and all dependencies to a single executable
crystal build {{path/to/file.cr}}

# Start a local interactive server for testing the language
crystal play

# Create a project directory for a crystal application
crystal init app {{application_name}}

# Display all help options
crystal help

# Lint a single CSS file
csslint {{file.css}}

# Lint multiple CSS files
csslint {{file1.css}} {{file2.css}} {{file3.css}}

# List all possible style rules
csslint --list-rules

# Specify certain rules as errors (which result in a non-zero exit code)
csslint --errors={{errors,universal-selector,imports}} {{file.css}}

# Specify certain rules as warnings
csslint --warnings={{box-sizing,selector-max,floats}} {{file.css}}

# Specify certain rules to completely ignore
csslint --ignore={{ids,rules-count,shorthand}} {{file.css}}

# Clean a CSV file
csvclean {{bad.csv}}

# List locations of syntax errors in a CSV file
csvclean -n {{bad.csv}}

# Print indices and names of all columns
csvcut -n {{data.csv}}

# Extract the first and third columns
csvcut -c {{1,3}} {{data.csv}}

# Extract all columns **except** the fourth one
csvcut -C {{4}} {{data.csv}}

# Extract the columns named "id" and "first name" (in that order)
csvcut -c {{id,"first name"}} {{data.csv}}

# Convert to a tab-delimited file (TSV)
csvformat -T {{data.csv}}

# Convert delimiters to a custom character
csvformat -D "{{custom_character}}" {{data.csv}}

# Convert line endings to carriage return (^M) + line feed
csvformat -M "{{\r\n}}" {{data.csv}}

# Minimize use of quote characters
csvformat -U 0 {{data.csv}}

# Maximize use of quote characters
csvformat -U 1 {{data.csv}}

# Find rows that have a certain string in column 1
csvgrep -c {{1}} -m {{string_to_match}} {{data.csv}}

# Find rows in which columns 3 or 4 match a certain regex pattern
csvgrep -c {{3,4}} -r {{regex_pattern}} {{data.csv}}

# Find rows in which the "name" column does NOT include the string "John Doe"
csvgrep -i -c {{name}} -m {{"John Doe"}} {{data.csv}}

# View a CSV file
csvlook {{data.csv}}

# Load a CSV file into a `CSVKitReader` object
csvpy {{data.csv}}

# Load a CSV file into a `CSVKitDictReader` object
csvpy --dict {{data.csv}}

# Sort a CSV file by column 9
csvsort -c {{9}} {{data.csv}}

# Sort a CSV file by the "name" column in descending order
csvsort -r -c {{name}} {{data.csv}}

# Sort a CSV file by column 2, then by column 4
csvsort -c {{2,4}} {{data.csv}}

# Sort a CSV file without inferring data types
csvsort --no-inference -c {{columns}} {{data.csv}}

# Show all stats for all columns
csvstat {{data.csv}}

# Show all stats for columns 2 and 4
csvstat -c {{2,4}} {{data.csv}}

# Show sums for all columns
csvstat --sum {{data.csv}}

# Show the max value length for column 3
csvstat -c {{3}} --len {{data.csv}}

# Show the number of unique values in the "name" column
csvstat -c {{name}} --unique {{data.csv}}

# Download the contents of an URL to a file
curl {{http://example.com}} -o {{filename}}

# Download a file, saving the output under the filename indicated by the URL
curl -O {{http://example.com/filename}}

# Download a file, following [L]ocation redirects, and automatically [C]ontinuing (resuming) a previous file transfer
curl -O -L -C - {{http://example.com/filename}}

# Send form-encoded data (POST request of type `application/x-www-form-urlencoded`)
curl -d {{'name=bob'}} {{http://example.com/form}}

# Send a request with an extra header, using a custom HTTP method
curl -H {{'X-My-Header: 123'}} -X {{PUT}} {{http://example.com}}

# Send data in JSON format, specifying the appropriate content-type header
curl -d {{'{"name":"bob"}'}} -H {{'Content-Type: application/json'}} {{http://example.com/users/1234}}

# Pass a user name and password for server authentication
curl -u myusername:mypassword {{http://example.com}}

# Pass client certificate and key for a resource, skipping certificate validation
curl --cert {{client.pem}} --key {{key.pem}} --insecure {{https://example.com}}

# Cut out the first sixteen characters of each line of STDIN
cut -c {{1-16}}

# Cut out the first sixteen characters of each line of the given files
cut -c {{1-16}} {{file}}

# Cut out everything from the 3rd character to the end of each line
cut -c{{3-}}

# Cut out the fifth field of each line, using a colon as a field delimiter (default delimiter is tab)
cut -d'{{:}}' -f{{5}}

# Cut out the 2nd and 10th fields of each line, using a semicolon as a delimiter
cut -d'{{;}}' -f{{2,10}}

# Cut out the fields 3 through to the end of each line, using a space as a delimiter
cut -d'{{ }}' -f{{3-}}

# Start server serving the specified document root
darkhttpd {{path/to/docroot}}

# Start server on specified port (port 8080 by default if running as non-root user)
darkhttpd {{path/to/docroot}} --port {{port}}

# Listen only on specified IP address (by default, the server listens on all interfaces)
darkhttpd {{path/to/docroot}} --addr {{ip_address}}

# Display the current date using the default locale's format
date +"%c"

# Display the current date in UTC and ISO 8601 format
date -u +"%Y-%m-%dT%H:%M:%SZ"

# Display the current date as a Unix timestamp (seconds since the Unix epoch)
date +%s

# Display a specific date (represented as a Unix timestamp) using the default format
date -d @1473305798

# Run calculator in interactive mode
dc

# Execute dc script in file
dc -f {{file}}

# Calculate 4 times 5 [4 5 *], subtract 17 [17 -], and [p]rint the output (using echo)
echo "4 5 * 17 - p"| dc

# Set number of decimal places to 7 [7 k], calculate 5 divided by -3 [5 _3 /] and [p]rint (using dc -e)
dc -e "7 k 5 _3 / p"

# Calculate the golden ratio, phi: Set number of decimal places to 100 [100 k], square root of 5 [5 v] plus 1 [1 +], divided by 2 [2 /], and [p]rint result
dc -e "100 k 5 v 1 + 2 / p"

# Make a bootable usb drive from an isohybrid file (such like archlinux-xxx.iso) and show the progress
dd if={{file.iso}} of=/dev/{{usb_drive}} status=progress

# Clone a drive to another drive with 4MB block, ignore error and show progress
dd if=/dev/{{source_drive}} of=/dev/{{dest_drive}} bs=4M conv=noerror status=progress

# Generate a file of 100 random bytes by using kernel random driver
dd if=/dev/urandom of={{random_file}} bs=100 count=1

# Benchmark the write performance of a disk
dd if=/dev/zero of={{file_1GB}} bs=1024 count=1000000

# Check progress of an ongoing dd operation (Run this command from another shell)
kill -USR1 $(pgrep ^dd)

# Convert a CoffeeScript file to JavaScript
decaffeinate {{path/to/file.coffee}}

# Convert a CoffeeScript v2 file to JavaScript
decaffeinate --use-cs2 {{path/to/file.coffee}}

# Convert require and module.exports to import and export
decaffeinate --use-js-modules {{path/to/file.coffee}}

# Convert a CoffeeScript, allowing named exports
decaffeinate --loose-js-modules {{path/to/file.coffee}}

# Remove a user
deluser {{name}}

# Remove a user along with their home directory and mail spool
deluser -r {{name}}

# Remove a user from a group
deluser {{name}} {{group}}

# Initialize the current directory as the root of a Go project
dep init

# Install any missing dependencies (Scans Gopkg.toml and your .go files)
dep ensure

# Report the status of the project's dependencies
dep status

# Add a dependency to the project
dep ensure -add {{package_url}}

# Update the locked versions of all dependencies
dep ensure -update

# Remove spaces and other undesirable characters from a file's name
detox {{file}}

# Show how detox would rename all of the files in a directory tree
detox --dry-run -r {{directory}}

# Remove spaces and other undesirable characters from all files in a directory tree
detox -r {{directory}}

# Display all file systems and their disk usage
df

# Display all file systems and their disk usage in human readable form
df -h

# Display the file system and its disk usage containing the given file or folder
df {{path/to/file_or_folder}}

# Flood the network with IP requests
dhcpwn --interface {{network_interface}} flood --count {{number_of_requests}}

# Sniff local DHCP traffic
dhcpwn --interface {{network_interface}} sniff

# Compare files
diff {{file1}} {{file2}}

# Compare files, ignoring white spaces
diff -w {{file1}} {{file2}}

# Compare files, showing the differences side by side
diff -y {{file1}} {{file2}}

# Compare files, showing the differences in unified format (as used by `git diff`)
diff -u {{file1}} {{file2}}

# Compare directories recursively
diff -r {{directory1}} {{directory2}}

# Compare directories, only showing the names of files that differ
diff -rq {{directory1}} {{directory2}}

# Display changes in a histogram
diff {{file1}} {{file2}} | diffstat

# Display inserted, deleted and modified changes as a table
diff {{file1}} {{file2}} | diffstat -t

# Lookup the IP(s) associated with a hostname (A records)
dig +short {{hostname.com}}

# Lookup the mail server(s) associated with a given domain name (MX record)
dig +short {{hostname.com}} MX

# Get all types of records for a given domain name
dig {{hostname.com}} ANY

# Specify an alternate DNS server to query
dig @{{8.8.8.8}} {{hostname.com}}

# Perform a reverse DNS lookup on an IP address (PTR record)
dig -x {{8.8.8.8}}

# Find authoritative name servers for the zone and display SOA records
dig +nssearch {{hostname.com}}

# Perform iterative queries and display the entire trace path to resolve a domain name
dig +trace {{hostname.com}}

# Output commands to set LS_COLOR using default colors
dircolors

# Output commands to set LS_COLOR using colors from a file
dircolors {{file}}

# Output commands for Bourne shell
dircolors --bourne-shell

# Output commands for C shell
dircolors --c-shell

# View the default colors for file types and extensions
dircolors --print-data

# Calculate the parent directory of a given path
dirname {{path/to/file_or_directory}}

# Calculate the parent directory of multiple paths
dirname {{path/to/file_a}} {{path/to/directory_b}}

# Delimit output with a NUL character instead of a newline (useful when combining with `xargs`)
dirname --zero {{path/to/directory_a}} {{path/to/file_b}}

# Display the directory stack with a space between each entry
dirs

# Display the directory stack with one entry per line
dirs -p

# Display only the nth entry in the directory stack, starting at 0
dirs +{{N}}

# Clear the directory stack
dirs -c

# Create and start all containers in the background using a `docker-compose.yml` file from the current directory
docker-compose up -d

# Start all containers, rebuild if necessary
docker-compose up --build

# Start all containers using an alternate compose file
docker-compose --file {{path/to/file}} up

# Stop all running containers
docker-compose stop

# Stop and remove all containers, networks, images, and volumes
docker-compose down

# Follow logs for all containers
docker-compose logs --follow

# List currently running docker containers
docker container ls

# List all docker containers (running and stopped)
docker container ls -a

# Start a container from an image, with a custom name
docker container run --name={{container_name}} {{image}}

# Start or stop an existing container
docker container {{start|stop}} {{container_name}}

# Start a container from an image and get a shell inside of it
docker container run -it {{image}} bash

# Run a command inside of an already running container
docker container exec {{container_name}} {{command}}

# Remove a stopped container
docker container rm {{container_name}}

# Fetch and follow the logs of a container
docker container logs -f {{container_name}}

# List runinng apps
dokku apps

# Create an app
dokku apps:create {{app_name}}

# Remove an app
dokku apps:destroy {{app_name}}

# Install plugin
dokku plugin:install {{full_repo_url}}

# Link database to an app
dokku {{db}}:link {{db_name}} {{app_name}}

# Render an image file and determine output filename based on input filename and selected format
dot -Tpng -O {{path/to/file.dot}}

# Create an SVG from DOT file
dot -Tsvg -o {{path/to/out_file.svg}} {{path/to/file.dot}}

# Initialize a new .NET project
dotnet new {{template_short_name}}

# Restore nuget packages
dotnet restore

# Build and execute the .NET project in the current directory
dotnet run

# Run a packaged dotnet application (only needs the runtime, the rest of the commands require the .NET Core SDK installed)
dotnet {{path/to/application.dll}}

# Generate a default template configuration file "Doxyfile"
doxygen -g

# Generate a template configuration file
doxygen -g {{path/to/config_file}}

# Generate documentation using an existing configuration file
doxygen {{path/to/config_file}}

# Download module "foo"
drush dl {{foo}}

# Download version 7.x-2.1-beta1 of module "foo"
drush dl {{foo}}-7.x-2.1-beta1

# Enable module "foo"
drush en {{foo}}

# Disable module "foo"
drush dis {{foo}}

# Clear all caches
drush cc all

# Clear CSS and JavaScript caches
drush cc css-js

# List the sizes of a folder and any subfolders, in the given unit (B/KB/MB)
du -{{b|k|m}} {{path/to/folder}}

# List the sizes of a folder and any subfolders, in human-readable form (i.e. auto-selecting the appropriate unit for each size)
du -h {{path/to/folder}}

# Show the size of a single folder, in human readable units
du -sh {{path/to/folder}}

# List the human-readable sizes of a folder and of all the files and folders within it
du -ah {{path/to/folder}}

# List the human-readable sizes of a folder and any subfolders, up to N levels deep
du -h --max-depth=N {{path/to/folder}}

# List the human-readable size of all .jpg files in subfolders of the current folder, and show a cumulative total at the end
du -ch */*.jpg

# Backup a folder via FTPS to a remote machine, encrypting it with a password
FTP_PASSWORD={{ftp_login_password}} PASSPHRASE={{encryption_password}} duplicity {{path/to/source/directory}} {{ftps://user@hostname/target/directory/path/}}

# Backup a folder to Amazon S3, doing a full backup every month
duplicity --full-if-older-than {{1M}} --use-new-style s3://{{bucket_name[/prefix]}}

# Delete versions older than 1 year from a backup stored on a WebDAV share
FTP_PASSWORD={{webdav_login_password}} duplicity remove-older-than {{1Y}} --force {{webdav[s]://user@hostname[:port]/some_dir}}

# List the available backups
duplicity collection-status "file://{{absolute/path/to/backup/folder}}"

# List the files in a backup stored on a remote machine, via ssh
duplicity list-current-files --time {{YYYY-MM-DD}} scp://{{user@hostname}}/path/to/backup/dir

# Restore a subdirectory from a GnuPG-encrypted local backup to a given location
PASSPHRASE={{gpg_key_password}} duplicity restore --encrypt-key {{gpg_key_id}} --file-to-restore {{relative/path/restorefolder}} file://{{absolute/path/to/backup/folder}} {{path/to/directory/to/restore/to}}

# Convert an ebook into another format
ebook-convert {{source}} {{destination}}

# Print a text message. Note: quotes are optional
echo {{"Hello World"}}

# Print a message with environment variables
echo {{"My path is $PATH"}}

# Print a message without the trailing newline
echo -n {{"Hello World"}}

# Enable interpretation of backslash escapes (special characters)
echo -e {{"Column 1\tColumn 2"}}

# Start ed, editing an empty document (which can be saved as a new file in the current directory)
ed

# Start ed, editing an empty document, with `:` as a command prompt indicator
ed -p :

# Start ed editing an existing file (this shows the byte count of the loaded file)
ed -p : {{path/to/file}}

# Toggle the printing of error explanations. (By default, explanations are not printed and only a `?` appears)
H

# Add text to the current document. Mark completion by entering a period by itself in a new line
a<Enter>{{text_to_insert}}<Enter>.

# Print the entire document (`,` is a shortcut to the range `1,$` which covers the start to the end of the document)
,p

# Write the current document to a new file (the filename can be omitted if `ed` was called with an existing file)
w {{filename}}

# Quit ed
q

# Create a new wallet
electrum -w {{new_wallet.dat}} create

# Restore an existing wallet from seed offline
electrum -w {{recovery_wallet.dat}} restore -o

# Create a signed transaction offline
electrum mktx {{recipient}} {{amount}} -f 0.0000001 -F {{from}} -o

# Display all wallet receiving addresses
electrum listaddresses -a

# Sign a message
electrum signmessage {{address}} {{message}}

# Verify a message
electrum verifymessage {{address}} {{signature}} {{message}}

# Connect only to a specific electrum-server instance
electrum -p socks5:{{127.0.0.1}}:9050 -s {{56ckl5obj37gypcu.onion}}:50001:t -1

# Start elinks
elinks

# Quit elinks
Ctrl + C

# Dump output of webpage to console, colorizing the text with ANSI control codes
elinks -dump -dump-color-mode {{1}} {{url}}

# Start an interactive Elm shell (REPL)
elm --repl

# Initialize an empty Elm project
elm --init

# Compile the current project and serve it via the local web server
elm --reactor

# Open emacs in console mode (without X window)
emacs -nw

# Open a file in emacs
emacs {{filename}}

# Exit emacs
C-x C-c

# Open files in an existing Emacs server (using GUI if available)
emacsclient {{filename}}

# Open file in console mode (without X window)
emacsclient -nw {{filename}}

# Open a file in an existing emacs frame and return immediately
emacsclient -n {{filename}}

# Create a new Ember application
ember new {{my_new_app}}

# Create a new Ember addon
ember addon {{my_new_addon}}

# Build the project
ember build

# Build the project in production mode
ember build -prod

# Run the development server
ember serve

# Run the test suite
ember test

# Run a blueprint to generate something like a route or component
ember generate {{type}} {{name}}

# Install an ember-cli addon
ember install {{name_of_addon}}

# Detect file(s) encoding according to your system's locale
enca {{file(s)}}

# Detect file(s) encoding; -L option tells enca the current language; language is in the POSIX/C locale format, e.g. zh_CN, en_US etc
enca -L {{language}} {{file(s)}}

# Convert file(s) to specified encoding
enca -L {{language}} -x {{to_encoding}} {{file(s)}}

# Save original_file as new_file and convert new_file to specified encoding
enca -L {{language}} -x {{to_encoding}} < {{original_file}} > {{new_file}}

# Generate PostScript from a file and output to another
enscript {{path/to/input_file}} --output={{path/to/output_file}}

# Generate a certain output language (eg. "html") from a file and output to another
enscript {{path/to/input_file}} --language={{language}} --output={{path/to/output_file}}

# Generate PostScript from a file and output to another with 1 to 9 column per page in landscape
enscript {{path/to/input_file}} --columns={{num}} --landscape --output={{path/to/output_file}}

# Display available syntax highlighting
enscript --help-highlight

# Generate PostScript from a file and output to another with syntax highlighting and color for a specified language
enscript {{path/to/input_file}} --color=1 --highlight={{language}} --output={{path/to/output_file}}

# Show the environment
env

# Run a program. Often used in scripts after the shebang (#!) for looking up the path to the program
env {{program}}

# Clear the environment and run a program
env -i {{program}}

# Remove variable from the environment and run a program
env -u {{variable}} {{program}}

# Set a variable and run a program
env {{variable}}={{value}} {{program}}

# Create eslint config
eslint --init

# Lint on files
eslint {{filename}}.js {{filename1}}.js

# Fix lint issues
eslint --fix

# Lint with config
eslint -c {{path/to/config_file}} {{app/src}}

# Speak a phrase aloud
espeak "I like to ride my bike."

# Speak a file aloud
espeak -f {{filename}}

# Save output to a WAV audio file, rather than speaking it directly
espeak -w {{filename.wav}} "It's GNU plus Linux"

# Use a different voice
espeak -v {{voice}}

# List files one per line
exa --oneline

# List all files, including hidden files
exa --all

# Long format list (permissions, ownership, size and modification date) of all files
exa --long --all

# List files with the largest at the top
exa --reverse --sort={{size}}

# Display a tree of files, three levels deep
exa --long --tree --level={{3}}

# List files sorted by modification date (oldest first)
exa --long --sort={{modified}}

# Remove all EXIF metadata from the given files
exiftool -All= {{file}}

# Increase time photo taken by 1 hour in directory
exiftool "-AllDates+=0:0:0 1:0:0" {{directory}}

# Decrease time photo taken by 1 day and 2 hours on JPEGs only
exiftool "-AllDates-=0:0:1 2:0:0" -ext jpg

# Change only DateTimeOriginal by -1.5 hours & do not keep backups
exiftool -DateTimeOriginal-=1.5 -overwrite_original

# Rename all JPEGs according to a DateTimeOriginal recursively
exiftool '-filename<DateTimeOriginal' -d %Y-%m-%d_%H-%M-%S%%lc.%%e {{directory}} -r -ext jpg

# Convert tabs in each file to spaces, writing to standard output
expand {{file}}

# Convert tabs to spaces, reading from standard input
expand

# Do not convert tabs after non blanks
expand -i {{file}}

# Have tabs a certain number of characters apart, not 8
expand -t={{number}} {{file}}

# Use comma separated list of explicit tab positions
expand -t={{list}}

# Get string length
expr length {{string}}

# Evaluate logical or math expression with an operator ('+', '-', '*', '&', '|', etc.). Special symbols should be escaped
expr {{first_argument}} {{operator}} {{second_argument}}

# Get position of the first character in 'string' that matches 'substring'
echo $(expr index {{string}} {{substring}})

# Extract part of the string
echo $(expr substr {{string}} {{position_to_start}} {{number_of_characters}}

# Extract part of the string which matches a regular expression
echo $(expr {{string}} : '\({{regular_expression}}\)')

# Display the prime-factorization of a number
factor {{number}}

# Take the input from stdin if no argument is specified
echo {{number}} | factor

# Return an exit code of 1
false

# Unlock the bootloader
fastboot oem unlock

# Relock the bootloader
fastboot oem lock

# Reboot the device from fastboot mode into fastboot mode again
fastboot reboot bootloader

# Flash a given image
fastboot flash {{file.zip}}

# Flash a custom recovery image
fastboot flash recovery {{file.img}}

# Display connected devices
fastboot devices

# Find files under current directory that match a pattern
fd {{pattern}}

# Find files that begin with foo
fd {{'^foo'}}

# Find files with a specific extension
fd --extension {{.ext}} {{pattern}}

# Find files under a specific directory
fd {{pattern}} {{path/to/dir}}

# Include ignored and hidden files in search
fd --hidden --no-ignore {{pattern}}

# Search a single directory
fdupes {{directory}}

# Search multiple directories
fdupes {{directory1}} {{directory2}}

# Search all directories recursively
fdupes -r {{directory}}

# Search multiple directories, one recursively
fdupes {{directory1}} -R {{directory2}}

# Extract the sound from a video and save it as MP3
ffmpeg -i {{video.mp4}} -vn {{sound}}.mp3

# Convert frames from a video or GIF into individual numbered images
ffmpeg -i {{video.mpg|video.gif}} {{frame_%d.png}}

# Combine numbered images (frame_1.jpg, frame_2.jpg, etc) into a video or GIF
ffmpeg -i {{frame_%d.jpg}} -f image2 {{video.mpg|video.gif}}

# Quickly extract a single frame from a video at time mm:ss and save it as a 128x128 resolution image
ffmpeg -ss {{mm:ss}} -i {{video.mp4}} -frames 1 -s {{128x128}} -f image2 {{image.png}}

# Trim a video from a given start time mm:ss to an end time mm2:ss2 (omit the -to flag to trim till the end)
ffmpeg -ss {{mm:ss}} -to {{mm2:ss2}} -i {{video.mp4}} -codec copy {{output.mp4}}

# Convert AVI video to MP4. AAC Audio @ 128kbit, h264 Video @ CRF 23
ffmpeg -i {{input_video}}.avi -codec:audio aac -b:audio 128k -codec:video libx264 -crf 23 {{output_video}}.mp4

# Remux MKV video to MP4 without re-encoding audio or video streams
ffmpeg -i {{input_video}}.mkv -codec copy {{output_video}}.mp4

# Convert MP4 video to VP9 codec. For the best quality, use a CRF value (recommended range 15-35) and -b:video MUST be 0
ffmpeg -i {{input_video}}.mp4 -codec:video libvpx-vp9 -crf {{30}} -b:video 0 -codec:audio libopus -vbr on -threads {{number_of_threads}} {{output_video}}.webm

# Display all available stream info for a media file
ffprobe -v error -show_entries {{input.mp4}}

# Display media duration
ffprobe -v error -show_entries format=duration -of default=noprint_wrappers=1:nokey=1 {{input.mp4}}

# Display the frame rate of a video
ffprobe -v error -select_streams v:0 -show_entries stream=avg_frame_rate -of default=noprint_wrappers=1:nokey=1 {{input.mp4}}

# Display the width or height of a video
ffprobe -v error -select_streams v:0 -show_entries stream={{width|height}} -of default=noprint_wrappers=1:nokey=1 {{input.mp4}}

# Display the average bit rate of a video
ffprobe -v error -select_streams v:0 -show_entries stream=bit_rate -of default=noprint_wrappers=1:nokey=1 {{input.mp4}}

# Bring most recently suspended background job to foreground
fg

# Bring a specific job to foreground
fg {{job_id}}

# Find files by extension
find {{root_path}} -name '{{*.ext}}'

# Find directories matching a given name
find {{root_path}} -type d -name {{*lib*}}

# Find files matching path pattern
find {{root_path}} -path '{{**/lib/**/*.ext}}'

# Run a command for each file, use {} within the command to access the filename
find {{root_path}} -name '{{*.ext}}' -exec {{wc -l {} }}\;

# Find files modified in the last 24-hour period
find {{root_path}} -mtime {{-1}}

# Find files using case insensitive name matching, of a certain size
find {{root_path}} -size {{+500k}} -size {{-10M}} -iname '{{*.TaR.gZ}}'

# Delete files by name, older than 180 days
find {{root_path}} -name '{{*.ext}}' -mtime {{+180}} -delete

# Find files matching a given pattern, while excluding specific paths
find {{root_path}} -name '{{*.py}}' -not -path '{{*/site-packages/*}}'

# Display information about currently logged in users
finger

# Display information about a specific user
finger {{username}}

# Display the user's login name, real name, terminal name, and other information
finger -s

# Produce multi-line output format displaying same information as `-s` as well as user's home directory, home phone number, login shell, mail status, etc.
finger -l

# Prevent matching against user's names and only use login names
finger -m

# Start interactive shell
fish

# Execute a command
fish -c "{{command}}"

# Run commands from a file
fish {{file.fish}}

# Check a file for syntax errors
fish --no-execute {{file.fish}}

# Display version information and exit
fish --version

# Install one or more plugins
fisher {{plugin1}} {{plugin2}}

# Install a plugin from a GitHub gist
fisher {{gist_url}}

# Edit 'fishfile' by hand with your favorite editor and install multiple plugins
{{editor}} ~/.config/fish/fishfile; fisher

# List installed plugins
fisher ls

# Show available plugins
fisher ls-remote

# Update plugins
fisher up

# Remove one or more plugins
fisher rm {{plugin1}} {{plugin2}}

# Run without arguments to use the interactive interface
fkill

# Kill the process by pid, name or port
fkill {{pid|name|:port}}

# Encode a wav file to flac (this will create a flac file in the same location as the wav file)
flac {{path/to/file.wav}}

# Encode a wav file to flac, specifying the output file
flac -o {{path/to/output.flac}} {{path/to/file.wav}}

# Decode a flac file to wav, specifying the output file
flac -d -o {{path/to/output.wav}} {{path/to/file.flac}}

# Test a flac file for the correct encoding
flac -t {{path/to/file.flac}}

# Generate an analyser from a flex file
flex {{analyser.l}}

# Specify the output file
flex {{analyser.l}} --outfile {{analyser.c}}

# Compile a C file generated by flex
cc {{path/to/lex.yy.c}} --output {{executable}}

# Check the Flutter version
flutter --version

# Display general help
flutter help

# Display help about a specific command
flutter help {{command}}

# Execute a Flutter command
flutter {{command}}

# Show information about the installed tooling
flutter doctor

# Authenticate with and save concourse target
fly --target {{target_name}} login --team-name {{team_name}} -c {{https://ci.example.com}}

# List targets
fly targets

# List pipelines
fly -t {{target_name}} pipelines

# Upload or update a pipeline
fly -t {{target_name}} set-pipeline --config {{pipeline.yml}} --pipeline {{pipeline_name}}

# Unpause pipeline
fly -t {{target_name}} unpause-pipeline --pipeline {{pipeline_name}}

# Show pipeline configuration
fly -t {{target_name}} get-pipeline --pipeline {{pipeline_name}}

# Update local copy of fly
fly -t {{target_name}} sync

# Destroy pipeline
fly -t {{target_name}} destroy-pipeline --pipeline {{pipeline_name}}

# Wrap each line to default width (80 characters)
fold {{file}}

# Wrap each line to width "30"
fold -w30 {{file}}

# Wrap each line to width "5" and break the line at spaces (puts each space separated word in a new line, words with length > 5 are wrapped)
fold -w5 -s {{file}}

# Perform a command with different arguments
for argument in 1 2 3; do {{command $argument}}; done

# Perform a command in every directory
for d in *; do (cd $d; {{command}}); done

# Start running a file forever (as a daemon)
forever {{script}}

# List running "forever" processes (along with IDs and other details of "forever" processes)
forever list

# Stop a running "forever" process
forever stop {{ID|pid|script}}

# Print a quotation
fortune

# Print an offensive quotation
fortune -o

# Print a long quotation
fortune -l

# Print a short quotation
fortune -s

# List the available quotation database files
fortune -f

# Print a quotation from one of the database files listed by `fortune -f`
fortune {{filename}}

# List alive hosts within a subnet generated from a netmask
fping -a -g 192.168.1.0/24

# List alive hosts within a subnet generated from an IP range
fping -a -g 192.168.1.1 192.168.1.254

# List unreachable hosts within a subnet generated from a netmask
fping -u -g 192.168.1.0/24

# Run a bash command on file creation, update or deletion
fswatch {{path/to/file}} | xargs -n 1 {{bash_command}}

# Watch one or more files and/or directories
fswatch {{path/to/file}} {{path/to/directory}} {{path/to/another_directory/**/*.js}} | xargs -n 1 {{bash_command}}

# Print the absolute paths of the changed files
fswatch {{path/to/directory}} | xargs -n 1 -I {} echo {}

# Filter by event type, eg. Updated, Deleted or Created
fswatch --event {{Updated}} {{path/to/directory}} | xargs -n 1 {{bash_command}}

# Take a picture
fswebcam {{filename}}

# Take a picture with custom resolution
fswebcam -r {{width}}x{{height}} {{filename}}

# Take a picture from selected device(Default is /dev/video0)
fswebcam -d {{device}} {{filename}}

# Take a picture with timestamp(timestamp string is formatted by strftime)
fswebcam --timestamp {{timestamp}} {{filename}}

# Connect to an FTP server
ftp {{ftp.example.com}}

# Switch to binary transfer mode (graphics, compressed files, etc)
binary

# Transfer multiple files without prompting for confirmation on every file
prompt off

# Download multiple files (glob expression)
mget {{*.png}}

# Upload multiple files (glob expression)
mput {{*.zip}}

# Delete multiple files on the remote server
mdelete {{*.txt}}

# Rename a file on the remote server
rename {{original_filename}} {{new_filename}}

# Set the `fuck` alias to `thefuck` tool
eval "$(thefuck --alias)"

# Try to match a rule for the previous command
fuck

# Start finder on all files from arbitrary locations
find {{path/to/search}} -type f | fzf

# Start finder on running processes
ps aux | fzf

# Select multiple files with `Shift + Tab` and write to a file
find {{path/to/search_files}} -type f | fzf -m > {{filename}}

# Start finder with a given query
fzf -q "{{query}}"

# Start finder on entries that start with core and end with either go, rb, or py
fzf -q "^core go$ | rb$ | py$"

# Start finder on entries that not match pyc and match exactly travis
fzf -q "!pyc 'travis"

# Compile a source code file into an executable binary
g++ {{source.cpp}} -o {{output_executable}}

# Display (almost) all errors and warnings
g++ {{source.cpp}} -Wall -o {{output_executable}}

# Choose a language standard to compile for(C++98/C++11/C++14/C++17)
g++ {{source.cpp}} -std={{language_standard}} -o {{output_executable}}

# Include libraries located at a different path than the source file
g++ {{source.cpp}} -o {{output_executable}} -I{{header_path}} -L{{library_path}} -l{{library_name}}

# Create a new site
gatsby new {{site_name}}

# Create a new site with a Gatsby 'starter'
gatsby new {{site_name}} {{url_of_starter_github_repo}}

# Start a live-reloading local development server
gatsby develop

# Perform a production build and generate static HTML
gatsby build

# Start a local server which serves the production build
gatsby serve

# Compile multiple source files into executable
gcc {{source1.c}} {{source2.c}} -o {{executable}}

# Allow warnings, debug symbols in output
gcc {{source.c}} -Wall -Og -o {{executable}}

# Include libraries from a different path
gcc {{source.c}} -o {{executable}} -I{{header_path}} -L{{library_path}} -l{{library_name}}

# Compile source code into Assembler instructions
gcc -S {{source.c}}

# Compile source code without linking
gcc -c {{source.c}}

# List all properties in one's active configuration
gcloud config list

# Set the active project
gcloud config set project {{project_name}}

# SSH into a virtual machine instance
gcloud compute ssh {{user}}@{{instance}} 

# Display all Google Compute Engine instances in a project. Instances from all zones are listed by default
gcloud compute instances list

# Update a kubeconfig file with the appropriate credentials to point kubectl to a specific cluster in Google Kubernetes Engine
gcloud container clusters get-credentials {{cluster_name}}

# Update all gcloud CLI components
gcloud components update

# Show help for a given command
gcloud help {{command}}

# Debug an executable
gdb {{executable}}

# Attach a process to gdb
gdb -p {{procID}}

# Execute given GDB commands upon start
gdb -ex "{{commands}}" {{executable}}

# Start gdb and pass arguments
gdb --args {{executable}} {{argument1}} {{argument2}}

# Upload a local path to the parent folder with the specified id
gdrive upload -p {{id}} {{path/to/file_or_folder}}

# Download file or directory by id to current directory
gdrive download {{id}}

# Download to a given local path by its id
gdrive download --path {{path/to/folder}} {{id}}

# Create a new revision of an id using a given file or folder
gdrive update {{id}} {{path/to/file_or_folder}}

# Install latest version of a gem
gem install {{gemname}}

# Install specific version of a gem
gem install {{gemname}} -v {{1.0.0}}

# Update a gem
gem update {{gemname}}

# List all gems
gem list

# Uninstall a gem
gem uninstall {{gemname}}

# Connect to the main Ethereum network and automatically download the full node
geth

# Connect to the Ropsten test network
geth --testnet

# Create a new account
geth account new

# Enable mining
geth --mine

# Find and compile all modules in the current directory
ghc Main

# Compile a single file
ghc {{file.hs}}

# Compile using extra optimization
ghc -O {{file.hs}}

# Stop compilation after generating object files (.o)
ghc -c {{file.hs}}

# Run Haskell interactive interpreter (REPL)
ghci

# Evaluate a single expression
ghc -e {{expression}}

# List available boilerplates
gibo list

# Write a boilerplate to stdout
gibo dump {{boilerplate}}

# Write a boilerplate to .gitignore
gibo dump {{boilerplate}} >>{{.gitignore}}

# Search for boilerplates containing a given string
gibo search {{string}}

# Update available local boilerplates
gibo update

# Optimise a GIF
gifsicle --batch --optimize=3 {{amin.gif}}

# Make a GIF animation with gifsicle
gifsicle --delay={{10}} --loop *.gif > {{anim.gif}}

# Extract frames from an animation
gifsicle {{anim.gif}} '#0' > {{firstframe.gif}}

# You can also edit animations by replacing, deleting, or inserting frames
gifsicle -b {{anim.gif}} --replace '#0' {{new.gif}}

# Login in gist on this computer
gist --login

# Create a gist from any number of text files
gist {{file.txt}} {{file2.txt}}

# Create a private gist with a description
gist -p -d {{"A meaningful description"}} {{file.txt}} 

# Read contents from STDIN and create a gist from it
{{echo "hello world"}} | gist

# List your public and private gists
gist -l

# List all gists for the currently logged in user
gist -l {{user_name}}

# Use the id from the gist URL to modify or include a file
gist -u {{GIST_ID}} {{file.txt}}

# Add a file to the index
git add {{path/to/file}}

# Add all files (tracked and untracked)
git add -A

# Only add already tracked files
git add -u

# Also add ignored files
git add -f

# Add parts of a file interactively
git add -p {{path/to/file}}

# Apply a patch file
git am {{path/to/file.patch}}

# Abort the process of applying a patch file
git am --abort

# Apply as much of a patch file as possible, saving failed hunks to reject files
git am --reject {{path/to/file.patch}}

# Start a bisect session on a commit range bounded by a known buggy commit, and a known clean (typically older) one
git bisect start {{bad_commit}} {{good_commit}}

# For each commit that `git bisect` selects, mark it as "bad" or "good" after testing it for the issue
git bisect {{good|bad}}

# After `git bisect` pinpoints the faulty commit, end the bisect session and return to the previous branch
git bisect reset

# Skip a commit during a bisect (e.g. one that fails the tests due to a different issue)
git bisect skip

# Print file with author name and commit hash on each line
git blame {{file}}

# Print file with author email and commit hash on each line
git blame -e {{file}}

# List local branches. The current branch is highlighted by `*`
git branch

# List all branches (local and remote)
git branch -a

# Create new branch based on the current commit
git branch {{branch_name}}

# Rename a branch (must not have it checked out to do this)
git branch -m {{old_branch_name}} {{new_branch_name}}

# Delete a local branch
git branch -d {{branch_name}}

# Create and switch to a new branch
git checkout -b {{branch_name}}

# Create and switch to a new branch based on a specific reference (branch, remote/branch, tag are examples of valid references)
git checkout -b {{branch_name}} {{reference}}

# Switch to an existing local branch
git checkout {{branch_name}}

# Switch to an existing remote branch
git checkout --track {{remote_name}}/{{branch_name}}

# Discard all unstaged changes in the current folder (see `git reset` for more undo-like commands)
git checkout .

# Discard unstaged changes to a given file
git checkout {{file_name}}

# Replace a file in the current folder with the version of it committed in a given branch
git checkout {{branch_name}} -- {{file_name}}

# Apply a commit to the current branch
git cherry-pick {{commit}}

# Apply a range of commits to the current branch (see also `git rebase --onto`)
git cherry-pick {{start_commit}}~..{{end_commit}}

# Apply multiple (non-sequential) commits to the current branch
git cherry-pick {{commit_1}} {{commit_2}}

# Delete files that are not tracked by git
git clean

# Interactively delete files that are not tracked by git
git clean -i

# Show what files would be deleted without actually deleting them
git clean --dry-run

# Forcefully delete files that are not tracked by git
git clean -f

# Forcefully delete directories that are not tracked by git
git clean -fd

# Delete untracked files, including ignored files in `.gitignore` and `.git/info/exclude`
git clean -x

# Clone an existing repository
git clone {{remote_repository_location}}

# Clone an existing repository and its submodules
git clone --recursive {{remote_repository_location}}

# For cloning from the local machine
git clone -l

# Do it quietly
git clone -q

# Clone an existing repository, and truncate to the specified number of revisions, save your time mostly
git clone --depth {{10}} {{remote_repository_location}}

# Commit staged files to the repository with a message
git commit -m {{message}}

# Auto stage all modified files and commit with a message
git commit -a -m {{message}}

# Replace the last commit with currently staged changes
git commit --amend

# List only local configuration entries (stored in `.git/config` in the current repository)
git config --list --local

# List only global configuration entries (stored in `~/.gitconfig`)
git config --list --global

# List all configuration entries that have been defined either locally or globally
git config --list

# Get the value of a given configuration entry
git config alias.unstage

# Set the global value of a given configuration entry
git config --global alias.unstage "reset HEAD --"

# Revert a global configuration entry to its default value
git config --global --unset alias.unstage

# Show unstaged, uncommitted changes
git diff

# Show all uncommitted changes (including staged ones)
git diff HEAD

# Show only staged (added, but not yet committed) changes
git diff --staged

# Show changes from all commits since a given date/time (a date expression, e.g. "1 week 2 days" or an ISO date)
git diff 'HEAD@{3 months|weeks|days|hours|seconds ago}'

# Show only names of changed files since a given commit
git diff --name-only {{commit}}

# Output a summary of file creations, renames and mode changes since a given commit
git diff --summary {{commit}}

# Create a patch file
git diff > {{target_file}}.patch

# Compare a single file between two branches or commits
git diff {{branch_1}}..{{branch_2}} [--] {{path/to/file}}

# Compare different files from the current branch to other branch
git diff {{branch}}:{{path/to/file2}} {{path/to/file}}

# Fetch the latest changes from the default remote upstream repository (if set)
git fetch

# Fetch new branches from a specific remote upstream repository
git fetch {{remote_name}}

# Fetch the latest changes from all remote upstream repositories
git fetch --all

# Also fetch tags from the remote upstream repository
git fetch --tags

# Delete local references to remote branches that have been deleted upstream
git fetch --prune

# Create an auto-named .patch file for all the unpushed commits
git format-patch {{origin}}

# Write a .patch file for all the commits between 2 revisions to stdout
git format-patch {{revision_1}}..{{revision_2}}

# Write a .patch file for the 3 latest commits
git format-patch -{{3}}

# Optimise the repository
git gc

# Aggressively optimise, takes more time
git gc --aggressive

# Do not prune loose objects (prunes by default)
git gc --no-prune

# Suppress all output
git gc --quiet

# View full usage
git gc --help

# Start imerge-based rebase (checkout the branch to be rebased, first)
git imerge rebase {{branch_to_rebase_onto}}

# Start imerge-based merge (checkout the branch to merge into, first)
git imerge merge {{branch_to_be_merged}}

# Show ASCII diagram of in-progress merge or rebase
git imerge diagram

# Continue imerge operation after resolving conflicts (`git add` the conflicted files, first)
git imerge continue --no-edit

# Wrap up imerge operation, after all conflicts are resolved
git imerge finish

# Abort imerge operation, and return to the previous branch
git-imerge remove && git checkout {{previous_branch}}

# Initialize a new local repository
git init

# Initialize a barebones repository, suitable for use as a remote over ssh
git init --bare

# Show the sequence of commits starting from the current one, in reverse chronological order
git log

# Show the history of a particular file or directory, including differences
git log -p {{path}}

# Show only the first line of each commit message
git log --oneline

# Show an overview of which file(s) changed in each commit
git log --stat

# Show all commits, tags and branches for the entire repo in a graph format
git log --oneline --decorate --all --graph

# Show only commits whose messages include a given string (case-insensitively)
git log -i --grep {{search_string}}

# Merge a branch with your current branch
git merge {{branch_name}}

# Edit the merge message
git merge -e {{branch_name}}

# Merge a branch and create a merge commit
git merge --no-ff {{branch_name}}

# Abort a merge in case of conflicts
git merge --abort

# Move file inside the repo and add the movement to the next commit
git mv {{path/to/file}} {{new/path/to/file}}

# Rename file and add renaming to the next commit
git mv {{filename}} {{new_filename}}

# Overwrite the file in the target path if it exists
git mv --force {{file}} {{target}}

# Download changes from default remote repository and merge it
git pull

# Download changes from default remote repository and use fast forward
git pull --rebase

# Download changes from given remote repository and branch, then merge them into HEAD
git pull {{remote_name}} {{branch}}

# Send local changes in the current branch to its remote counterpart
git push

# Send local changes in a given branch to its remote counterpart
git push {{remote_name}} {{local_branch}}

# Publish the current branch to a remote repository, setting the remote branch name
git push {{remote_name}} -u {{remote_branch}}

# Send changes on all local branches to their counterparts in a given remote repository
git push --all {{remote_name}}

# Delete a branch in a remote repository
git push {{remote_name}} --delete {{remote_branch}}

# Remove remote branches that don't have a local counterpart
git push --prune {{remote_name}}

# Publish tags that aren't yet in the remote repository
git push --tags

# Rebase the current branch on top of the master branch
git rebase {{master}}

# Start an interactive rebase, which allows the commits to be reordered, omitted, combined or modified
git rebase -i {{target_base_branch_or_commit_hash}}

# Continue a rebase that was interrupted by a merge failure, after editing conflicting files
git rebase --continue

# Abort a rebase in progress (e.g. if it is interrupted by a merge conflict)
git rebase --abort

# Move part of the current branch onto a new base, providing the old base to start from
git rebase --onto {{new_base}} {{old_base}}

# Reapply the last 5 commits in-place, stopping to allow them to be reordered, omitted, combined or modified
git rebase -i {{HEAD~5}}

# View reflog
git reflog

# View 5 latest entries in reflog
git reflog -n {{5}}

# Show a list of existing remotes, their names and URL
git remote -v

# Add a remote
git remote add {{remote_name}} {{remote_url}}

# Change the URL of a remote
git remote set-url {{remote_name}} {{new_url}}

# Remove a remote
git remote remove {{remote_name}}

# Rename a remote
git remote rename {{old_name}} {{new_name}}

# Unstage everything
git reset

# Unstage specific file(s)
git reset {{path/to/file(s)}}

# Unstage portions of a file
git reset -p {{path/to/file}}

# Undo the last commit, keeping its changes (and any further uncommitted changes) in the filesystem
git reset HEAD~

# Undo the last two commits, adding their changes to the index, i.e. staged for commit
git reset --soft HEAD~2

# Discard any uncommitted changes, staged or not (for only unstaged changes, use `git checkout`)
git reset --hard

# Reset the repository to a given commit, discarding committed, staged and uncommitted changes since then
git reset --hard {{commit}}

# Remove file from repository index and filesystem
git rm {{file}}

# Remove directory
git rm -r {{directory}}

# Remove file from repository index but keep it untouched locally
git rm --cached {{file}}

# View a summary of all the commits made, grouped alphabetically by author name
git shortlog

# View a summary of all the commits made, sorted by the number of commits made
git shortlog -n

# View a summary of all the commits made, grouped by the commiter identities (name and email)
git shortlog -c

# View a summary of the last 5 commits (i.e. specify a revision range)
git shortlog HEAD~{{5}}..HEAD

# Show information about the latest commit (message, changes, and other metadata)
git show

# Show information about a given commit
git show {{commit}}

# Show information about the commit associated with a given tag
git show {{tag}}

# Show information about the 3rd commit from the tip of a branch
git show {{branch}}~{{3}}

# Show a commit's hash and message in a single line, suppressing the diff output
git show --oneline -s {{commit}}

# Report only statistics that have a level of concern greater than 0
git sizer

# Report all statistics
git sizer -v

# See additional options
git sizer -h

# Stash current changes, except new (untracked) files
git stash [save {{optional_stash_message}}]

# Stash current changes, including new (untracked) files
git stash -u

# Interactively select parts of changed files for stashing
git stash -p

# List all stashes (shows stash name, related branch and message)
git stash list

# Apply a stash (default is the latest, named stash@{0})
git stash apply {{optional_stash_name_or_commit}}

# Apply a stash (default is stash@{0}), and remove it from the stash list if applying doesn't cause conflicts
git stash pop {{optional_stash_name}}

# Drop a stash (default is stash@{0})
git stash drop {{optional_stash_name}}

# Drop all stashes
git stash clear

# Show changed files which are not yet added for commit
git status

# Give output in short format
git status -s

# Install a repository's specified submodules
git submodule update --init --recursive

# Add a git repository as a submodule
git submodule add {{repository_url}}

# Add a git repository as a submodule at the specified directory
git submodule add {{repository_url}} {{path/to/directory}}

# Update every submodule to its latest commit
git submodule foreach git pull

# Clone an SVN repository
git svn clone {{https://example.com/subversion_repo}} {{local_dir}}

# Clone a SVN repository starting at a given revision number
git svn clone -r{{1234}}:HEAD {{https://svn.example.net/subversion/repo}} {{local_dir}}

# Update local clone from the remote SVN repository
git svn rebase

# Fetch updates from the remote SVN repository without changing the git HEAD
git svn fetch

# Commit back to the SVN repository
git svn dcommit

# List all tags
git tag

# Create a tag with the given name pointing to the current commit
git tag {{tag_name}}

# Create a tag with the given name pointing to a given commit
git tag {{tag_name}} {{commit}}

# Create an annotated tag with the given message
git tag {{tag_name}} -m {{tag_message}}

# Delete the tag with the given name
git tag -d {{tag_name}}

# Get updated tags from upstream
git fetch --tags

# List all tags whose ancestors include a given commit
git tag --contains {{commit}}

# Create a new folder with the specified branch checked out into it
git worktree add {{path/to/folder}} {{branch}}

# Create a new folder with a new branch checked out into it
git worktree add {{path/to/folder}} -b {{new_branch}}

# List all the working directories attached to this repository
git worktree list

# Remove a worktree (after deleting worktree folder)
git worktree prune

# Check the Git version
git --version

# Call general help
git --help

# Call help on a command
git help {{command}}

# Execute Git command
git {{command}}

# Show the repository browser for the current git repository
gitk

# Show repository browser for a specific file or folder
gitk {{path/to/file_or_folder}}

# Show commits made since 1 week ago
gitk --since={{"1 week ago"}}

# Show commits older than 1/1/2016
gitk --until={{"1/1/2015"}}

# Show at most 100 changes in all branches
 gitk --max-count={{100}} --all

# Enter the gitsome shell (optional), to enable autocompletion and interactive help for git (and gh) commands
gitsome

# Setup GitHub integration with the current account
gh configure

# List notifications for the current account (as would be seen in https://github.com/notifications)
gh notifications

# List the current account's starred repos, filtered by a given search string
gh starred "{{python 3}}"

# View the recent activity feed of a given GitHub repository
gh feed {{tldr-pages/tldr}}

# View the recent activity feed for a given GitHub user, using the default pager (e.g. `less`)
gh feed {{torvalds}} -p

# Run in terminal
glances

# Run in web server mode to show results in browser
glances -w

# Run in server mode to allow connections from other Glances clients
glances -s

# Connect to a Glances server
glances -c {{hostname}}

# Require a password in (web) server mode
glances -s --password

# Use UNIX (or DOS) pipes to pipe the stdout of any command through gnomon
{{npm test}} | gnomon

# Show number of seconds since the start of the process
{{npm test}} | gnomon --type=elapsed-total

# Show an absolute timestamp in UTC
{{npm test}} | gnomon --type=absolute

# Set a high threshold of 0.5 seconds for the elapsed time; exceeding which the timestamp will be colored bright red
{{npm test}} | gnomon --high {{0.5}}

# Set a medium threshold of 0.2 seconds (Timestamp will be colored bright yellow)
{{npm test}} | gnomon --medium {{0.2}}

# Start the interactive graph plotting shell
gnuplot

# Plot the graph for the specified graph definition file
gnuplot {{path/to/definition.plt}}

# Set the output format by executing a command before loading the definition file
gnuplot -e "{{set output "path/to/filename.png" size 1024,768}}" {{path/to/definition.plt}}

# Persist the graph plot preview window after gnuplot exits
gnuplot --persist {{path/to/definition.plt}}

# Download and install a package, specified by its import path
go get {{package_path}}

# Compile and run a source file (it has to contain a `main` package)
go run {{file}}.go

# Compile a source file into a named executable
go build -o {{executable}} {{file}}.go

# Compile the package present in the current directory
go build

# Execute all test cases of the current package (files have to end with `_test.go`)
go test

# Compile and install the current package
go install

# Initialize an encrypted filesystem
gocryptfs -init {{path/to/cipher_dir}}

# Mount an encrypted filesystem
gocryptfs {{path/to/cipher_dir}} {{path/to/mount_point}}

# Mount with the explicit master key instead of password
gocryptfs --masterkey {{path/to/cipher_dir}} {{path/to/mount_point}}

# Change the password
gocryptfs --passwd {{path/to/cipher_dir}}

# Make an encrypted snapshot of a plain directory
gocryptfs --reverse {{path/to/plain_dir}} {{path/to/cipher_dir}}

# Display help for package "fmt"
godoc {{fmt}}

# Display help for the function "Printf" of "fmt" package
godoc {{fmt}} {{Printf}}

# Serve documentation as a web server on port "6060"
godoc -http=:{{6060}}

# Create an index file
godoc -write_index -index_files={{path/to/file}}

# Use the given index file to search the docs
godoc -http=:{{6060}} -index -index_files={{path/to/file}}

# Run a project if the current directory contains a `project.godot` file, otherwise open the project manager
godot

# Edit a project (the current directory must contain a `project.godot` file)
godot -e

# Open the project manager even if the current directory contains a `project.godot` file
godot -p

# Export a project for a given target (the target must be defined in the project)
godot --export {{target}}

# Execute a standalone GDScript file
godot -s {{script.gd}}

# Format a file and display the result to the console
gofmt {{source.go}}

# Format a file, overwriting the original file in-place
gofmt -w {{source.go}}

# Format a file, and then simplify the code, overwriting the original file
gofmt -s -w {{source.go}}

# Print all (including spurious) errors
gofmt -e {{source.go}}

# Run gource in a directory (if it isn't the repository's root directory, the root is seeked up from there)
gource {{path/to/repository}}

# Run gource in the current directory, with a custom output resolution
gource -{{width}}x{{height}}

# Set a custom time scale for the animation
gource -c {{time_scale_multiplier}}

# Set how long each day should be in the animation (this combines with -c, if provided)
gource -s {{seconds}}

# Set fullscreen mode and a custom background color
gource -f -b {{hex_color_code}}

# Set a title for the animation
gource --title {{title}}

# Encrypt a directory into archive.gpg using a passphrase
gpg-zip --symmetric --output {{archive.gpg}} {{path/to/directory}}

# Decrypt archive.gpg into a directory of the same name
gpg-zip --decrypt {{path/to/archive.gpg}}

# List the contents of the encrypted archive.gpg
gpg-zip --list-archive {{path/to/archive.gpg}}

# Sign doc.txt without encryption (writes output to doc.txt.asc)
gpg --clearsign {{doc.txt}}

# Encrypt doc.txt for alice@example.com (output to doc.txt.gpg)
gpg --encrypt --recipient {{alice@example.com}} {{doc.txt}}

# Encrypt doc.txt with only a passphrase (output to doc.txt.gpg)
gpg --symmetric {{doc.txt}}

# Decrypt doc.txt.gpg (output to STDOUT)
gpg --decrypt {{doc.txt.gpg}}

# Import a public key
gpg --import {{public.gpg}}

# Export public key for alice@example.com (output to STDOUT)
gpg --export --armor {{alice@example.com}}

# Export private key for alice@example.com (output to STDOUT)
gpg --export-secret-keys --armor {{alice@example.com}}

# Compile a package
gradle build

# Exclude test task
gradle build -x {{test}}

# Run in offline mode to prevent gradle from accessing the network during builds
gradle build --offline

# Clear the build folder
gradle clean

# Compile and Release package
gradle assembleRelease

# Search for an exact string
grep {{search_string}} {{path/to/file}}

# Search in case-insensitive mode
grep -i {{search_string}} {{path/to/file}}

# Search recursively (ignoring non-text files) in current directory for an exact string
grep -RI {{search_string}} .

# Use extended regular expressions (supporting `?`, `+`, `{}`, `()` and `|`)
grep -E {{^regex$}} {{path/to/file}}

# Print 3 lines of [C]ontext around, [B]efore, or [A]fter each match
grep -{{C|B|A}} 3 {{search_string}} {{path/to/file}}

# Print file name with the corresponding line number for each match
grep -Hn {{search_string}} {{path/to/file}}

# Use the standard input instead of a file
cat {{path/to/file}} | grep {{search_string}}

# Invert match for excluding specific strings
grep -v {{search_string}}

# Render a man page as plain text, and display the result
groff -man -T utf8 {{manpage.1}}

# Render a man page using the ASCII output device, and display it using a pager
groff -man -T ascii {{manpage.1}} | less

# Render a man page into an HTML file
groff -man -T html {{manpage.1}} > {{page.html}}

# Process a roff file using the `tbl` and `pic` preprocessors, and the `me` macro set
groff -t -p -me -T utf8 {{foo.me}}

# Run a `groff` command with preprocessor and macro options guessed by the `grog` utility
eval "$(grog -T utf8 {{foo.me}})"

# Print group memberships for the current user
groups

# Print group memberships for a specific user
groups {{username}}

# Print group memberships for a list of users
groups {{username1}} {{username2}} {{username3}}

# Run the default task process
grunt

# Run one or more specific space-separated task(s)
grunt {{task_name}}

# Specify an alternative configuration file
grunt --gruntfile {{path/to/file}}

# Specify an alternative base path for relative files
grunt --base {{path/to/directory}}

# Specify an additional directory to scan for tasks in
grunt --tasks {{path/to/directory}}

# Perform a dry-run without writing any files
grunt --no-write

# List all available options
grunt --help

# Show the system stats dashboard
gtop

# Sort by CPU usage
c

# Sort by memory usage
m

# Compress a JPEG image
guetzli {{input.jpg}} {{output.jpg}}

# Create compressed JPEG image from PNG image
guetzli {{input.png}} {{output.jpg}}

# Compress a JPEG image with desired visual quality (84-100)
guetzli --quality {{quality_value}} {{input.jpg}} {{output.jpg}}

# Start the Guile Scheme REPL
guile

# Execute the script in a given Scheme file
guile {{script.scm}}

# Execute a Scheme expression
guile -c "{{expression}}"

# Listen on a port or a Unix domain socket (the default is port 37146) for remote REPL connections
guile --listen={{port_or_socket}}

# Run the default task
gulp

# Run individual tasks
gulp {{task}} {{othertask}}

# Extract a file from an archive, replacing the original file if it exists
gunzip {{archive.tar.gz}}

# Extract a file to a target destination
gunzip -c {{archive.tar.gz}} > {{archive.tar}}

# List the contents of a compressed file
gunzip -l {{file.txt.gz}}

# Compress a file, replacing it with a gzipped compressed version
gzip {{file.ext}}

# Decompress a file, replacing it with the original uncompressed version
gzip -d {{file.ext}}.gz

# Compress a file specifying the output filename
gzip -c {{file.ext}} > {{compressed_file.ext.gz}}

# Uncompress a gzipped file specifying the output filename
gzip -c -d {{file.ext}}.gz > {{uncompressed_file.ext}}

# Specify the compression level. 1=Fastest (Worst), 9=Slowest (Best), Default level is 6
gzip -9 -c {{file.ext}} > {{compressed_file.ext.gz}}

# Convert a video file to MKV (AAC 160kbit audio and x264 CRF20 video)
handbrakecli -i {{input.avi}} -o {{output.mkv}} -e x264 -q 20 -B 160

# Resize a video file to 320x240
handbrakecli -i {{input.mp4}} -o {{output.mp4} -w 320 -l 240

# List available presets
handbrakecli --preset-list

# Convert an AVI video to MP4 using the Android preset
handbrakecli --preset="Android" -i {{input.ext}} -o {{output.mp4}}

# Start hangups
hangups

# View troubeshooting information and help
hangups -h

# Set a refresh token for hangups
hangups --token-path {{/path/to/token}}

# Search for a Haxe library
haxelib search {{keyword}}

# Install a Haxe library
haxelib install {{libname}}

# Upgrade all installed Haxe libraries
haxelib upgrade

# Install the development version of a library from a Git repository
haxelib git {{libname}} {{git_url}}

# Output the first few lines of a file
head -n {{count_of_lines}} {{filename}}

# Output the first few bytes of a file
head -c {{size_in_bytes}} {{filename}}

# Output everything but the last few lines of a file
head -n -{{count_of_lines}} {{filename}}

# Output everything but the last few bytes of a file
head -c -{{size_in_bytes}} {{filename}}

# Create a helm chart
helm create {{chart_name}}

# Add a new helm repository
helm repo add {{repo_name}}

# List helm repositories
helm repo list

# Update helm repositories
helm repo update

# Delete a helm repository
helm repo remove {{repo_name}}

# Install a helm chart
helm install {{repo_name}}/{{chart_name}}

# Download helm chart as a tar archive
helm get {{chart_release_name}}

# Update helm dependencies
helm dependency update

# Generate a man page for an executable
help2man {{executable}}

# Specify the "name" paragraph in the man page
help2man {{executable}} --name {{name}}

# Specify the section for the man page (defaults to 1)
help2man {{executable}} --section {{section}}

# Output to a file instead of stdout
help2man {{executable}} --output {{path/to/file}}

# Display detailed help
help2man --help

# Login to your heroku account
heroku login

# Create a heroku app
heroku create

# Show logs for an app
heroku logs --app {{app_name}}

# Run a one-off process inside a dyno (Heroku virtual machine)
heroku run {{process_name}} --app {{app_name}}

# List dynos (Heroku virtual machines) for an app
heroku ps --app {{app_name}}

# Permanently destroy an app
heroku destroy --app {{app_name}}

# Add files or directories to the staging area
hg add {{path/to/file}}

# Add all unstaged files matching a specified pattern
hg add --include {{pattern}}

# Add all unstaged files, excluding those that match a specified pattern
hg add --exclude {{pattern}}

# Recursively add sub-repositories
hg add --subrepos

# Perform a test-run without performing any actions
hg add --dry-run

# Show the name of the currently active branch
hg branch

# Create a new branch for the next commit
hg branch {{branch_name}}

# Clone a repository to a specified directory
hg clone {{remote_repository_source}} {{destination_path}}

# Clone a repository to the head of a specific branch, ignoring later commits
hg clone --branch {{branch}} {{remote_repository_source}}

# Clone a repository with only the ".hg" directory, without checking out files
hg clone --noupdate {{remote_repository_source}}

# Clone a repository to a specific revision, tag or branch, keeping the entire history
hg clone --updaterev {{revision}} {{remote_repository_source}}

# Clone a repository up to a specific revision without any newer history
hg clone --rev {{revision}} {{remote_repository_source}}

# Commit staged files to the repository
hg commit

# Commit a specific file or directory
hg commit {{path/to/file}}

# Commit with a specific message
hg commit --message {{message}}

# Commit all files matching a specified pattern
hg commit --include {{pattern}}

# Commit all files, excluding those that match a specified pattern
hg commit --exclude {{pattern}}

# Commit using the interactive mode
hg commit --interactive

# Initialise a new repository in the current directory
hg init

# Initialise a new repository in the specified directory
hg init {{path/to/directory}}

# Display the entire revision history of the repository
hg log

# Display the revision history with an ASCII graph
hg log --graph

# Display the revision history with file names matching a specified pattern
hg log --include {{pattern}}

# Display the revision history, excluding file names that match a specified pattern
hg log --exclude {{pattern}}

# Display the log information for a specific revision
hg log --rev {{revision}}

# Display the revision history for a specific branch
hg log --branch {{branch}}

# Display the revision history for a specific date
hg log --date {{date}}

# Display revisions committed by a specific user
hg log --user {{user}}

# Pull from the "default" source path
hg pull

# Pull from a specified source repository
hg pull {{path/to/source_repository}}

# Update the local repository to the head of the remote
hg pull --update

# Pull changes even when the remote repository is unrelated
hg pull --force

# Specify a specific revision changeset to pull up to
hg pull --rev {{revision}}

# Specify a specific branch to pull
hg pull --branch {{branch}}

# Specify a specific bookmark to pull
hg pull --bookmark {{bookmark}}

# Push changes to the "default" remote path
hg push

# Push changes to a specified remote repository
hg push {{path/to/destination_repository}}

# Push a new branch if it does not exist (disabled by default)
hg push --new-branch

# Specify a specific revision changeset to push
hg push --rev {{revision}}

# Specify a specific branch to push
hg push --branch {{branch}}

# Specify a specific bookmark to push
hg push --bookmark {{bookmark}}

# Remove files or directories from the staging area
hg remove {{path/to/file}}

# Remove all staged files matching a specified pattern
hg remove --include {{pattern}}

# Remove all staged files, excluding those that match a specified pattern
hg remove --exclude {{pattern}}

# Recursively remove sub-repositories
hg remove --subrepos

# Remove files from the repository that have been physically removed
hg remove --after

# Start a web server instance
hg serve

# Start a web server instance on the specified port
hg serve --port {{port}}

# Start a web server instance on the specified listening address
hg serve --address {{address}}

# Start a web server instance with a specific identifier
hg serve --name {{name}}

# Start a web server instance using the specified theme (see the templates directory)
hg serve --style {{style}}

# Start a web server instance using the specified SSL certificate bundle
hg serve --certificate {{path/to/certificate}}

# Update to the tip of the current branch
hg update

# Update to the specified revision
hg update --rev {{revision}}

# Update and discard uncommitted changes
hg update --clean

# Update to the last commit matching a specified date
hg update --date {{dd-mm-yyyy}}

# Execute Mercurial command
hg {{command}}

# Call general help
hg help

# Call help on a command
hg help {{command}}

# Check the Mercurial version
hg --version

# Display the commands history list with line numbers
history

# Clear the commands history list (only for current `bash` shell)
history -c

# Overwrite history file with history of current `bash` shell (often combined with `history -c` to purge history)
history -w

# View stories on Hacker News
hn

# View _number_ of stories on Hacker News
hn --limit {{number}}

# View stories on Hacker News, and keep the list open after selecting a link
hn --keep-open

# View stories on Hacker News sorted by submission date
hn --latest

# Lookup A, AAAA, and MX records of a domain
host {{domain}}

# Lookup a field (CNAME, TXT,...) of a domain
host -t {{field}} {{domain}}

# Reverse lookup an IP
host {{ip_address}}

# Specify an alternate DNS server to query
host {{domain}} {{8.8.8.8}}

# Display the numeric identifier for the current host in hexadecimal
hostid

# Print a horizontal rule
hr

# Print a horizontal rule with a custom string
hr {{string}}

# Print a multiline horizontal rule
hr {{string_a}} {{string_b}} {{string_c}}

# Create/overwrite htpasswd file
htpasswd -c {{path/to/file}} {{user_name}}

# Add user to htpasswd file or update existing user
htpasswd {{path/to/file}} {{user_name}}

# Add user to htpasswd file in batch mode without an interactive password prompt (for script usage)
htpasswd -b {{path/to/file}} {{user_name}} {{password}}

# Delete user from htpasswd file
htpasswd -D {{path/to/file}} {{user_name}}

# Verify user password
htpasswd -v {{path/to/file}} {{user_name}}

# Download a URL to a file
http -d {{example.org}}

# Send form-encoded data
http -f {{example.org}} {{name='bob'}} {{profile_picture@'bob.png'}}

# Send JSON object
http {{example.org}} {{name='bob'}}

# Specify an HTTP method
http {{HEAD}} {{example.org}}

# Include an extra header
http {{example.org}} {{X-MyHeader:123}}

# Pass a user name and password for server authentication
http -a {{username:password}} {{example.org}}

# Specify raw request body via stdin
cat {{data.txt}} | http PUT {{example.org}}

# Clone a repository you own, using just the repository name rather than the full URL
hub clone {{repo_name}}

# Clone another user's repository, using their github username and the repository name
hub clone {{username}}/{{repo_name}}

# Create a fork of the current repository (cloned from another user) under your github profile
hub fork

# Create a PR of the current branch in the original repository (after pushing the branch to github)
hub pull-request

# Upload the current (local-only) repository to your github account
hub create

# Create a new Hugo site
hugo new site {{path/to/site}}

# Create a new Hugo theme (themes may also be downloaded from https://themes.gohugo.io/)
hugo new theme {{theme_name}}

# Create a new page
hugo new {{section_name}}/{{filename}}

# Build a site to the `./public/` directory
hugo

# Build a site including pages that are marked as a "draft"
hugo --buildDrafts

# Build a site to a given directory
hugo --destination {{path/to/destination}}

# Build a site, start up a webserver to serve it, and automatically reload when pages are edited
hugo server

# Run a basic benchmark, performing at least 10 runs
hyperfine '{{make}}'

# Run a comparative benchmark
hyperfine '{{make target1}}' '{{make target2}}'

# Change minimum number of benchmarking runs
hyperfine --min-runs {{7}} '{{make}}'

# Perform benchmark with warmup
hyperfine --warmup {{5}} '{{make}}'

# Run a command before each benchmark run (to clear caches, etc.)
hyperfine --prepare '{{make clean}}' '{{make}}'

# Run a benchmark where a single parameter changes for each run
hyperfine --prepare '{{make clean}}' --parameter-scan num_threads {{1}} {{10}} '{{make -j {num_threads}}}'

# Convert file to a specific encoding, and print to stdout
iconv -f {{from_encoding}} -t {{to_encoding}} {{input_file}}

# Convert file to the current locale's encoding, and output to a file
iconv -f {{from_encoding}} {{input_file}} > {{output_file}}

# List supported encodings
iconv -l

# Display the current user identity as a number
id -u

# Display the current group identity as a number
id -g

# Set artist and title tag of an MP3 file
id3tag --artist={{artist}} --title={{title}} {{path/to/file.mp3}}

# Set album title of all MP3 files in the current directory
id3tag --album={{album}} {{*.mp3}}

# Get more help
id3tag --help

# Echo a different thing depending on a command's success
{{command}} && echo "success" || echo "failure"

# Full if syntax
if {{condition}}; then echo "true"; else echo "false"; fi

# View network settings of an ethernet adapter
ifconfig eth0

# Display details of all interfaces, including disabled interfaces
ifconfig -a

# Disable eth0 interface
ifconfig eth0 down

# Enable eth0 interface
ifconfig eth0 up

# Assign IP address to eth0 interface
ifconfig eth0 {{ip_address}}

# Create a new React Native project
ignite new {{project_name}}

# Generate file from a plugin
ignite generate {{plugin_name}} {{file_name}}

# Add an Ignite plugin to the project
ignite add {{plugin_name}}

# Remove an Ignite plugin from the project
ignite remove {{plugin_name}}

# Synchronize imap account between host1 and host2
imapsync --host1 {{host1}} --user1 {{user1}} --password1 {{secret1}} --host2 {{host2}} --user2 {{user2}} --password2 {{secret2}}

# Capture the entire X server screen in the PostScript image format
import -window root {{output.postscript}}

# Capture contents of a remote X server screen in the PNG image format
import -window root -display {{remote_host}}:{screen}.{display} {{output.png}}

# Capture a specific window, given its ID as displayed by `xwininfo`, into the JPEG format
import -window {{window_id}} {{output.jpg}}

# Convert an XLS file to CSV
in2csv {{data.xls}}

# Convert a DBF file to a CSV file
in2csv {{data.dbf}} > {{data.csv}}

# Convert a specific sheet from an XLSX file to CSV
in2csv --sheet={{sheet_name}} {{data.xlsx}}

# Pipe a JSON file to in2csv
cat {{data.json}} | in2csv -f json > {{data.csv}}

# Open an SVG file in the Inkscape GUI
inkscape {{filename.svg}}

# Export an SVG file into a bitmap with the default format (PNG) and the default resolution (90 DPI)
inkscape {{filename.svg}} -e {{filename.png}}

# Export an SVG file into a bitmap of 600x400 pixels (aspect ratio distortion may occur)
inkscape {{filename.svg}} -e {{filename.png}} -w {{600}} -h {{400}}

# Export a single object, given its ID, into a bitmap
inkscape {{filename.svg}} -i {{id}} -e {{object.png}}

# Export an SVG document to PDF, converting all texts to paths
inkscape {{filename.svg}} --export-pdf={{filename.pdf}} --export-text-to-path

# Duplicate the object with id="path123", rotate the duplicate 90 degrees, save the file, and quit Inkscape
inkscape {{filename.svg}} --select=path123 --verb=EditDuplicate --verb=ObjectRotate90 --verb=FileSave --verb=FileQuit

# Copy files to destination
install {{path/to/source}} {{path/to/destination}}

# Copy files to destination, setting their ownership
install -o {{user}} {{path/to/source}} {{path/to/destination}}

# Copy files to destination, setting their group ownership
install -g {{user}} {{path/to/source}} {{path/to/destination}}

# Copy files to destination, setting their `mode`
install -m {{+x}} {{path/to/source}} {{path/to/destination}}

# Copy files and apply access/modification times of source to destination
install -p {{path/to/source}} {{path/to/destination}}

# Set I/O scheduling class of a running process
ionice -c {{scheduling_class}} -p {{pid}}

# Run a command with custom I/O scheduling class and priority
ionice -c {{scheduling_class}} -n {{priority}} {{command}}

# Print the I/O scheduling class and priority of a running process
ionice -p {{pid}}

# Show disk I/O latency using the default values and the current directory
ioping .

# Measure latency on /tmp using 10 requests of 1 megabyte each
ioping -c 10 -s 1M /tmp

# Measure disk seek rate on /dev/sda
ioping -R /dev/sda

# Measure disk sequential speed on /dev/sda
ioping -RL /dev/sda

# Specific information about the Message Queue which has the id 32768
ipcs -qi 32768

# General information about all the IPC
ipcs -a

# Run on server
iperf -s

# Run on client
iperf -c {{server_address}}

# Run on client with 5 parallel threads
iperf -c {{server_address}} -P {{5}}

# Run iperf3 as a server
iperf3 -s

# Run an iperf3 server on a specific port
iperf3 -s -p {{port}}

# Start bandwidth test
iperf3 -c {{server}}

# Run iperf3 in multiple parallel streams
iperf3 -c {{server}} -P {{streams}}

# Reverse direction of the test. Server sends data to the client
iperf3 -c {{server}} -R

# Add a file from local to the file system, pin it and print the relative hash
ipfs add {{filename}}

# Add a folder and its files recursively from local to the file system and print the relative hash
ipfs add -r {{folder}}

# Save a remote file and give it a name but not pin it
ipfs get {{hash}} -o {{filename}}

# Pin a remote file locally
ipfs pin add {{hash}}

# Display pinned files
ipfs pin ls

# Unpin a file from the local storage
ipfs pin rm {{hash}}

# Remove unpinned files from local storage
ipfs repo gc

# Open irssi and connect to a server with a nickname
irssi -n {{nickname}} -c {{server.name.com}}

# Open irssi and connect with a specific server on a given port
irssi -c {{server.name.com}} -p {{port}}

# View the help
irssi --help

# Join a channel
/join {{#channelname}}

# Change active window (starts at 1)
/win {{window_number}}

# Exit the application cleanly and quitting any server(s)
/quit

# Unzip .jar/.war file to the current directory
jar -xvf {{file.jar}}

# List a .jar/.war file content
jar tf {{path/to/file.jar}}

# List a .jar/.war file content with verbose output
jar tvf {{path/to/file.jar}}

# Execute a java .class file that contains a main method by using just the class name
java {{classname}}

# Execute a .jar program
java -jar {{filename.jar}}

# Display JDK, JRE and HotSpot versions
java -version

# Compile a .java file
javac {{file.java}}

# Compile several .java files
javac {{file1.java}} {{file2.java}} {{file3.java}}

# Compile all .java files in current directory
javac {{*.java}}

# Compile a .java file and place the resulting class file in a specific directory
javac -d {{path/to/some/directory}} {{file.java}}

# Generate a development server that will run at http://localhost:4000/
jekyll serve

# Enable incremental regeneration
jekyll serve --incremental

# Generate the current folder into "./_site"
jekyll build

# Analyze a heap dump (from jmap), view via http on port 7000
jhat {{dump_file.bin}}

# Analyze a heap dump, specifying an alternate port for the http server
jhat -p {{port}} {{dump_file.bin}}

# Analyze a dump letting jhat use up to 8GB RAM (2-4x dump size recommended)
jhat -J-mx8G {{dump_file.bin}}

# Print shared object mappings for a java process (output like pmap)
jmap {{java_pid}}

# Print heap summary information
jmap -heap {{filename.jar}} {{java_pid}}

# Print histogram of heap usage by type
jmap -histo {{java_pid}}

# Dump contents of the heap into a binary file for analysis with jhat
jmap -dump:format=b,file={{filename}} {{java_pid}}

# Show status of all jobs
jobs

# Show status of a particular job
jobs {{job_id}}

# Show status and process IDs of all jobs
jobs -l

# Show process IDs of all jobs
jobs -p

# Join two files on the first (default) field
join {{file1}} {{file2}}

# Join field3 of file1 with field1 of file2
join -1 3 -2 1 {{file1}} {{file2}}

# Produce a line for each unpairable line for file1
join -a 1 {{file1}} {{file2}}

# Optimise a set of JPEG images, retaining all associated data
jpegoptim {{image1.jpeg}} {{image2.jpeg}} {{imageN.jpeg}}

# Optimise JPEG images, stripping all non-essential data
jpegoptim --strip-all {{image1.jpeg}} {{image2.jpeg}} {{imageN.jpeg}}

# Force the output images to be progressive
jpegoptim --all-progressive {{image1.jpeg}} {{image2.jpeg}} {{imageN.jpeg}}

# Force the output images to have a fixed maximum filesize
jpegoptim --size={{250k}} {{image1.jpeg}} {{image2.jpeg}} {{imageN.jpeg}}

# List all JVM processes
jps

# List all JVM processes with only PID
jps -q

# Display the arguments passed to the processes
jps -m

# Display the full package name of all processes
jps -l

# Display the arguments passed to the JVM
jps -v

# Output a JSON file, in pretty-print format
jq . {{file.json}}

# Output all elements from arrays (or all key-value pairs from objects) in a JSON file
jq .[] {{file.json}}

# Read JSON objects from a file into an array, and output it (inverse of `jq .[]`)
jq --slurp . {{file.json}}

# Output the first element in a JSON file
jq .[0] {{file.json}}

# Output the value of a given key of the first element in a JSON text from stdin
cat {{file.json}} | jq .[0].{{key_name}}

# Output the value of a given key of each element in a JSON text from stdin
cat {{file.json}} | jq 'map(.{{key_name}})'

# Insert a new entry with your editor
jrnl

# Quickly insert a new entry
jrnl {{today at 3am}}: {{title}}. {{content}}

# View the last ten entries
jrnl -n {{10}}

# View everything that happened from the start of last year to the start of last march
jrnl -from {{"last year"}} -until {{march}}

# Edit all entries tagged with "texas" and "history"
jrnl {{@texas}} -and {{@history}} --edit

# Convert JSON5 stdin to JSON stdout
echo {{input}} | json5

# Convert a JSON5 file to JSON and output to stdout
json5 {{path/to/input_file.json5}}

# Convert a JSON5 file to the specified JSON file
json5 {{path/to/input_file.json5}} --out-file {{path/to/output_file.json}}

# Validate a JSON5 file
json5 {{path/to/input_file.json5}} --validate

# Specify the number of spaces to indent by (or "t" for tabs)
json5 --space {{indent_amount}}

# View available options
json5 --help

# Print java stack traces for all threads in a java process
jstack {{java_pid}}

# Print mixed mode (java/c++) stack traces for all threads in a java process
jstack -m {{java_pid}}

# Print stack traces from java core dump
jstack {{/usr/bin/java}} {{file.core}}

# Start a Julia REPL session
julia

# Execute a Julia program and exit
julia {{program.jl}}

# Execute a Julia program that takes arguments
julia {{program.jl}} {{arguments}}

# Evaluate a string containing Julia code
julia -e '{{julia_code}}'

# Evaluate a string of Julia code, passing arguments to it
julia -e '{{for x in ARGS; println(x); end}}' {{arguments}}

# Start Julia in parallel mode, using N worker processes
julia -p {{N}}

# Start a Jupyter notebook server in the current directory
jupyter notebook

# Open a specific Jupyter notebook
jupyter notebook {{example.ipynb}}

# Start a server on a specific port
jupyter notebook --port={{port}}

# List currently running notebook servers
jupyter notebook list

# Stop the currently running server
jupyter notebook stop

# Start JupyterLab, if installed, in the current directory
jupyter lab

# Run load test locally
k6 run {{script.js}}

# Run load test locally with a given number of virtual users and duration
k6 run --vus {{10}} --duration {{30s}} {{script.js}}

# Run load test locally with a given environment variable
k6 run -e {{HOSTNAME=example.com}} {{script.js}}

# Run load test locally using InfluxDB to store results
k6 run --out influxdb={{http://localhost:8086/k6db}} {{script.js}}

# Login to cloud service using secret token
k6 login cloud --token {{secret}}

# Run load test on cloud infrastructure
k6 cloud {{script.js}}

# Consume messages starting with the newest offset
kafkacat -C -t {{topic}} -b {{brokers}}

# Consume messages starting with the oldest offset and exit after the last message is received
kafkacat -C -t {{topic}} -b {{brokers}} -o beginning -e

# Consume messages as a Kafka consumer group
kafkacat -G {{group_id}} {{topic}} -b {{brokers}}

# Publish message by reading from stdin
 echo {{message}} | kafkacat -P -t {{topic}} -b {{brokers}}

# Publish messages by reading from a file
kafkacat -P -t {{topic}} -b {{brokers}} {{path/to/file}}

# List metadata for all topics and brokers
kafkacat -L -b {{brokers}}

# List metadata for a specific topic
kafkacat -L -t {{topic}} -b {{brokers}}

# Get offset for a topic/partition for a specific point in time
kafkacat -Q -t {{topic}:{{partition}}:{{unix_timestamp}} -b {{brokers}}

# Open a file and enter normal mode, to execute commands
kak {{path/to/file}}

# Enter insert mode from normal mode, to write text into the file
i

# Escape insert mode, to go back to normal mode
<Escape>

# Replace all instances of "foo" in the current file with "bar"
%s{{foo}}<Enter>c{{bar}}<Escape>

# Un-select all secondary selections, and keep only the main one
<Space>

# Search for numbers and select the first two
/\d+<Enter>N

# Insert the contents of a file
!cat {{path/to/file}}<Enter>

# Save the current file
:w<Enter>

# Start KeePass 2, opening the most recently-opened password database
keepass2

# Start KeePass 2, opening a specific password database
keepass2 {{path/to/database.kbdx}}

# Use a specific key file to open a password database
keepass2 {{path/to/database.kbdx}} -keyfile:{{path/to/key/file.key}}

# Follow another user
keybase follow {{username}}

# Add a new proof
keybase prove {{service}} {{service_username}}

# Sign a file
keybase sign --infile {{input_file}} --outfile {{output_file}}

# Verify a signed file
keybase verify --infile {{input_file}} --outfile {{output_file}}

# Encrypt a file
keybase encrypt --infile {{input_file}} --outfile {{output_file}} {{receiver}}

# Decrypt a file
keybase decrypt --infile {{input_file}} --outfile {{output_file}}

# Revoke current device, log out, and delete local data
keybase deprovision

# Terminate a program using the default SIGTERM (terminate) signal
kill {{process_id}}

# List available signal names (to be used without the `SIG` prefix)
kill -l

# Terminate a program using the SIGHUP (hang up) signal. Many daemons will reload instead of terminating
kill -{{1|HUP}} {{process_id}}

# Terminate a program using the SIGINT (interrupt) signal. This is typically initiated by the user pressing `Ctrl + C`
kill -{{2|INT}} {{process_id}}

# Signal the operating system to immediately terminate a program (which gets no chance to capture the signal)
kill -{{9|KILL}} {{process_id}}

# Signal the operating system to pause a program, it until a SIGCONT ("continue") signal is received
kill -{{17|STOP}} {{process_id}}

# Terminate a process using the default SIGTERM (terminate) signal
killall {{process_name}}

# List available signal names (to be used without the 'SIG' prefix)
killall --list

# Interactively ask for confirmation before termination
killall -i {{process_name}}

# Terminate a process using the SIGINT (interrupt) signal, which is the same signal sent by pressing `Ctrl + C`
killall -INT {{process_name}}

# Force kill a process
killall -KILL {{process_name}}

# Create a Kubernetes master node
kubeadm init

# Bootstrap a Kubernetes worker node and join it to a cluster
kubeadm join --token {{token}}

# Create a new bootstrap token with a TTL of 12 hours
kubeadm token create --ttl {{12h0m0s}}

# Check if the Kubernetes cluster is upgradeable and which versions are available
kubeadm upgrade plan

# Upgrade Kubernetes cluster to a specified version
kubeadm upgrade apply {{version}}

# View the kubeadm ConfigMap containing the cluster's configuration
kubeadm config view

# Revert changes made to the host by 'kubeadm init' or 'kubeadm join'
kubeadm reset

# List all pods in all namespaces
kubectl get pods --all-namespaces

# List all pods with more information (such as node name)
kubectl get pods -o wide

# Update specified pod with the label 'unhealthy' and the value 'true'
kubectl label pods {{name}} unhealthy=true

# List all resources with different types
kubectl get all

# Show metrics for all nodes
kubectl top node

# Show metrics for all pods in the default namespace
kubectl top pod

# Print the address of the master and cluster services
kubectl cluster-info

# Create a new Laravel application
laravel new {{name}}

# Use the latest development release
laravel new {{name}} --dev

# Overwrite if the directory already exists
laravel new {{name}} --force

# List the available installer commands
laravel list

# View last logins, their duration  and other information as read from /var/log/wtmp
last

# Specify how many of the last logins to show
last -n {{login_count}}

# Print the full date and time for entries and then display the hostname column last to prevent truncation
last -F -a

# View all logins by a specific user and show the ip address instead of the hostname
last {{user_name}} -i

# View all recorded reboots (i.e., the last logins of the pseudo user "reboot")
last reboot

# View all recorded shutdowns (i.e., the last logins of the pseudo user "shutdown")
last shutdown

# Compile a dvi (DeVice Independent file) document from every source
latexmk

# Compile a dvi document from a specific source file
latexmk {{source.tex}}

# Compile a pdf document
latexmk -pdf {{source.tex}}

# Force the generation of a document even if there are errors
latexmk -f {{source.tex}}

# Clean up temporary tex files created for a specific tex file
latexmk -c {{source.tex}}

# Clean up all temporary tex files in the current directory
latexmk -c

# Set a reminder at a given time
leave {{time_to_leave}}

# Remind to leave at noon
leave {{1200}}

# Set a reminder in a specific amount of time
leave +{{amount_of_time}}

# Remind to leave in 4 hours and 4 minutes
leave +{{0404}}

# Display a list of the available transformations
lebab --help

# Transpile using one or more comma-separated transformations
lebab --transform {{transformation}}

# Transpile a file to stdout
lebab {{path/to/input_file}}

# Transpile a file to the specified output file
lebab {{path/to/input_file}} --out-file {{path/to/output_file}}

# Replace all `.js` files in-place in the specified directory, glob or file
lebab --replace {{directory|glob|file}}

# Generate scaffolding for a new project based on a template
lein new {{template_name}} {{project_name}}

# Start a REPL session either with the project or standalone
lein repl

# Run the project's "-main" function with optional args
lein run {{args}}

# Run the project's tests
lein test

# Package up the project files and all its dependencies into a jar file
lein uberjar

# Open a file
less {{source_file}}

# Page down / up
<Space> (down), b (up)

# Go to end / start of file
G (end), g (start)

# Forward search for a string (press `n`/`N` to go to next/previous match)
/{{something}}

# Backward search for a string (press `n`/`N` to go to next/previous match)
?{{something}}

# Follow the output of the currently opened file
F

# Open the current file in an editor
v

# Exit
q

# Generate an analyser from a Lex file
lex {{analyser.l}}

# Specify the output file
lex {{analyser.l}} --outfile {{analyser.c}}

# Compile a C file generated by Lex
cc {{path/to/lex.yy.c}} --output {{executable}}

# Print a license to stdout, using the defaults (auto-detected author name, and current year)
license {{license_name}}

# Generate a license and save it to a file
license -o {{filename}} {{license_name}}

# List all available licenses
license ls

# Generate a license with custom author name and year
license --name {{author}} --year {{release_year}} {{license_name}}

# Generate a new public/private key pair
light-arionum-cli

# Display the balance of the current address
light-arionum-cli balance

# Display the balance of the specified address
light-arionum-cli balance {{address}}

# Send a transaction with an optional message
light-arionum-cli send {{address}} {{value}} {{optional_message}}

# Export the current wallet information
light-arionum-cli export

# Display information about the current block
light-arionum-cli block

# Display information about the current address' transactions
light-arionum-cli transactions

# Display information about a specific transaction
light-arionum-cli transaction {{transaction_id}}

# Create a hard link from a new file to an existing file
link {{path/to/existing_file}} {{path/to/new_file}}

# Serve an index.html file and reload on changes
live-server

# Specify a port (default is 8080) from which to serve a file
live-server --port={{8081}}

# Specify a given file to serve
live-server --open={{about.html}}

# Proxy all requests for ROUTE to URL
live-server --proxy={{/}}:{{http:localhost:3000}}

# Create a symbolic link to a file (or folder)
ln -s {{path/to/file}} {{path/to/symlink}}

# Overwrite an existing symbolic to point to a different file
ln -sf {{path/to/new_file}} {{path/to/symlink}}

# Create a hard link to a file
ln {{path/to/file}} {{path/to/hardlink}}

# Print lines of code in the current directory
loc

# Print lines of code in the target directory
loc {{path/to/directory}}

# Print lines of code with stats for individual files
loc --files

# Print lines of code without .gitignore (etc.) files (e.g. two -u flags will additionally count hidden files and dirs)
loc -u

# Load-test "example.com" with web interface using locustfile.py
locust --host={{http://example.com}}

# Use a different test file
locust --locustfile={{test_file.py}} --host={{http://example.com}}

# Run test without web interface, spawning 1 user a second until there are 100 users
locust --no-web --clients={{100}} --hatch-rate={{1}} --host={{http://example.com}}

# Start locust in master mode
locust --master --host={{http://example.com}}

# Connect locust slave to master
locust --slave --host={{http://example.com}}

# Connect locust slave to master on a different machine
locust --slave --master-host={{master_hostname}} --host={{http://example.com}}

# Display the currently logged in user's name
logname

# Check validity of a logstash configuration
logstash --configtest --config {{logstash_config.conf}}

# Run logstash using configuration
sudo logstash --config {{logstash_config.conf}}

# Run logstash with the most basic inline configuration string
sudo logstash -e 'input {} filter {} output {}'

# Print the output of a command to the default printer (see `lpstat` command)
echo "test" | lp

# Print a file to the default printer
lp {{path/to/filename}}

# Print a file to a named printer (see `lpstat` command)
lp -d {{printer_name}} {{path/to/filename}}

# Print N copies of file to default printer (replace N with desired number of copies)
lp -n {{N}} {{path/to/filename}}

# Print only certain pages to the default printer (print pages 1, 3-5, and 16)
lp -P 1,3-5,16 {{path/to/filename}}

# Login to your LastPass account, by entering your master password when prompted
lpass login {{username}}

# Show login status
lpass status

# List all sites grouped by category
lpass ls

# Generate a new password for "gmail.com" with identifier "myinbox" and add to LastPass
lpass generate --username {{username}} --url {{gmail.com}} {{myinbox}} {{password_length}}

# Show password for a specified entry
lpass show {{myinbox}} --password

# List printers present on the machine and whether they are enabled for printing
lpstat -p

# Show the default printer
lpstat -d

# Display all available status information
lpstat -t

# Show a list of print jobs queued by the specified user
lpstat -u {{user}}

# List files one per line
ls -1

# List all files, including hidden files
ls -a

# Long format list (permissions, ownership, size and modification date) of all files
ls -la

# Long format list with size displayed using human readable units (KB, MB, GB)
ls -lh

# Long format list sorted by size (descending)
ls -lS

# Long format list of all files, sorted by modification date (oldest first)
ls -ltr

# Find the processes that have a given file open
lsof {{path/to/file}}

# Find the process that opened a local internet port
lsof -i :{{port}}

# Only output the process ID (PID)
lsof -t {{path/to/file}}

# List files opened by the given user
lsof -u {{username}}

# List files opened by the given command or process
lsof -c {{process_or_command_name}}

# List files opened by a specific process, given its PID
lsof -p {{PID}}

# List open files in a directory
lsof +D {{path/to/directory}}

# Start an interactive Lua shell
lua

# Execute a Lua script
lua {{script_name.lua}} {{--optional-argument}}

# Execute a Lua expression
lua -e '{{print( "Hello World" )}}

# Compile a Lua source file to Lua bytecode
luac -o {{byte_code.luac}} {{source.lua}}

# Do not include debug symbols in the output
luac -s -o {{byte_code.luac}} {{source.lua}}

# Create a new Lumen application
lumen new {{application_name}}

# List the available installer commands
lumen list

# Make a simple GET request
lwp-request -m GET {{http://example.com/some/path}}

# Upload a file with a POST request
cat {{/path/to/file}} | lwp-request -m POST {{http://example.com/some/path}}

# Make a request with a custom user agent
lwp-request -H 'User-Agent: {{user_agent}} -m {{METHOD}} {{http://example.com/some/path}}

# Make a request with HTTP authentication
lwp-request -C {{username}}:{{password}} -m {{METHOD}} {{http://example.com/some/path}}

# Make a request and print request headers
lwp-request -U -m {{METHOD}} {{http://example.com/some/path}}

# Make a request and print response headers and status chain
lwp-request -E -m {{METHOD}} {{http://example.com/some/path}}

# Compress a file
lz4 {{file}}

# Decompress a file
lz4 -d {{file.lz4}}

# Decompress a file and write to stdout
lz4 -dc {{file.lz4}}

# Package and compress a directory and its contents
tar cvf - {{path/to/dir}} | lz4 - {{dir.tar.lz4}}

# Decompress and unpack a directory and its contents
lz4 -d {{dir.tar.lz4}} | tar -xv

# Compress a file using the best compression
lz4 -9 {{file}}

# Process macros in a file
m4 {{path/to/file}}

# Define a macro before processing files
m4 -D{{macro_name}}={{macro_value}} {{path/to/file}}

# Enable one or more space-separated modules
magento module:enable {{module(s)}}

# Disable one or more space-separated modules
magento module:disable {{module(s)}}

# Update the database after enabling modules
magento setup:upgrade

# Update code and dependency injection configuration
magento setup:di:compile

# Deploy static assets
magento setup:static-content:deploy

# Enable maintenance mode
magento maintenance:enable

# Disable maintenance mode
magento maintenance:disable

# List all available commands
magento list

# Send mail (the content should be typed after the command, and ended with `Ctrl+D`)
mailx -s "{{subject}}" {{to_addr}}

# Send mail with content passed from another command
echo "{{content}}" | mailx -s "{{subject}}" {{to_addr}}

# Send mail with content read from a file
mailx -s "{{subject}}" {{to_addr}} < {{content.txt}}

# Send mail to a recipient and CC to another address
mailx -s "{{subject}}" -c {{cc_addr}} {{to_addr}}

# Send mail specifying the sender address
mailx -s "{{subject}}" -r {{from_addr}} {{to_addr}}

# Send mail with an attachment
mailx -a {{file}} -s "{{subject}}" {{to_addr}}

# Call the first target specified in the Makefile (usually named "all")
make

# Call a specific target
make {{target}}

# Call a specific target, executing 4 jobs at a time in parallel
make -j{{4}} {{target}}

# Use a specific Makefile
make --file {{file}}

# Execute make from another directory
make --directory {{directory}}

# Force making of a target, even if source files are unchanged
make --always-make {{target}}

# Compile a NSIS script
makensis {{path/to/file.nsi}}

# Compile a NSIS script in strict mode (treat warnings as errors)
makensis -WX {{path/to/file.nsi}}

# Print help for a specific command
makensis -CMDHELP {{command}}

# Display man page for a command
man {{command}}

# Display man page for a command from section 7
man {{command}}.{{7}}

# Display path searched for manpages
man --path

# Display location of a manpage rather than the manpage itself
man -w {{command}}

# Do a keyword search for manpages containing a search string
man -k {{keyword}}

# Start mc
mc

# Calculate the MD5 checksum for a file
md5sum {{filename1}}

# Calculate MD5 checksums for multiple files
md5sum {{filename1}} {{filename2}}

# Read a file of MD5SUMs and verify all files have matching checksums
md5sum -c {{filename.md5}}

# Launch a presentation in the terminal from a markdown file
mdp {{presentation.md}}

# Disable fading transitions
mdp --nofade {{presentation.md}}

# Invert font colors to use in terminals with light background
mdp --invert {{presentation.md}}

# Disable transparency in transparent terminals
mdp --notrans {{presentation.md}}

# Display metadata for a given file in the console
mediainfo {{file}}

# Store the output to a given file along with displaying in the console
mediainfo --Logfile={{out.txt}} {{file}}

# Display the list of metadata attributes that can be extracted
mediainfo --Info-Parameters

# Convert an STL file to an OBJ file
meshlabserver -i {{input.stl}} -o {{output.obj}}

# Convert a WRL file to a OFF file, including the vertex and face normals in the output mesh
meshlabserver -i {{input.wrl}} -o {{output.off}} -om vn fn

# Dump a list of all the available processing filters into a file
meshlabserver -d {{filename}}

# Process a 3D file using a filter script created in the MeshLab GUI (Filters > Show current filter script > Save Script)
meshlabserver -i {{input.ply}} -o {{output.ply}} -s {{filter_script.mlx}}

# Process a 3D file using a filter script, writing the output of the filters into a log file
meshlabserver -i {{input.x3d}} -o {{output.x3d}} -s {{filter_script.mlx}} -l {{logfile}}

# Run a meteor project from its root directory in development mode
meteor

# Create a project under the given directory
meteor create {{path/to/directory}}

# Display the list of packages the project is currently using
meteor list

# Add a package to the project
meteor add {{package_name}}

# Remove a package from the project
meteor remove {{package_name}}

# Create a production build of the project as a tarball under the given directory
meteor build {{path/to/directory}}

# Open a file
micro {{file}}

# Cut the entire line
Ctrl + K

# Search for a pattern in the file (press `Ctrl + N`/`Ctrl + P` to go to next/previous match)
Ctrl + F "{{pattern}}" <Enter>

# Execute a command
Ctrl + E {{command}} <Enter>

# Perform a substitution in the whole file
Ctrl + E replaceall "{{pattern}}" "{{replacement}}" <Enter>

# Quit
Ctrl + Q

# Start minetest in client mode
minetest

# Start minetest in server mode
minetest --server

# Write logs to a specific file
minetest --logfile {{path/to/file}}

# Only write errors to the console
minetest --quiet

# Start the server
minetestserver

# List available worlds
minetestserver --world list

# Specify the world name to load
minetestserver --world {{world_name}}

# List the available game IDs
minetestserver --gameid list

# Specify a game to use
minetestserver --gameid {{game_id}}

# Listen on a specific port
minetestserver --port {{34567}}

# Migrate to a different data backend
minetestserver --migrate {{sqlite3|leveldb|redis}}

# Start an interactive terminal after starting the server
minetestserver --terminal

# Start the cluster
minikube start

# Get the IP address of the cluster
minikube ip

# Access a service named my_service exposed via a node port and get the url
minikube service {{my_service}} --url

# Open kubernetes dashboard in a browser
minikube dashboard

# Start a proxy and save all output to a file
mitmdump -w {{filename}}

# Filter a saved traffic file to just POST requests
mitmdump -nr {{input_filename}} -w {{output_filename}} {{"~m post"}}

# Replay a saved traffic file
mitmdump -nc {{filename}}

# Start mitmproxy with default settings
mitmproxy

# Start mitmproxy bound to custom address and port
mitmproxy -b {{ip_address}} -p {{port}}

# Execute a particular file
mix run {{my_script.exs}}

# Create a new project
mix new {{project_name}}

# Compile project
mix compile

# Run project tests
mix test

# List all mix commands
mix help

# Create a directory in current folder or given path
mkdir {{directory}}

# Create directories recursively (useful for creating nested dirs)
mkdir -p {{path/to/directory}}

# Create a named pipe at a given path
mkfifo {{path/to/pipe}}

# Create an empty temporary file and return the absolute path to it
mktemp

# Create a temporary directory and return the absolute path to it
mktemp -d

# Create a temporary file with a specified suffix
mktemp --suffix "{{.txt}}"

# Pretty-print a CSV file in a tabular format
mlr --icsv --opprint cat {{example.csv}}

# Receive JSON data and pretty print the output
echo '{"hello":"world"}' | mlr --ijson --opprint cat

# Sort alphabetically on a field
mlr --icsv --opprint sort -f {{field}} {{example.csv}}

# Sort in descending numerical order on a field
mlr --icsv --opprint sort -nr {{field}} {{example.csv}}

# Convert CSV to JSON, performing calculations and display those calculations
mlr --icsv --ojson put '${{newField1}} = ${{oldFieldA}}/${{oldFieldB}}' {{example.csv}}

# Receive JSON and format the output as vertical JSON
echo '{"hello":"world", "foo":"bar"}' | mlr --ijson --ojson --jvstack cat

# Rename all files with a certain extension to a different extension
mmv "*{{.old_extension}}" "#1{{.new_extension}}"

# Copy report6part4.txt to ./french/rapport6partie4.txt along with all similarly named files
mmv -c {{"report*part*.txt"}} {{"./french/rapport#1partie#2.txt"}}

# Append all .txt files into one file
mmv -a {{"*.txt"}} {{"all.txt"}}

# Convert dates in filenames from "M-D-Y" format to "D-M-Y" format
mmv {{"[0-1][0-9]-[0-3][0-9]-[0-9][0-9][0-9][0-9].txt"}} {{"#3#4-#1#2-#5#6#7#8.txt"}}

# Run tests with default configuration or as configured in `mocha.opts`
mocha

# Run tests contained at a specific location
mocha {{folder/with/tests}}

# Run tests that match a specific grep pattern
mocha --grep {{^regex$}}

# Run tests on changes to JavaScript files in the current directory and once initially
mocha --watch

# Run tests with a specific reporter
mocha --reporter {{reporter}}

# Resize all JPEG images in the folder to 50% of their initial size
mogrify -resize {{50%}} {{*.jpg}}

# Resize all images starting with "DSC" to 800x600
mogrify -resize {{800x600}} {{DSC*}}

# Convert all PNG images in the folder to JPEG
mogrify -format {{jpg}} {{*.png}}

# Halve the saturation of all image files in the current directory
mogrify -modulate {{100,50}} {{*}}

# Double the brightness of all image files in the current directory
mogrify -modulate {{200}} {{*}}

# Connect to a database
mongo {{database}}

# Connect to a database running on a given host on a given port
mongo --host {{host}} --port {{port}} {{database}}

# Connect to a database with a given username; user will be prompted for password
mongo --username {{username}} {{database}} --password

# Evaluate a javascript expression on the database
mongo --eval '{{JSON.stringify(db.foo.findOne())}}' {{database}}

# Specify a config file
mongod --config {{filename}}

# Specify the port to listen on
mongod --port {{port}}

# Specify database profiling level. 0 is off, 1 is only slow operations, 2 is all
mongod --profile {{0|1|2}}

# Create a dump of all databases (this will place the files inside a folder called "dump")
mongodump

# Specify an output location for the dump
mongodump --out {{path/to/folder}}

# Create a dump of a given database
mongodump --db {{database_name}}

# Create a dump of a given collection within a given database
mongodump --collection {{collection_name}} --db {{database_name}}

# Connect to a given host running on a given port, and create a dump
mongodump --host {{host}} --port {{port}}

# Create a dump of a given database with a given username; user will be prompted for password
mongodump --username {{username}} {{database}} --password

# Import a bson data dump from a folder to a MongoDB database
mongorestore --db {{database_name}} {{path/to/folder}}

# Import a bson data dump from a folder to a given database in a MongoDB server host, running at a given port, with user authentication (user will be prompted for password)
mongorestore --host {{database_host:port}} --db {{database_name}} --username {{username}} {{path/to/folder}} --password

# Import a collection from a bson file to a MongoDB database
mongorestore --db {{database_name}} {{path/to/file}}

# Import a collection from a bson file to a given database in a MongoDB server host, running at a given port, with user authentication (user will be prompted for password)
mongorestore --host {{database_host:port}} --db {{database_name}} --username {{username}} {{path/to/file}} --password

# Tile images into a grid, automatically resizing images larger than the grid cell size
montage {{image1.png}} {{image2.jpg}} {{imageN.png}} montage.jpg

# Tile images into a grid, automatically calculating the grid cell size from the largest image
montage {{image1.png}} {{image2.jpg}} {{imageN.png}} -geometry +0+0 montage.jpg

# Set the grid cell size and resize images to fit it before tiling
montage {{image1.png}} {{image2.jpg}} {{imageN.png}} -geometry 640x480+0+0 montage.jpg

# Limit the number of rows and columns in the grid, causing input images to overflow into multiple output montages
montage {{image1.png}} {{image2.jpg}} {{imageN.png}} -geometry +0+0 -tile 2x3 montage_%d.jpg

# Resize and crop images to completely fill their grid cells before tiling
montage {{image1.png}} {{image2.jpg}} {{imageN.png}} -geometry +0+0 -resize 640x480^ -gravity center -crop 640x480+0+0 montage.jpg

# Open a file
more {{source_file}}

# Page down
<Space>

# Search for a string (press `n` to go to the next match)
/{{something}}

# Exit
q

# Invoke `moro` without parameters, to set the current time as the start of the working day
moro

# Specify a custom time for the start of the working day
moro hi {{09:30}}

# Invoke `moro` without parameters a second time, to set the current time at the end of the working day
moro

# Specify a custom time for the end of the working day
moro bye {{17:30}}

# Add a note on the current working day
moro note {{3 hours on project Foo}}

# Show a report of time logs and notes for the current working day
moro report

# Show a report of time logs and notes for all working days on record
moro report --all

# Connect to a remote server
mosh {{username}}@{{remote_host}}

# Connect to a remote server with a specific identity (private key)
mosh --ssh="ssh -i {{/path/to/key_file}}" {{username}}@{{remote_host}}

# Connect to a remote server using a specific port
mosh --ssh="ssh -p {{2222}}" {{username}}@{{remote_host}}

# Run a command on a remote server
mosh {{remote_host}} -- {{command -with -flags}}

# Select Mosh UDP port (useful when `{{remote_host}}` is behind a NAT)
mosh -p {{124}} {{username}}@{{remote_host}}

# Usage when `mosh-server` binary is outside standard path
mosh --server={{/path/to/bin/}}mosh-server {{remote_host}}

# Open a file
most {{path/to/file}}

# Open several files
most {{path/to/file1}} {{path/to/file2}}

# Open a file at the first occurrence of "string"
most {{file}} +/{{string}}

# Move through opened files
:O n

# Jump to the 100th line
{{100}}j

# Edit current file
e

# Split the current window in half
<CTRL-x> o

# Exit
Q

# Show all mounted filesystems
mount

# Mount a device to a directory
mount -t {{filesystem_type}} {{path/to/device_file}} {{path/to/target_directory}}

# Mount a CD-ROM device (with the filetype ISO9660) to /cdrom (readonly)
mount -t {{iso9660}} -o ro {{/dev/cdrom}} {{/cdrom}}

# Mount all the filesystem defined in /etc/fstab
mount -a

# Mount a specific filesystem described in /etc/fstab (e.g. "/dev/sda1 /my_drive ext2 defaults 0 2")
mount {{/my_drive}}

# Display information about an existing MP4 file
mp4box -info {{filename}}

# Add an SRT subtitle file into an MP4 file
mp4box -add {{input_subs.srt}}:lang=eng -add {{input.mp4}} {{output.mp4}}

# Combine audio from one file and video from another
mp4box -add {{input1.mp4}}#audio -add {{input2.mp4}}#video {{output.mp4}

# Toggle play/pause
mpc toggle

# Stop playing
mpc stop

# Show information about the currently playing song
mpc status

# Play next song
mpc next

# Play previous song
mpc prev

# Forward or rewind the currently playing song
mpc [+-]{{seconds}}

# Play a video or audio file
mpv {{file}}

# Jump backward/forward 5 seconds
LEFT <or> RIGHT

# Jump backward/forward 1 minute
DOWN <or> UP

# Decrease or increase playback speed by 10 %
[ <or> ]

# Play a file at a specified speed (0.01 to 100, default 1)
mpv --speed {{speed}} {{file}}

# Play a file using a profile defined in the `mpv.conf` file
mpv --profile {{profile_name}} {{file}}

# Register a repository
mr register

# Update repositories in 5 concurent jobs
mr -j{{5}} update

# Print the status of all repositories
mr status

# Checkout all repositories to the latest version
mr checkout

# Build the first project file in the current directory
msbuild

# Build a specific project file
msbuild {{path/to/project_file}}

# Set one or more semicolon-separated targets to build
msbuild {{path/to/project_file}} /target:{{targets}}

# Set one or more semicolon-separated properties
msbuild {{path/to/project_file}} /property:{{name=value}}

# Set the build tools version to use
msbuild {{path/to/project_file}} /toolsversion:{{version}}

# Display detailed information at the end of the log about how the project was configured
msbuild {{path/to/project_file}} /detailedsummary

# Display detailed help information
msbuild /help

# Send an email using the default account configured in `~/.msmtprc`
echo {{"Hello world"}} | msmtp {{to@example.org}}

# Send an email using a specific account configured in `~/.msmtprc`
echo {{"Hello world"}} | msmtp --account={{account_name}} {{to@example.org}}

# Send an email without a configured account. The password should be specified in the `~/.msmtprc` file
echo {{"Hello world"}} | msmtp --host={{localhost}} --port={{999}} --from={{from@example.org}} {{to@example.org}}

# Traceroute to a host and continuously ping all intermediary hops
mtr {{host}}

# Disable IP address and host name mapping
mtr -n {{host}}

# Generate output after pinging each hop 10 times
mtr -w {{host}}

# Force IP IPv4 or IPV6
mtr -4 {{host}}

# Wait for a given time (in seconds) before sending another packet to the same hop
mtr -i {{seconds}} {{host}}

# Convert pages 1-10 into 10 PNG images
mutool convert -o {{image%d.png}} {{file.pdf}} {{1-10}}

# Convert pages 2, 3 and 5 of a PDF into text in the standard output
mutool draw -F {{txt}} {{file.pdf}} {{2,3,5}}

# Concatenate two PDFs
mutool merge -o {{output.pdf}} {{input1.pdf}} {{input2.pdf}}

# Query information about all content embedded in a PDF
mutool info {{input.pdf}}

# Extract all images, fonts and resources embedded in a PDF out into the current directory
mutool extract {{input.pdf}}

# Open the specified mailbox
mutt -f {{mailbox}}

# Send an email and specify a subject and a cc recipient
mutt -s {{subject}} -c {{cc@example.com}} {{recipient@example.com}}

# Send an email with files attached
mutt -a {{file1}} {{file2}} -- {{recipient@example.com}}

# Specify a file to include as the message body
mutt -i {{file}} {{recipient@example.com}}

# Specify a draft file containing the header and the body of the message, in RFC 5322 format
mutt -H {{file}} {{recipient@example.com}}

# Move files in arbitrary locations
mv {{source}} {{target}}

# Do not prompt for confirmation before overwriting existing files
mv -f {{source}} {{target}}

# Prompt for confirmation before overwriting existing files, regardless of file permissions
mv -i {{source}} {{target}}

# Do not overwrite existing files at the target
mv -n {{source}} {{target}}

# Move files in verbose mode, showing files after they are moved
mv -v {{source}} {{target}}

# Compile a project
mvn compile

# Compile and package the compiled code in its distributable format, such as a `jar`
mvn package

# Compile and package, skipping unit tests
mvn package -Dmaven.test.skip=true

# Install the built package in local maven repository. (This will invoke the compile and package commands too)
mvn install

# Delete build artifacts from the target folder
mvn clean

# Do a clean and then invoke the package phase
mvn clean package

# Clean and then package the code with a given build profile
mvn clean -P{{profile}} package

# Run a class with a main method
mvn exec:java -Dexec.mainClass="{{com.example.Main}}" -Dexec.args="{{arg1 arg2}}"

# Connect to a database
mysql {{database_name}}

# Connect to a database, user will be prompted for a password
mysql -u {{user}} --password {{database_name}}

# Connect to a database on another host
mysql -h {{database_host}} {{database_name}}

# Connect to a database through a Unix socket
mysql --socket {{path/to/socket.sock}}

# Execute SQL statements in a script file (batch file)
mysql -e "source {{filename.sql}}" {{database_name}}

# Create a backup, user will be prompted for a password
mysqldump -u {{user}} --password {{database_name}} -r {{filename.sql}}

# Restore a backup, user will be prompted for a password
mysql -u {{user}} --password -e "source {{filename.sql}}" {{database_name}}

# Start nano in terminal with {filename}
nano {{filename}}

# Enable smooth scrolling
nano -S {{filename}}

# Indent new lines to the previous lines' indentation
nano -i {{filename}}

# Assemble `source.asm` into a binary file `source`, in the (default) raw binary format
nasm {{source.asm}}

# Assemble `source.asm` into a binary file `output_file`, in the specified format
nasm -f {{format}} {{source.asm}} -o {{output_file}}

# List valid output formats (along with basic nasm help)
nasm -hf

# Assemble and generate an assembly listing file
nasm -l {{list_file}} {{source.asm}}

# Add a directory (must be written with trailing slash) to the include file search path before assembling
nasm -i {{/path/to/include_dir/}} {{source.asm}}

# Listen on a specified port
nc  -l {{port}}

# Connect to a certain port (you can then write to this port)
nc {{ip_address}} {{port}}

# Set a timeout
nc -w {{timeout_in_seconds}} {{ipaddress}} {{port}}

# Serve a file
nc -l {{port}} < {{file}}

# Receive a file
nc {{ip_address}} {{port}} > {{file}}

# Server stay up after client detach
nc -k -l {{port}}

# Client stay up after EOF
nc -q {{timeout}} {{ip_address}}

# Port scanning
nc -v -z {{ip_address}} {{port}}

# Proxy and port forwarding
nc -l {{port}} | nc {{hostname}} {{port}}

# Connect to a music player daemon on a given host and port
ncmpcpp --host {{ip}} --port {{port}}

# Display metadata of the current song to console
ncmpcpp --current-song

# Use a specified configuration file
ncmpcpp --config {{file}}

# Use a different set of key bindings from a file
ncmpcpp --bindings {{file}}

# Return the default config, and create it if it's the first time the program runs
neofetch

# Trigger an info line from appearing in the output, where 'infoname' is the function name in the config file, e.g. memory
neofetch --{{enable|disable}} {{infoname}}

# Hide/Show OS architecture
neofetch --os_arch {{on|off}}

# Enable/Disable CPU brand in output
neofetch --cpu_brand {{on|off}}

# Start server with the default config file
nginx

# Start server with a custom config file
nginx -c {{config_file}}

# Start server with a prefix for all relative paths in the config file
nginx -c {{config_file}} -p {{prefix/for/relative/paths}}

# Test the configuration without affecting the running server
nginx -t

# Reload the configuration by sending a signal with no downtime
nginx -s reload

# Capture traffic of all interfaces
ngrep -d any

# Capture traffic of a specific interface
ngrep -d {{eth0}}

# Capture traffic crossing port 22 of interface eth0
ngrep -d {{eth0}} port {{22}}

# Capture traffic from or to a host
ngrep host {{www.example.com}}

# Filter keyword 'User-Agent:' of interface eth0
ngrep -d {{eth0}} '{{User-Agent:}}'

# Launch a program with altered priority
nice -n {{niceness_value}} {{command}}

# Perform a basic Nikto scan against a target host
perl nikto.pl -h {{192.168.0.1}}

# Specify the port number when performing a basic scan
perl nikto.pl -h {{192.168.0.1}} -p {{443}}

# Scan ports and protocols with full URL syntax
perl nikto.pl -h {{https://192.168.0.1:443/}}

# Scan multiple ports in the same scanning session
perl nikto.pl -h {{192.168.0.1}} -p {{80,88,443}}

# Update to the latest plugins and databases
perl nikto.pl -update

# Compile a source file
nim compile {{file.nim}}

# Compile and run a source file
nim compile -r {{file.nim}}

# Compile a source file with release optimizations enabled
nim compile -d:release {{file.nim}}

# Build a release binary optimized for low file size
nim compile -d:release --opt:size {{file.nim}}

# Generate HTML documentation for a module (output will be placed in the current directory)
nim doc {{file.nim}}

# Search for packages
nimble search {{search_string}}

# Install a package
nimble install {{package_name}}

# List installed packages
nimble list -i

# Create a new Nimble package in the current directory
nimble init

# Build a Nimble package
nimble build

# Install a Nimble package
nimble install

# Delete all store paths unused by current generations of each profile
sudo nix-collect-garbage --delete-old

# Simulate the deletion of old store paths
sudo nix-collect-garbage --delete-old --dry-run

# Delete all store paths older than 30 days
sudo nix-collect-garbage --delete-older-than {{30d}}

# Show available package with name or without name
nix-env -qa {{pkg_name}}

# Show the status of available packages
nix-env -qas

# Install package
nix-env -i {{pkg_name}}

# Uninstall package
nix-env -e {{pkg_name}}

# Upgrade one package
nix-env -u {{pkg_name}}

# Upgrade all packages
nix-env -u

# Number non-blank lines in a file
nl {{file}}

# Read from standard output
cat {{file}} | nl {{options}} -

# Number only the lines with printable text
nl -t {{file}}

# Number all lines including blank lines
nl -b a {{file}}

# Number only the body lines that match a basic regular expression (BRE) pattern
nl -b p'FooBar[0-9]' {{file}}

# Try to determine whether the specified hosts are up and what are their names
nmap -sn {{ip_or_hostname}} {{optional_another_address}}

# Like above, but also run a default 1000-port TCP scan if host seems up
nmap {{ip_or_hostname}} {{optional_another_address}}

# Also enable scripts, service detection, OS fingerprinting and traceroute
nmap -A {{address_or_addresses}}

# Assume good network connection and speed up execution
nmap -T4 {{address_or_addresses}}

# Scan a specific list of ports (use -p- for all ports 1-65535)
nmap -p {{port1,port2,...,portN}} {{address_or_addresses}}

# Perform TCP and UDP scanning (use -sU for UDP only, -sZ for SCTP, -sO for IP)
nmap -sSU {{address_or_addresses}}

# Perform TLS cipher scan against a host to determine supported ciphers and SSL/TLS protocols
nmap --script ssl-enum-ciphers {{address_or_addresses}} -p 443

# Run a JavaScript file
node {{file}}.js

# Start a REPL (interactive shell)
node

# Evaluate JavaScript by passing it in the command
node -e "{{code}}"

# Run process that can live beyond the terminal
nohup {{command options}}

# Parse the contents of a url or file
nokogiri {{url|path/to/file}}

# Parse as a specific type
nokogiri {{url|path/to/file}} --type {{xml|html}}

# Load a specific initialisation file before parsing
nokogiri {{url|path/to/file}} -C {{path/to/config_file}}

# Parse using a specific encoding
nokogiri {{url|path/to/file}} --encoding {{encoding}}

# Validate using a RELAX NG file
nokogiri {{url|path/to/file}} --rng {{url|path/to/file}}

# Display a report of outdated, incorrect, and unused dependencies
npm-check

# Interactively update out-of-date packages
npm-check --update

# Update everything without prompting
npm-check --update-all

# Don't check for unused packages
npm-check --skip-unused

# Download and install a module globally
npm install -g {{module_name}}

# Download all dependencies referenced in package.json
npm install

# Download a given dependency required for the application to run, and add it to the package.json
npm install {{module_name}}@{{version}} --save

# Download a given dependency for development purposes, and add it to the package.json
npm install {{module_name}}@{{version}} --save-dev

# Uninstall a module
npm uninstall {{module_name}}

# List a tree of installed modules referenced in package.json
npm list

# List top-level globally installed modules
npm list -g --depth={{0}}

# Interactively create a package.json file
npm init

# Display the number of available processing units
nproc

# Display the number of installed processing units, including any inactive ones
nproc --all

# If possible, subtract a given number of units from the returned value
nproc --ignore {{count}}

# Execute the binary from a given npm module
npx {{module_name}}

# In case a package has multiple binaries, specify the package name along with the binary
npx -p {{package_name}} {{module_name}}

# View help contents
npx --help

# List all registries
nrm ls

# Change to a particular registry
nrm use {{registry}}

# Show the response time for all registries
nrm test

# Add a custom registry
nrm add {{registry}} {{url}}

# Delete a registry
nrm del {{registry}}

# Query your system's default name server for an IP address (A record) of the domain
nslookup {{example.com}}

# Query a given name server for a NS record of the domain
nslookup -type=NS {{example.com}} {{8.8.8.8}}

# Query for a reverse lookup (PTR record) of an IP address
nslookup -type=PTR {{54.240.162.118}}

# Query for ANY available records using TCP protocol
nslookup -vc -type=ANY {{example.com}} 

# Query a given name server for the whole zone file (zone transfer) of the domain using TCP protocol
nslookup -vc -type=AXFR {{example.com}} {{name_server}}

# Query for a mail server (MX record) of the domain, showing details of the transaction
nslookup -type=MX -debug {{example.com}}

# Query a given name server on a specific port number for a TXT record of the domain
nslookup -port={{port_number}} -type=TXT {{example.com}} {{name_server}}

# Convert 1.5K (SI Units) to 1500
numfmt --from={{si}} {{1.5K}}

# Convert 5th field (1-indexed) to IEC Units without converting header
ls -l | numfmt --header={{1}} --field={{5}} --to={{iec}}

# Convert to IEC units, pad with 5 characters, left aligned
du -s * | numfmt --to={{iec}} --format={{"%-5f"}}

# Open a file
nvim {{file}}

# Enter text editing mode (insert mode)
<Esc>i

# Copy ("yank") or cut ("delete") the current line (paste it with `P`)
<Esc>{{yy|dd}}

# Undo the last operation
<Esc>u

# Search for a pattern in the file (press `n`/`N` to go to next/previous match)
<Esc>/{{search_pattern}}<Enter>

# Perform a regex substitution in the whole file
<Esc>:%s/{{pattern}}/{{replacement}}/g<Enter>

# Save (write) the file, and quit
<Esc>:wq<Enter>

# Quit without saving
<Esc>:q!<Enter>

# Install a specific version of NodeJS
nvm install {{node_version}}

# Use a specific version NodeJS in the current shell
nvm use {{node_version}}

# Set the default NodeJS version
nvm alias default {{node_version}}

# List all available NodeJS versions and print the default one
nvm list

# Run a specific version NodeJS REPL
nvm run {{node_version}} --version

# Run app in a specific version of NodeJS
nvm exec {{node_version}} node {{app.js}}

# Display file using default settings: octal format, 8 bytes per line, byte offsets in octal, and duplicate lines replaced with `*`
od {{path/to/file}}

# Display file in verbose mode, i.e. without replacing duplicate lines with `*`
od -v {{path/to/file}}

# Display file in hexadecimal format (2-byte units), with byte offsets in decimal format
od --format={{x}} --address-radix={{d}} -v {{path/to/file}}

# Display file in hexadecimal format (1-byte units), and 4 bytes per line
od --format={{x1}} --width={{4}} -v {{path/to/file}}

# Display file in hexadecimal format along with its character representation, and do not print byte offsets
od --format={{xz}} --address-radix={{n}} -v {{path/to/file}}

# Read only 100 bytes of a file starting from the 500th byte
od --read-bytes {{100}} --skip-bytes={{500}} -v {{path/to/file}}

# Add a user to the current project
add user {{user_name}};

# Grant a set of authorities to a user
grant {{action_list}} on {{object_type}} {{object_name}} to user {{user_name}};

# Show authorities of a user
show grants for {{user_name}};

# Create a user role
create role {{role_name}};

# Grant a set of authorities to a role
grant {{action_list}} on {{object_type}} {{object_name}} to role {{role_name}};

# Describe authorities of a role
desc role {{role_name}};

# Grant a role to a user
grant {{role_name}} to {{user_name}};

# Show functions in the current project
list functions;

# Create a Java function using a .jar resource
create function {{func_name}} as {{path.to.package.Func}} using '{{package.jar}}';

# Create a Python function using a .py resource
create function {{func_name}} as {{script.Func}} using '{{script.py}}';

# Delete a function
drop function {{func_name}};

# Show instances created by current user
show instances;

# Describe the details of an instance
desc instance {{instance_id}};

# Check the status of an instance
status {{instance_id}};

# Wait on the termination of an instance, printing log and progress information until then
wait {{instance_id}};

# Kill an instance
kill {{instance_id}};

# Show resources in the current project
list resources;

# Add file resource
add file {{file_name}} as {{alias}};

# Add archive resource
add archive {{archive.tar.gz}} as {{alias}};

# Add .jar resource
add jar {{package.jar}};

# Add .py resource
add py {{script.py}};

# Delete resource
drop resource {{resource_name}};

# Create a table with partition and lifecycle
create table {{table_name}} ({{col}} {{type}}) partitioned by ({{col}} {{type}}) lifecycle {{days}};

# Create a table based on the definition of another table
create table {{table_name}} like {{another_table}};

# Add partition to a table
alter table {{table_name}} add partition ({{partition_spec}});

# Delete partition from a table
alter table {{table_name}} drop partition ({{partition_spec}});

# Delete table
drop table {{table_name}};

# Download table to local file
tunnel download {{table_name}} {{file}};

# Upload local file to a table partition
tunnel upload {{file}} {{table_name}}/{{partition_spec}};

# Upload table specifying field and record delimiters
tunnel upload {{file}} {{table_name}} -fd {{field_delim}} -rd {{record_delim}};

# Upload table using multiple threads
tunnel upload {{file}} {{table_name}} -threads {{num}};

# Start the command line with a custom configuration file
odpscmd --config={{odps_config.ini}}

# Switch current project
use {{project_name}};

# Show tables in the current project
show tables;

# Describe a table
desc {{table_name}};

# Show table partitions
show partitions {{table_name}};

# Describe a partition
desc {{table_name}} partition ({{partition_spec}});

# Install one or more packages
omf install {{name}}

# List installed packages
omf list

# List available themes
omf theme

# Apply a theme
omf theme {{name}}

# Remove a theme or package
omf remove {{name}}

# Uninstall Oh My Fish
omf destroy

# Generate a 2048bit RSA private key and save it to a file
openssl genrsa -out {{filename.key}} 2048

# Generate a certificate signing request to be sent to a certificate authority
openssl req -new -sha256 -key {{filename.key}} -out {{filename.csr}}

# Generate a self-signed certificate from a certificate signing request valid for some number of days
openssl x509 -req -days {{days}} -in {{filename.csr}} -signkey {{filename.key}} -out {{filename.crt}}

# Display certificate information
openssl x509 -in {{filename.crt}} -noout -text

# Display the start and expiry dates for a domain's certificate
openssl s_client -connect {{host}}:{{port}} 2>/dev/null | openssl x509 -noout -dates

# Display the certificate presented by an SSL/TLS server
openssl s_client -connect {{host}}:{{port}} </dev/null

# Display the complete certificate chain of an HTTPS server
openssl s_client -connect {{host}}:443 -showcerts </dev/null

# Run an optimization or analysis on a bitcode file
opt -{{passname}} {{path/to/file.bc}} -S -o {{file_opt.bc}}

# Output the Control Flow Graph of a function to a "dot" file
opt {{-dot-cfg}} -S {{path/to/file.bc}} -disable-output

# Optimize the program at level 2 and output the result to another file
opt -O2 {{path/to/file.bc}} -S -o {{path/to/output_file.bc}}

# Compress a PNG with default settings
optipng {{path/to/file.png}}

# Compress a PNG with best compression
optipng -o{{7}} {{path/to/file.png}}

# Compress a PNG with fastest compression
optipng -o{{0}} {{path/to/file.png}}

# Compress a PNG and add interlacing
optipng -i {{1}} {{path/to/file.png}}

# Compress a PNG and preserve all metadata (including file timestamps)
optipng -preserve {{path/to/file.png}}

# Compress a PNG and remove all metadata
optipng -strip all {{path/to/file.png}}

# Log in to the Perforce service
p4 login -a

# Create a client
p4 client

# Copy files from depot into the client workspace
p4 sync

# Create or edit changelist description
p4 change

# Open a file to edit
p4 edit -c {{changelist_number}} {{file_name}}

# Open a new file to add it to the depot
p4 add

# Display list of files modified by changelist
p4 describe -c {{changelist_number}}

# Submit a changelist to the depot
p4 submit -c {{changelist_number}}

# Create a new p5 collection
p5 new {{collection_name}}

# Generate a new p5 project (should be run from collection directory)
p5 generate {{project_name}}

# Run the p5 manager server
p5 server

# Update libraries to their latest versions
p5 update

# Update the list of available packages and versions (it's recommended to run this before other `paci` commands)
paci refresh

# Configure its behaviour
paci configure

# Search for a given package
paci search {{package}}

# Install a package
paci install {{package}}

# Update a package
paci update {{package}}

# Convert file to pdf (the output format is determined by file extension)
pandoc {{input.md}} -o {{output.pdf}}

# Force conversion to use a specific format
pandoc {{input.docx}} --to {{markdown_github}} -o {{output.md}}

# Convert to a standalone file with the appropriate headers/footers (for LaTeX, HTML, etc.)
pandoc {{input.md}} -s -o {{output.tex}}

# List all supported input formats
pandoc --list-input-formats

# List all supported output formats
pandoc --list-output-formats

# Gzip several files at once, using all cores
parallel gzip ::: {{file1}} {{file2}} {{file3}}

# Read arguments from stdin, run 4 jobs at once
ls *.txt | parallel -j4 gzip

# Convert JPG images to PNG using replacement strings
parallel convert {} {.}.png ::: *.jpg

# Parallel xargs, cram as many args as possible onto one command
{{args}} | parallel -X {{command}}

# Break stdin into ~1M blocks, feed each block to stdin of new command
cat {{big_file.txt}} | parallel --pipe --block 1M {{command}}

# Run on multiple machines via SSH
parallel -S {{machine1}},{{machine2}} {{command}} ::: {{arg1}} {{arg2}}

# Initialize the storage using a gpg-id for encryption
pass init {{gpg_id}}

# Save a new password (prompts you for the value without echoing it)
pass insert {{path/to/data}}

# Copy a password (first line of the data file) to the clipboard
pass -c {{path/to/data}}

# List the whole store tree
pass

# Generate a new random password with a given length, and copy it to the clipboard
pass generate -c {{path/to/data}} {{num}}

# Run any git command against the underlying store repository
pass git {{git_arguments}}

# Change the password of the current user
passwd {{new_password}}

# Change the password of the specified user
passwd {{username}} {{new_password}}

# Get the current status of the user
passwd -S

# Make the password of the account blank (it will set the named account passwordless)
passwd -d

# Join all the lines into a single line, using TAB as delimiter
paste -s {{file}}

# Join all the lines into a single line, using the specified delimiter
paste -s -d {{delimiter}} {{file}}

# Merge two files side by side, each in its column, using TAB as delimiter
paste {{file1}} {{file2}}

# Merge two files side by side, each in its column, using the specified delimiter
paste -d {{delimiter}} {{file1}} {{file2}}

# Merge two files, with lines added alternatively
paste -d '\n' {{file1}} {{file2}}

# Apply a patch
patch < {{patch_file}}.diff

# Apply a patch to current directory
patch -p1 < {{patch_file}}.diff

# Apply the reverse of a patch
patch -R < {{patch_file}}.diff

# Merge two PDFs
pdfjoin {{file1}} {{file2}} --outfile {{output_file}}

# Save pages 3 to 5 followed by page 1 to a new PDF
pdfjoin {{file 3-5,1}} --outfile {{output_file}}

# Merge subranges from two PDFs
pdfjoin {{file1 3-5,1}} {{file2 4-6}} --outfile {{output_file}}

# Compile a pdf document
pdflatex {{source.tex}}

# Compile a pdf document, halting on each error
pdflatex -halt-on-error {{source.tex}}

# Convert an A2 poster into 4 A4 pages
pdfposter --poster-size a2 {{input_file.pdf}} {{output_file.pdf}}

# Scale an A4 poster to A3 and then generate 2 A4 pages
pdfposter --scale 2 {{input_file.pdf}} {{output_file.pdf}}

# Extract pages 1-3, 5 and 6-10 from a PDF file and save them as another one
pdftk {{input.pdf}} cat {{1-3 5 6-10}} output {{output.pdf}}

# Merge (concatenate) a list of PDF files and save the result as another one
pdftk {{file1.pdf}} {{file2.pdf}} ... cat output {{output.pdf}}

# Split each page of a PDF file into a separate file, with a given filename output pattern
pdftk {{input.pdf}} burst output {{out_%d.pdf}}

# Rotate all pages by 180 degrees clockwise
pdftk {{input.pdf}} cat {{1-endsouth}} output {{output.pdf}}

# Rotate third page by 90 degrees clockwise and leave others unchanged
pdftk {{input.pdf}} cat {{1-2 3east 4-end}} output {{output.pdf}}

# Convert filename.pdf to plain text and print it to standard output
pdftotext {{filename.pdf}} -

# Convert filename.pdf to plain text and save it as filename.txt
pdftotext {{filename.pdf}}

# Convert input.pdf to plain text and save it as output.txt
pdftotext {{input.pdf}} {{output.txt}}

# Convert pages 2, 3 and 4 of input.pdf to plain text and save them as output.txt
pdftotext -f {{2}} -l {{4}} {{input.pdf}} {{output.txt}}

# Merge 2 PDFs into a single PDF
pdfunite {{path/to/fileA.pdf}} {{path/to/fileB.pdf}} {{path/to/merged_output.pdf}}

# Merge a folder of PDFs into a single PDF
pdfunite {{path/to/directory/*.pdf}} {{path/to/merged_output.pdf}}

# Stream the largest media file in a torrent
peerflix "{{torrent_url|magnet_link}}"

# List all streamable files contained in a torrent (given as a magnet link)
peerflix "{{magnet:?xt=urn:btih:0123456789abcdef0123456789abcdef01234567}}" --list

# Stream the largest file in a torrent, given as a torrent URL, to VLC
peerflix "{{http://example.net/music.torrent}}" --vlc

# Stream the largest file in a torrent to MPlayer, with subtitles
peerflix "{{torrent_url|magnet_link}}" --mplayer --subtitles {{subtitle-file.srt}}

# Stream all files from a torrent to Airplay
peerflix "{{torrent_url|magnet_link}}" --all --airplay

# Parse and execute a Perl script
perl {{script.pl}}

# Check syntax errors on a Perl script
perl -c {{script.pl}}

# Parse and execute a perl statement
perl -e {{perl_statement}}

# Run a Perl script in debug mode, using `perldebug`
perl -d {{script.pl}}

# Loo[p] over all lines of a file, editing them [i]n-place using a find/replace [e]xpression
perl -p -i -e 's/{{find}}/{{replace}}/g' {{filename}}

# Run a find/replace expression on a file, saving the original file with a given extension
perl -p -i'.old' -e 's/{{find}}/{{replace}}/g' {{filename}}

# Run a multi-line find/replace expression on a file, and save the result in another file
perl -p0e 's/{{foo\nbar}}/{{foobar}}/g' {{input_file}} > {{output_file}}

# Start a PostgreSQL server
pg_ctl -D {{data_directory}} -l {{log_file_name}}

# Initialize a PostgreSQL database cluster
pg_ctl -D {{data_directory}} init

# Stop a PostgreSQL server
pg_ctl -D {{data_directory}} stop

# Restart a PostgreSQL server
pg_ctl -D {{data_directory}} restart

# Dump database into a SQL-script file
pg_dump {{db_name}} > {{output_file.sql}}

# Same as above, customize username
pg_dump -U {{username}} {{db_name}} > {{output_file.sql}}

# Same as above, customize host and port
pg_dump -h {{host}} -p {{port}} {{db_name}} > {{output_file.sql}}

# Dump a database into a custom-format archive file
pg_dump -Fc {{db_name}} > {{output_file.dump}}

# Restore an archive into an existing database
pg_restore -d {{db_name}} {{archive_file.dump}}

# Same as above, customize username
pg_restore -U {{username}} -d {{db_name}} {{archive_file.dump}}

# Same as above, customize host and port
pg_restore -h {{host}} -p {{port}} -d {{db_name}} {{archive_file.dump}}

# Clean database objects before creating them
pg_restore --clean -d {{db_name}} {{archive_file.dump}}

# Use multiple jobs to do the restoring
pg_restore -j {{2}} -d {{db_name}} {{archive_file.dump}}

# Return PIDs of any running processes with a matching command string
pgrep {{process_name}}

# Search full command line with parameters instead of just the process name
pgrep -f "{{process_name}} {{parameter}}"

# Search for process run by a specific user
pgrep -u root {{process_name}}

# Display a list of available aliased Phars
phive list

# Install a specified Phar to the local directory
phive install {{alias|url}}

# Install a specified Phar globally
phive install {{alias|url}} --global

# Install a specified Phar to a target directory
phive install {{alias|url}} --target {{path/to/directory}}

# Update all Phar files to the latest version
phive update

# Remove a specified Phar file
phive remove {{alias|url}}

# Remove unused Phar files
phive purge

# List all available commands
phive help

# Display a list of all available commands
php yii {{help}}

# Start PHP's built-in web server for the current Yii application
php yii {{serve}}

# Generate a controller, views and related files for the CRUD actions on the specified model class
php yii {{gii/crud}} --modelClass={{ModelName}} --controllerClass={{ControllerName}}

# Parse and execute a php script
php {{file}}

# Check syntax on (i.e. lint) a PHP script
php -l {{file}}

# Run PHP interactively
php -a

# Run PHP code (Notes: Don't use <? ?> tags; escape double quotes with backslash)
php -r "{{code}}"

# Start a PHP built-in web server in the current directory
php -S {{host:port}}

# Sniff the specified directory for issues (defaults to the PEAR standard)
phpcs {{path/to/directory}}

# Display a list of installed coding standards
phpcs -i

# Specify a coding standard to validate against
phpcs {{path/to/directory}} --standard {{standard}}

# Specify file extension(s) to include when sniffing
phpcs {{path/to/directory}} --extensions {{file_extension(s)}}

# Specify the format of the output report (e.g. `full`, `xml`, `json`, `summary`)
phpcs {{path/to/directory}} --report {{format}}

# Set config variables to be used during the process
phpcs {{path/to/directory}} --config-set {{key}} {{value}}

# A comma-separated list of files to load before processing
phpcs {{path/to/directory}} --bootstrap {{file(s)}}

# Don't recurse into subdirectories
phpcs {{path/to/directory}} -l

# Prepare the PHP extension in the current directory for compiling
phpize

# Delete files previously created by phpize
phpize --clean

# Analyse a directory and print the result
phploc {{path/to/directory}}

# Include only specific files from a comma-separated list (globs are allowed)
phploc {{path/to/directory}} --names {{files}}

# Exclude specific files from a comma-separated list (globs are allowed)
phploc {{path/to/directory}} --names-exclude {{files}}

# Exclude a specific directory from analysis
phploc {{path/to/directory}} --exclude {{path/to/exclude_directory}}

# Log the results to a specific CSV file
phploc {{path/to/directory}} --log-csv {{path/to/file}}

# Log the results to a specific XML file
phploc {{path/to/directory}} --log-xml {{path/to/file}}

# Count PHPUnit test case classes and test methods
phploc {{path/to/directory}} --count-tests

# Display available options for analysis
phpstan analyse --help

# Analyse the specified space-separated directories
phpstan analyse {{path/to/directory}}

# Analyse a directory using a configuration file
phpstan analyse {{path/to/directory}} --configuration {{path/to/config}}

# Analyse using a specific rule level (0-7, higher is stricter)
phpstan analyse {{path/to/directory}} --level {{level}}

# Specify an autoload file to load before analysing
phpstan analyse {{path/to/directory}} --autoload-file {{path/to/autoload_file}}

# Specify a memory limit during analysis
phpstan analyse {{path/to/directory}} --memory-limit {{memory_limit}}

# Run tests in the current directory. Note: Expects you to have a 'phpunit.xml'
phpunit

# Run tests in a specific file
phpunit {{path/to/TestFile.php}}

# Run tests annotated with the given group
phpunit --group {{name}}

# Run tests and generate a coverage report in HTML
phpunit --coverage-html {{directory}}

# Start Picard
picard

# Open a set of files
picard {{path/to/file1.mp3}} {{path/to/file2.mp3}}

# Display the version of Picard installed
picard --long-version

# Compress a file with default options
pigz {{filename}}

# Compress a file using the best compression method
pigz -9 {{filename}}

# Compress a file using no compression and 4 processors
pigz -0 -p{{4}} {{filename}}

# Decompress a file
pigz -d {{archive.gz}}

# List the contents of an archive
pigz -l {{archive.tar.gz}}

# Ping host
ping {{host}}

# Ping a host only a specific number of times
ping -c {{count}} {{host}}

# Ping host, specifying the interval in seconds between requests (default is 1 second)
ping -i {{seconds}} {{host}}

# Ping host without trying to lookup symbolic names for addresses
ping -n {{host}}

# Ping host and ring the bell when a packet is received (if your terminal supports it)
ping -a {{host}}

# Also display a message if no response was received
ping -O {{host}}

# Ping a host
ping6 {{host}}

# Ping a host only a specific number of times
ping6 -c {{count}} {{host}}

# Ping a host, specifying the interval in seconds between requests (default is 1 second)
ping6 -i {{seconds}} {{host}}

# Ping a host without trying to lookup symbolic names for addresses
ping6 -n {{host}}

# Ping a host and ring the bell when a packet is received (if your terminal supports it)
ping6 -a {{host}}

# Display details about the current user
pinky

# Display details for a specific user
pinky {{user}}

# Display details in the long format
pinky {{user}} -l

# Omit the user's home directory and shell in long format
pinky {{user}} -lb

# Omit the user's project file in long format
pinky {{user}} -lh

# Omit the column headings in short format
pinky {{user}} -f

# Install a package
pip install {{package_name}}

# Install a specific version of a package
pip install {{package_name}}=={{package_version}}

# Upgrade a package
pip install -U {{package_name}}

# Uninstall a package
pip uninstall {{package_name}}

# Save installed packages to file
pip freeze > {{requirements.txt}}

# Install packages from file
pip install -r {{requirements.txt}}

# Create a new project
pipenv

# Create a new project using Python 3
pipenv --three

# Install a package
pipenv install {{package_name}}

# Install all the dependencies for a project (including dev)
pipenv install --dev

# Uninstall a package
pipenv uninstall {{package_name}}

# Start a shell within the created virtual environment
pipenv shell

# Generate a requirements.txt for a project
pipenv lock --requirements

# Kill all processes which match
pkill -9 {{process_name}}

# Kill all processes which match their full command instead of just the process name
pkill -9 -f "{{command_name}}"

# Send SIGUSR1 signal to processes which match
pkill -USR1 {{process_name}}

# Play the given audio file
play {{audiofile}}

# Play the given audio files
play {{audiofile1}} {{audiofile2}}

# Play the given audio at twice the speed
play {{audiofile}} speed 2.0

# Play the given audio in reverse
play {{audiofile}} reverse

# Start a process with a name that can be used for later operations
pm2 start {{app.js}} --name {{myapp}}

# List processes
pm2 list

# Monitor all processes
pm2 monit

# Stop a process
pm2 stop {{myapp}}

# Restart a process
pm2 restart {{myapp}}

# Compress a PNG file
pngcrush {{in.png}} {{out.png}}

# Compress all PNGs and output to directory
pngcrush -d {{path/to/output}} *.png

# Compress PNG file with all 114 available algorithms and pick the best result
pngcrush -rem allb -brute -reduce {{in.png}} {{out.png}}

# Parse and transform a CSS file
postcss {{path/to/file}}

# Parse and transform a CSS file and output to a specific file
postcss {{path/to/file}} --output {{path/to/file}}

# Parse and transform a CSS file and output to a specific directory
postcss {{path/to/file}} --dir {{path/to/directory}}

# Parse and transform a CSS file in-place
postcss {{path/to/file}} --replace

# Specify a custom PostCSS parser
postcss {{path/to/file}} --parser {{parser}}

# Specify a custom PostCSS syntax
postcss {{path/to/file}} --syntax {{syntax}}

# Watch for changes to a CSS file
postcss {{path/to/file}} --watch

# Display available options and examples
postcss --help

# Display key-value pairs of all environment variables
printenv

# Display the value of a specific variable
printenv {{HOME}}

# Display the value of a variable and end with NUL instead of newline
printenv --null {{HOME}}

# Print a text message
printf {{"%s\n"}} {{"Hello world"}}

# Print an integer in bold blue
printf {{"\e[1;34m%.3d\e[0m\n"}} {{42}}

# Print a float number with the unicode Euro sign
printf {{"\u20AC %.2f\n"}} {{123.4}}

# Print a text message composed with environment variables
printf {{"var1: %s\tvar2: %s\n"}} {{"$VAR1"}} {{"$VAR2"}}

# Store a formatted message in a variable (does not work on zsh)
printf -v {{myvar}} {{"This is %s = %d\n" "a year" 2016}}

# Show the status of the Prosody server
sudo prosodyctl status

# Reload the server's configuration files
sudo prosodyctl reload

# Add a user to the Prosody XMPP server
sudo prosodyctl adduser {{user@example.com}}

# Set a user's password
sudo prosodyctl passwd {{user@example.com}}

# Permanently delete a user
sudo prosodyctl deluser {{user@example.com}}

# Generate Python code from a `.proto` file
protoc --python_out={{path/to/output_directory}} {{input_file.proto}}

# Generate Java code from a `.proto` file that imports other `.proto` files
protoc --java_out={{path/to/output_directory}} --proto_path={{path/to/import_search_path}} {{input_file.proto}}

# Generate code for multiple languages
protoc --csharp_out={{path/to/c#_output_directory}} --js_out={{path/to/js_output_directory}} {{input_file.proto}}

# List all running processes
ps aux

# List all running processes including the full command string
ps auxww

# Search for a process that matches a string
ps aux | grep {{string}}

# List all processes of the current user in extra full format
ps --user $(id -u) -F

# List all processes of the current user as a tree
ps --user $(id -u) f

# Get the parent pid of a process
ps -o ppid= -p {{pid}}

# Connect to database. It connects to localhost using default port 5432 with default user as currently logged in user
psql {{database}}

# Connect to database on given server host running on given port with given username, without a password prompt
psql -h {{host}} -p {{port}} -U {{username}} {{database}}

# Connect to database; user will be prompted for password
psql -h {{host}} -p {{port}} -U {{username}} -W {{database}}

# Execute a single SQL query or PostgreSQL command on the given database (useful in shell scripts)
psql -c '{{query}}' {{database}}

# Execute commands from a file on the given database
psql {{database}} -f {{file.sql}}

# Run a command on two hosts, and print its output on each server inline
pssh -i -H "{{host1}} {{host2}}" {{hostname -i}}

# Run a command and save the output to separate files
pssh -H {{host1}} -H {{host2}} -o {{path/to/output_dir}} {{hostname -i}}

# Run a command on multiple hosts, specified in a new-line separated file
pssh -i -h {{path/to/hosts_file}} {{hostname -i}}

# Run a command as root (this asks for the root password)
pssh -i -h {{path/to/hosts_file}} -A -l {{root_username}} {{hostname -i}}

# Run a command with extra SSH arguments
pssh -i -h {{path/to/hosts_file}} -x "{{-O VisualHostKey=yes}}" {{hostname -i}}

# Run a command limiting the number of parallel connections to 10
pssh -i -h {{path/to/hosts_file}} -p {{10}} '{{cd dir; ./script.sh; exit}}'

# Find files containing "foo" and print the files with highlighted matches
pt {{foo}}

# Find files containing "foo" and display count of matches in each file
pt -c {{foo}}

# Find files containing "foo" as a whole word and ignore its case
pt -wi {{foo}}

# Find "foo" in files with a given extension using a regular expression
pt -G='{{\.bar$}}' {{foo}}

# Find files whose contents match the regular expression, up to 2 folders deep
pt --depth={{2}} -e '{{^ba[rz]*$}}'

# Transform a raw HTML file into a cleaned, indented, and colored format
cat {{index.html}} | pup --color

# Filter HTML by element tag name
cat {{index.html}} | pup '{{tag}}'

# Filter HTML by id
cat {{index.html}} | pup '{{div#id}}'

# Filter HTML by attribute value
cat {{index.html}} | pup '{{input[type="text"]}}'

# Print all text from the filtered HTML elements and their children
cat {{index.html}} | pup '{{div}} text{}'

# Print HTML as JSON
cat {{index.html}} | pup '{{div}} json{}'

# Print the contents of the file and display a progress bar
pv {{file}}

# Measure the speed and amount of data flow between pipes (`-s` is optional)
command1 | pv -s {{expected_amount_of_data_for_eta}} | command2

# Filter a file, see both progress and amount of output data
pv -cN in {{big_text_file}} | grep {{pattern}} | pv -cN out > {{filtered_file}}

# Attach to an already running process and see its file reading progress
pv -d {{PID}}

# Read an erroneous file, skip errors as `dd conv=sync,noerror` would
pv -EE {{path/to/faulty_media}} > image.img

# Stop reading after reading specified amount of data, rate limit to 1K/s
pv -L 1K -S {{maximum_file_size_to_be_read}}

# Print the current directory
pwd

# Print the current directory, and resolve all symlinks (i.e. show the "physical" path)
pwd -P

# Check the style of a single file
pycodestyle {{file.py}}

# Check the style of multiple files
pycodestyle {{file1.py}} {{file2.py}} {{file3.py}}

# Show only the first occurrence of an error
pycodestyle --first {{file.py}}

# Show the source code for each error
pycodestyle --show-source {{file.py}}

# Show the specific PEP 8 text for each error
pycodestyle --show-pep8 {{file.py}}

# List all available commands
pyenv commands

# List all Python versions under the ${PYENV_ROOT}/versions directory
pyenv versions

# Install a Python version under the ${PYENV_ROOT}/versions directory
pyenv install {{2.7.10}}

# Uninstall a Python version under the ${PYENV_ROOT}/versions directory
pyenv uninstall {{2.7.10}}

# Set Python version to be used globally in the current machine
pyenv global {{2.7.10}}

# Set Python version to be used in the current directory and all directories below it
pyenv local {{2.7.10}}

# Highlight file syntax and print to standard output (language is inferred from the file extension)
pygmentize {{file.py}}

# Explicitly set the language for syntax highlighting
pygmentize -l {{javascript}} {{input_file}}

# List available lexers (processors for input languages)
pygmentize -L lexers

# Save output to a file in HTML format
pygmentize -f html -o {{output_file.html}} {{input_file.py}}

# List available output formats
pygmentize -L formatters

# Output an HTML file, with additional formatter options (full page, with line numbers)
pygmentize -f html -O "full,linenos=True" -o {{output_file.html}} {{input_file}}

# Call a Python interactive shell (REPL)
python

# Execute script in a given Python file
python {{script.py}}

# Execute script as part of an interactive shell
python -i {{script.py}}

# Execute a Python expression
python -c "{{expression}}"

# Run library module as a script (terminates option list)
python -m {{module}} {{arguments}}

# Interactively debug a Python script
python -m pdb {{script.py}}

# Query .csv file by specifying the delimiter as ','
q -d',' "SELECT * from {{path/to/file}}"

# Query .tsv file
q -t "SELECT * from {{path/to/file}}"

# Query file with header row
q -d{{delimiter}} -H "SELECT * from {{path/to/file}}"

# Read data from stdin; '-' in the query represents the data from stdin
{{output}} | q "select * from -"

# Join two files (aliased as `f1` and `f2` in the example) on column `c1`, a common column
q "SELECT * FROM {{path/to/file}} f1 JOIN {{path/to/other_file}} f2 ON (f1.c1 = f2.c1)"

# Format output using an output delimiter with an output header line (note: command will output column names based on the input file header or the column aliases overridden in the query)
q -D{{delimiter}} -O "SELECT {{column}} as {{alias}} from {{path/to/file}}"

# Create disk image with a specific size (in gigabytes)
qemu-img create {{image_name.img}} {{gigabites}}G

# Show information about a disk image
qemu-img info {{image_name.img}}

# Increase or decrease image size
qemu-img resize {{image_name.img}} {{gigabites}}G

# Dump the allocation state of every sector of the specified disk image
qemu-img map {{image_name.img}}

# Boot from image emulating i386 architecture
qemu-system-i386 -hda {{image_name.img}}

# Boot from image emulating x64 architecture
qemu-system-x86_64 -hda {{image_name.img}}

# Boot QEMU instance with a live ISO image
qemu-system-i386 -hda {{image_name.img}} -cdrom {{os_image.iso}} -boot d

# Specify amount of RAM for instance
qemu-system-i386 -m 256 -hda image_name.img -cdrom os-image.iso -boot d

# Boot from physical device (e.g. from USB to test bootable medium)
qemu-system-i386 -hda /dev/{{storage_device}}

# Extract pages 1-3, 5 and 6-10 from a PDF file and save them as another one
qpdf --empty --pages {{input.pdf}} {{1-3,5,6-10}} -- {{output.pdf}}

# Merge (concatenate) a list of PDF files and save the result as another one
qpdf --empty --pages {{file1.pdf}} {{1,6-8}} --pages {{file2.pdf}} {{3,4,5}} -- {{output.pdf}}

# Write each group of n pages to a separate output file with a given filename pattern
qpdf --split-pages=n {{input.pdf}} {{out_%d.pdf}}

# Rotate certain pages of a pdf with a given angle
qpdf --rotate={{90:2,4,6}} --rotate={{180:7-8}} {{input.pdf}} {{output.pdf}}

# Remove the password from a password protected file
qpdf --password={{password}} --decrypt {{input.pdf}} {{output.pdf}}

# Show disk quotas in human readable units for the current user
quota -s

# Verbose output (also display quotas on filesystems where no storage is allocated)
quota -v

# Quiet output (only display quotas on filesystems where usage is over quota)
quota -q

# Print quotas for the groups of which the current user is a member
quota -g

# Show disk quotas for another user
sudo quota -u {{username}}

# Start an R interactive shell (REPL)
R

# Check R version
R --version

# Execute a file
R -f {{file.R}}

# Display general information about a binary (architecture, type, endianness)
rabin2 -I {{path/to/binary}}

# Display linked libraries
rabin2 -l {{path/to/binary}}

# Display symbols imported from libraries
rabin2 -i {{path/to/binary}}

# Display strings contained in the binary
rabin2 -z {{path/to/binary}}

# Display the output in JSON
rabin2 -j -I {{path/to/binary}}

# Create a new rails project
rails new "{{project_name}}"

# Start local server for current project on port 3000
rails server

# Start local server for current project on a specified port
rails server -p "{{port}}"

# Open console to interact with application from command line
rails console

# Check current version of rails
rails --version

# Open rainbowstream
rainbowstream

# Show your timeline (optional number of tweets to display, default is 5)
home [{{num_of_last_tweets}}]

# Show profile of a given user
whois @{{user}}

# Tweet the message as-is
t {{message}}

# Retweet the tweet with given id (id is beside the time)
rt {{tweet_id}}

# Favorite the tweet with given id
fav {{tweet_id}}

# Perform a search for a given word (with or without hashtag)
s {{word}}

# Start rbash
rbash

# Execute a command
rbash -c "{{command}}"

# Run commands from a file
rbash {{file.sh}}

# Print the version information of rbash
rbash --version

# Install one or more space-separated versions of Ruby
rbenv install {{version(s)}}

# Display a list of installed versions
rbenv versions

# Use a specific version of Ruby across the whole system
rbenv global {{version}}

# Use a specific version of Ruby for an application/project folder
rbenv local {{version}}

# Show the currently selected Ruby version
rbenv version

# Uninstall a version of Ruby
rbenv uninstall {{version}}

# Display all ruby versions that contain the specified executable
rbenv whence {{executable}}

# Identify all duplicates in a given directory and output a summary
rdfind -dryrun true {{path/to/directory}}

# Replace all duplicates with hardlinks
rdfind -makehardlinks true {{path/to/directory}}

# Replace all duplicates with symlinks/soft links
rdfind -makesymlinks true {{path/to/directory}}

# Delete all duplicates and do not ignore empty files
rdfind -deleteduplicates true -ignoreempty false {{path/to/directory}}

# Store data that you type from the keyboard
read {{variable}}

# Store each of the next lines you enter as values of an array
read -a {{array}}

# Enable backspace and GNU readline hotkeys when entering input with read
read -e {{variable}}

# Specify the number of maximum characters to be read
read -n {{character_count}} {{variable}}

# Use a specific character as a delimiter instead of a new line
read -d {{new_delimiter}} {{variable}}

# Do not let backslash (\) act as an escape character
read -r {{variable}}

# Get the actual file to which the symlink points
readlink {{filename}}

# Get the absolute path to a file
readlink -f {{filename}}

# Display the absolute path for a file or directory
realpath {{path/to/file_or_directory}}

# Require all path components to exist
realpath --canonicalize-existing {{path/to/file_or_directory}}

# Resolve ".." components before symlinks
realpath --logical {{path/to/file_or_directory}}

# Disable symlink expansion
realpath --no-symlinks {{path/to/file_or_directory}}

# Suppress error messages
realpath --quiet {{path/to/file_or_directory}}

# Connect to the local server
redis-cli

# Connect to a remote server on the default port (6379)
redis-cli -h {{host}}

# Connect to a remote server specifying a port number
redis-cli -h {{host}} -p {{port}}

# Specify a password
redis-cli -a {{password}}

# Execute Redis command
redis-cli {{redis_command}}

# Turn on Redshift with 5700K temperature during day and 3600K at night
redshift -t {{5700}}:{{3600}}

# Turn on Redshift with a manually-specified custom location
redshift -l {{latitude}}:{{longitude}}

# Turn on Redshift with 70% screen brightness during day and 40% brightness at night
redshift -b {{0.7}}:{{0.4}}

# Turn on Redshift with custom gamma levels (between 0 and 1)
redshift -g {{red}}:{{green}}:{{blue}}

# Turn on Redshift with a constant unchanging color temperature
redshift -O {{temperature}}

# Rename files using a Perl Common Regular Expression (substitute 'foo' with 'bar' wherever found)
rename {{'s/foo/bar/'}} {{\*}}

# Dry-run - display which renames would occur without performing them
rename -n {{'s/foo/bar/'}} {{\*}}

# Force renaming even if the operation would overwrite existing files
rename -f {{'s/foo/bar/'}} {{\*}}

# Convert filenames to lower case (use `-f` in case-insensitive filesystems to prevent "already exists" errors)
rename 'y/A-Z/a-z/' {{\*}}

# Replace whitespace with underscores
rename 's/\s+/_/g' {{\*}}

# Change priority of a running process
renice -n {{niceness_value}} -p {{pid}}

# Change priority of all processes owned by a user
renice -n {{niceness_value}} -u {{user}}

# Change priority of all processes that belong to a process group
renice -n {{niceness_value}} --pgrp {{process_group}}

# Do a dry-run renaming a folder of pngs with a literal string replacement
repren --dry-run --rename --literal --from '{{find_string}}' --to '{{replacement_string}}' {{*.png}}

# Do a dry-run renaming a folder of jpegs with a regular expression
repren --rename --dry-run --from '{{regular_expression}}' --to '{{replacement_string}}' {{*.jpg}} {{*.jpeg}}

# Do a find-and-replace on the contents of a folder of csv files
repren --from '{{([0-9]+) example_string}}' --to '{{replacement_string \1}}' {{*.csv}}

# Do both a find-and-replace and a rename operation at the same time, using a pattern file
repren --patterns {{path/to/patfile.ext}} --full {{*.txt}}

# Do a case-insensitive rename
repren --rename --insensitive --patterns {{path/to/patfile.ext}} *

# Initialize a backup repository in the specified local directory
restic init -r {{path/to/repository}}

# Backup folder "my_folder" to the repository
restic -r {{path/to/repository}} backup {{path/to/my_folder}}

# Show backup snapshots currently stored in the repository
restic -r {{path/to/repository}} snapshots

# Restore a specific backup snapshot to a target directory
restic -r {{path/to/repository}} restore {{snapshot_id}} {{path/to/target}}

# Clean up the repository and keep only the most recent snapshot of each unique backup
restic forget --keep-last 1 --prune

# Reverse the text string "hello"
echo "hello" | rev

# Reverse an entire file and print to stdout
rev {{file}}

# Recursively search the current directory for a regex pattern
rg {{pattern}}

# Search for pattern including all .gitignored and hidden files
rg -uu {{pattern}}

# Search for a pattern only in a certain filetype (e.g., html, css, etc.)
rg -t {{filetype}} {{pattern}}

# Search for a pattern only in a subset of directories
rg {{pattern}} {{set_of_subdirs}}

# Search for a pattern in files matching a glob (e.g., `README.*`)
rg {{pattern}} -g {{glob}}

# Only list matched files -- useful when piping to other commands
rg --files-with-matches {{pattern}}

# Remove files from arbitrary locations
rm {{path/to/file}} {{path/to/another/file}}

# Recursively remove a directory and all its subdirectories
rm -r {{path/to/folder}}

# Forcibly remove a directory, without prompting for confirmation or showing error messages
rm -rf {{path/to/folder}}

# Interactively remove multiple files, with a prompt before every removal
rm -i {{file(s)}}

# Remove files in verbose mode, printing a message for each removed file
rm -v {{path/to/folder/*}}

# Remove directory, provided it is empty. Use `rm` to remove not empty directories
rmdir {{path/to/directory}}

# Remove directories recursively (useful for nested dirs)
rmdir -p {{path/to/directory}}

# Roll 3 6-sided dice and sums the results
roll {{3d}}

# Roll 1 8-sided die, add 3 and sum the results
roll {{d8 + 3}}

# Roll 4 6-sided dice, keep the 3 highest results and sum the results
roll {{4d6h3}}

# Roll 2 12-sided dice 2 times and show every roll
roll --verbose {{2{2d12}}}

# Roll 2 20-sided dice until the result is bigger than 10
roll "{{2d20>10}}"

# Roll 2 5-sided dice 3 times and show the total sum
roll --sum-series {{3{2d5}}}

# Display the information of route table
route -n

# Add route rule
sudo route add -net {{ip_address}} netmask {{netmask_address}} gw {{gw_address}}

# Delete route rule
sudo route del -net {{ip_address}} netmask {{netmask_address}} dev {{gw_address}}

# Show the feed of a given url and wait for new entries appearing at the bottom
rsstail -u {{url}}

# Show the feed in reverse chronological order (newer at the bottom)
rsstail -r -u {{url}}

# Include publication date and link
rsstail -pl -u {{url}}

# Set update interval
rsstail -u {{url}} -i {{interval_in_seconds}}

# Show feed and exit
rsstail -1 -u {{url}}

# Transfer file from local to remote host
rsync {{path/to/file}} {{remote_host_name}}:{{remote_host_location}}

# Transfer file from remote host to local
rsync {{remote_host_name}}:{{remote_file_location}} {{local_file_location}}

# Transfer file in archive (to preserve attributes) and compressed (zipped) mode with verbose and human-readable progress
rsync -azvhP {{path/to/file}} {{remote_host_name}}:{{remote_host_location}}

# Transfer a directory and all its children from a remote to local
rsync -r {{remote_host_name}}:{{remote_folder_location}} {{local_folder_location}}

# Transfer only updated files from remote host
rsync -ru {{remote_host_name}}:{{remote_folder_location}} {{local_folder_location}}

# Transfer file over SSH and show progress per file
rsync -e ssh --progress {{remote_host_name}}:{{remote_file}} {{local_file}}

# Transfer file over SSH and show global progress
rsync -e ssh --info=progress2 {{remote_host_name}}:{{remote_file}} {{local_file}}

# Open the front page
/front

# Open a subreddit
/r/{{subreddit_name}}

# Expand/collapse comments
[space]

# Open link
o

# Login
u

# Open the help screen
?

# Open an Interactive Ruby Shell (REPL)
irb

# Execute a Ruby script
ruby {{script.rb}}

# Execute a single Ruby command in the command line
ruby -e {{command}}

# Check for syntax errors on a given Ruby script
ruby -c {{script.rb}}

# Show the version of Ruby you are using
ruby -v

# Compile a single file
rustc {{file.rs}}

# Compile with high optimization
rustc -O {{file.rs}}

# Compile with debugging information
rustc -g {{file.rs}}

# Format a file, overwriting the original file in-place
rustfmt {{source.rs}}

# Check a file for formatting and display any changes on the console
rustfmt --check {{source.rs}}

# Backup any modified files before formatting (the original file is renamed with a `.bk` extension)
rustfmt --backup {{source.rs}}

# Install the nightly toolchain for your system
rustup install nightly

# Switch the default toolchain to nightly so that the `cargo` and `rustc` commands will use it
rustup default nightly

# Use the nightly toolchain when inside the current project, but leave global settings unchanged
rustup override set nightly

# Update all toolchains
rustup update

# List installed toolchains
rustup show

# Run cargo build with a certain toolchain
rustup run {{toolchain_name}} cargo build

# Install one or more space-separated versions of Ruby
rvm install {{version(s)}}

# Display a list of installed versions
rvm list

# Use a specific version of Ruby
rvm use {{version}}

# Set the default Ruby version
rvm --default use {{version}}

# Upgrade a version of Ruby to a new version
rvm upgrade {{current_version}} {{new_version}}

# Uninstall a version of Ruby and keep its sources
rvm uninstall {{version}}

# Remove a version of Ruby and its sources
rvm remove {{version}}

# Search for a query on Google(default provider)
s {{query}}

# List all providers
s --list-providers

# Search for a query with a given provider
s --provider {{provider}} {{query}}

# Use a specified binary to perform the search query
s --binary "{{binary}} {{arguments}}" {{query}}

# Start Sails
sails lift

# Create new Sails project
sails new {{projectName}}

# Generate Sails API
sails generate {{name}}

# Generate Sails Controller
sails generate controller {{name}}

# Generate Sails Model
sails generate model {{name}}

# Perform a highstate on this minion
salt-call state.highstate

# Perform a highstate dry-run, compute all changes but don't actually perform them
salt-call state.highstate test=true

# Perform a highstate with verbose debugging output
salt-call -l debug state.highstate

# List this minion's grains
salt-call grains.items

# List all accepted, unaccepted and rejected minion keys
salt-key -L

# Accept a minion key by name
salt-key -a {{MINION_ID}}

# Reject a minion key by name
salt-key -r {{MINION_ID}}

# Print fingerprints of all public keys
salt-key -F

# Show status of all minions
salt-run manage.status

# Show all minions which are disconnected
salt-run manage.up

# List connected minions
salt '*' test.ping

# Execute a highstate on all connected minions
salt '*' state.highstate

# Upgrade packages using the OS package manager (apt, yum, brew) on a subset of minions
salt '*.domain.com' pkg.upgrade

# Execute an arbitrary command on a particular minion
salt '{{minion_id}}' cmd.run "ls "

# Convert a SAM input file to BAM stream and save to file
samtools view -S -b {{input.sam}} > {{output.bam}}

# Take input from stdin (-) and print the SAM header and any reads overlapping a specific region to stdout
{{other_command}} | samtools view -h - chromosome:start-end

# Sort file and save to BAM (the output format is automatically determined from the output file's extension)
samtools sort {{input}} -o {{output.bam}}

# Index a sorted BAM file (creates {{sorted_input.bam.bai}})
samtools index {{sorted_input.bam}}

# Print alignment statistics about a file
samtools flagstat {{sorted_input}}

# Count alignments to each index (chromosome / contig)
samtools idxstats {{sorted_indexed_input}}

# Merge multiple files
samtools merge {{output}} {{input_1}} [{{input_2}}...]

# Split input file according to read groups
samtools split {{merged_input}}

# Convert a SCSS or Sass file to CSS and print out the result
sass {{inputfile.scss|inputfile.sass}}

# Convert a SCSS or Sass file to CSS and save the result to a file
sass {{inputfile.scss|inputfile.sass}} {{outputfile.css}}

# Watch a SCSS or Sass file for changes and output or update the CSS file with same filename
sass --watch {{inputfile.scss|inputfile.sass}}

# Watch a SCSS or Sass file for changes and output or update the CSS file with the given filename
sass --watch {{inputfile.scss|inputfile.sass}}:{{outputfile.css}}

# Start SC-IM
scim {{file_name}}.csv

# Enter a string into the current cell
< or >

# Enter a numeric constant into the current cell
=

# Edit string in the current cell
E

# Edit number in the current cell
e

# Center align the current cell
|

# Start a Scala interactive shell (REPL)
scala

# Execute a Scala script
scala {{script.scala}}

# Execute a .jar program
scala {{filename.jar}}

# Execute a single Scala command in the command line
scala -e {{command}}

# Open an interactive shell (REPL)
scheme

# Run a scheme program (with no REPL output)
scheme --quiet < {{script.scm}}

# Load a scheme program into the REPL
scheme --load {{script.scm}}

# Load scheme expressions into the REPL
scheme --eval {{"(define foo 'x)"}}

# Open the REPL in quiet mode
scheme --quiet

# Copy a local file to a remote host
scp {{path/to/local_file}} {{remote_host}}:{{path/to/remote_file}}

# Copy a file from a remote host to a local folder
scp {{remote_host}}:{{path/to/remote_file}} {{path/to/local_dir}}

# Recursively copy the contents of a directory from a remote host to a local directory
scp -r {{remote_host}}:{{path/to/remote_dir}} {{path/to/local_dir}}

# Copy a file between two remote hosts transferring through the local host
scp -3 {{host1}}:{{path/to/remote_file}} {{host2}}:{{path/to/remote_dir}}

# Use a specific username when connecting to the remote host
scp {{path/to/local_file}} {{remote_username}}@{{remote_host}}:{{path/to/remote_dir}}

# Use a specific ssh private key for authentication with the remote host
scp -i {{~/.ssh/private_key}} {{local_file}} {{remote_host}}:{{/path/remote_file}}

# Create a project
scrapy startproject {{project_name}}

# Create a spider (in project directory)
scrapy genspider {{spider_name}} {{website_domain}}

# Edit spider (in project directory)
scrapy edit {{spider_name}}

# Run spider (in project directory)
scrapy crawl {{spider_name}}

# Fetch a webpage as scrapy sees it and print source in stdout
scrapy fetch {{url}}

# Open a webpage in the default browser as scrapy sees it (disable javascript for extra fidelity)
scrapy view {{url}}

# Open scrapy shell for url, which allows interaction with the page source in python shell (or ipython if available)
scrapy shell {{url}}

# Start a new screen session
screen

# Start a new named screen session
screen -S {{session_name}}

# Start a new daemon and log the output to screenlog.x
screen -dmLS {{session_name}} {{command}}

# Show open screen sessions
screen -ls

# Reattach to an open screen
screen -r {{session_name}}

# Detach from inside a screen
Ctrl + A, D

# Kill a detached screen
screen -X -S {{session_name}} quit

# Start screenfetch
screenfetch

# Take a screenshot (requires 'scrot')
screenfetch -s

# Specify distribution logo
screenfetch -A '{{distribution_name}}'

# Specify distribution logo and text
screenfetch -D '{{distribution_name}}'

# Strip all color
screenfetch -N

# Start recording in file named "typescript"
script

# Stop recording
exit

# Start recording in a given file
script {{logfile.log}}

# Append to an existing file
script -a {{logfile.log}}

# Execute quietly without start and done messages
script -q {{logfile.log}}

# Install a specific version of Gradle
sdk install {{gradle}} {{gradle_version}}

# Switch to a specific version of Gradle
sdk use {{gradle}} {{gradle_version}}

# Check current Gradle version
sdk current {{gradle}}

# List all Software Development Kits available to install
sdk list

# Update Gradle to the latest version
sdk upgrade {{gradle}}

# Uninstall a particular version of Gradle
sdk rm {{gradle}} {{gradle_version}}

# Replace the first occurrence of a string in a file, and print the result
sed 's/{{find}}/{{replace}}/' {{filename}}

# Replace all occurrences of an extended regular expression in a file
sed -r 's/{{regex}}/{{replace}}/g' {{filename}}

# Replace all occurrences of a string in a file, overwriting the file (i.e. in-place)
sed -i 's/{{find}}/{{replace}}/g' {{filename}}

# Replace only on lines matching the line pattern
sed '/{{line_pattern}}/s/{{find}}/{{replace}}/' {{filename}}

# Print only text between n-th line till the next empty line
sed -n '{{line_number}},/^$/p' {{filename}}

# Apply multiple find-replace expressions to a file
sed -e 's/{{find}}/{{replace}}/' -e 's/{{find}}/{{replace}}/' {{filename}}

# Replace separator / by any other character not used in the find or replace patterns, e.g., #
sed 's#{{find}}#{{replace}}#' {{filename}}

# Send a message with the content of message.txt to the mail folder of local user `user_name`
sendmail {{user_name}} < {{message.txt}}

# Send an email from you@yourdomain.com (assuming the mail server is configured for this) to test@gmail.com containing the message in `message.txt`
sendmail -f {{you@yourdomain.com}} {{test@gmail.com}} < {{message.txt}}

# Send an email from you@yourdomain.com (assuming the mail server is configured for this) to test@gmail.com containing the file `file.zip`
sendmail -f {{you@yourdomain.com}} {{test@gmail.com}} < {{file.zip}}

# Sequence from 1 to 10
seq 10

# Every 3rd number from 5 to 20
seq 5 3 20

# Separate the output with a space instead of a newline
seq -s " " 5 3 20

# Create a serverless project
serverless create

# Create a serverless project from a template
serverless create --template {{template_name}}

# Deploy to a cloud provider
serverless deploy

# Display information about a serverless project
serverless info

# Invoke a deployed function
serverless invoke -f {{function_name}}

# Follow the logs for a project
serverless logs -t

# Display the names and values of shell variables
set

# Mark variables that are modified or created for export
set -a

# Notify of job termination immediately
set -b

# Set various options, e.g. enable `vi` style line editing
set -o {{vi}}

# Connect to a remote server and enter an interactive command mode
sftp {{remote_user}}@{{remote_host}}

# Connect using an alternate port
sftp -P {{remote_port}} {{remote_user}}@{{remote_host}}

# Transfer remote file to the local system
get {{/path/remote_file}}

# Transfer local file to the remote system
put {{/path/local_file}}

# Transfer remote folder to the local system recursively (works with `put` too)
get -R {{/path/remote_folder}}

# Get list of files on local machine
lls

# Get list of files on remote machine
ls

# Start interactive shell
sh

# Execute a command
sh -c {{command}}

# Run commands from a file
sh {{file.sh}}

# Run commands from STDIN
sh -s

# Calculate the SHA1 checksum for a file
sha1sum {{filename1}}

# Calculate SHA1 checksums for multiple files
sha1sum {{filename1}} {{filename2}}

# Read a file of SHA1 sums and verify all files have matching checksums
sha1sum -c {{filename.sha1}}

# Calculate the SHA224 checksum for a file
sha224sum {{filename1}}

# Calculate SHA224 checksums for multiple files
sha224sum {{filename1}} {{filename2}}

# Read a file of SHA224 sums and verify all files have matching checksums
sha224sum -c {{filename.sha224}}

# Calculate the SHA256 checksum for a file
sha256sum {{filename1}}

# Calculate SHA256 checksums for multiple files
sha256sum {{filename1}} {{filename2}}

# Read a file of SHA256 sums and verify all files have matching checksums
sha256sum -c {{filename.sha256}}

# Calculate the SHA384 checksum for a file
sha384sum {{filename1}}

# Calculate SHA384 checksums for multiple files
sha384sum {{filename1}} {{filename2}}

# Read a file of SHA384 sums and verify all files have matching checksums
sha384sum -c {{filename.sha384}}

# Calculate the SHA512 checksum for a file
sha512sum {{filename1}}

# Calculate SHA512 checksums for multiple files
sha512sum {{filename1}} {{filename2}}

# Read a file of SHA512 sums and verify all files have matching checksums
sha512sum -c {{filename.sha512}}

# Create a skeleton shard.yml file
shards init

# Install dependencies from a shard.yml file
shards install

# Update all dependencies
shards update

# List all installed dependencies
shards list

# List version of dependency
shards version {{path/to/dependency_folder}}

# Compile a shell script
shc -f {{script}}

# Compile a shell script and specify an output binary file
shc -f {{script}} -o {{binary}}

# Compile a shell script and set an expiration date for the executable
shc -f {{script}} -e {{dd/mm/yyyy}}

# Compile a shell script and set a message to display upon expiration
shc -f {{script}} -e {{dd/mm/yyyy}} -m {{"Please contact your provider"}}

# Check a shell script
shellcheck {{file.sh}}

# Override script's shebang
shellcheck --shell {{sh|bash|ksh}} {{file.sh}}

# Ignore certain errors
shellcheck --exclude {{SC1009}} {{file.sh}}

# Ignore multiple errors
shellcheck --exclude {{SC1009,SC1073}} {{file.sh}}

# List of all settable options and whether they are set
shopt

# Set an option
shopt -s {{option_name}}

# Unset an option
shopt -u {{option_name}}

# Print a list of all options and their status formatted as runnable `shopt` commands
shopt -p

# Show help for the command
help shopt

# Overwrite a file
shred {{file}}

# Overwrite a file, leaving zeroes instead of random data
shred --zero {{file}}

# Overwrite a file 25 times
shred -n25 {{file}}

# Overwrite a file and remove it
shred --remove {{file}}

# Randomize the order of lines in a file and output the result
shuf {{filename}}

# Only output the first 5 entries of the result
shuf -n {{5}} {{filename}}

# Write the output to another file
shuf {{filename}} -o {{output_filename}}

# Generate random numbers in range
shuf -i {{1-10}}

# Download a remote image
singularity pull --name {{container.simg}} {{shub://vsoch/hello-world}}

# Rebuild a remote image using latest Singularity image format
singularity build {{container.simg}} {{docker://godlovedc/lolcow}}

# Start a container from an image and get a shell inside of it
singularity shell {{container.simg}}

# Start a container from an image and run a command
singularity exec {{container.simg}} {{command}}

# Start a container from an image and execute the internal runscript
singularity run {{container.simg}}

# Build a singularity image from a recipe file
sudo singularity build {{container.simg}} {{recipe}}

# Upload a file/folder to Google Drive
skicka upload {{path/to/local}} {{path/to/remote}}

# Download a file/folder from Google Drive
skicka download {{path/to/remote}} {{path/to/local}}

# List files
skicka ls {{path/to/folder}}

# Show amount of space used by children folders
skicka du {{path/to/parent/folder}}

# Create a folder
skicka mkdir {{path/to/folder}}

# Delete a file
skicka rm {{path/to/file}}

# Let a steam locomotive run through your terminal
sl

# The train burns, people scream
sl -a

# Let the train fly
sl -F

# Make the train little
sl -l

# Let the user exit (CTRL + C)
sl -e

# Post a file to Slack
slackcat --channel {{channel_name}} {{path/to/file}}

# Post a file to Slack with a custom filename
slackcat --channel {{channel_name}} --filename={{filename}} {{path/to/file}}

# Pipe command output to Slack as a text snippet
{{command}} | slackcat --channel {{channel_name}} --filename={{snippet_name}}

# Stream command output to Slack continuously
{{command}} | slackcat --channel {{channel_name}} --stream

# Delay in seconds
sleep {{seconds}}

# Delay in minutes
sleep {{minutes}}m

# Delay in hours
sleep {{hours}}h

# Convert a Slim file to HTML
slimrb {{input.slim}} {{output.html}}

# Convert a Slim file and output to prettified HTML
slimrb --pretty {{input.slim}} {{output.html}}

# Convert a Slim file to ERB
slimrb --erb {{input.slim}} {{output.erb}}

# View SMART health summary
sudo smartctl --health {{/dev/sda}}

# View device information
sudo smartctl --info {{/dev/sda}}

# Begin a short self-test
sudo smartctl --test short {{/dev/sda}}

# View current/last self-test status and other SMART capabilities
sudo smartctl --capabilities {{/dev/sda}}

# View SMART self-test log (if supported)
sudo smartctl --log selftest {{/dev/sda}}

# Listen to a port, wait for an incoming connection and transfer data to STDIO
socat - TCP-LISTEN:8080,fork

# Create a connection to a host and port, transfer data in STDIO to connected host
socat - TCP4:www.domain.com:80

# Forward incoming data of a local port to another host and port
socat TCP-LISTEN:80,fork TCP4:www.domain.com:80

# Sort a file in ascending order
sort {{filename}}

# Sort a file in descending order
sort -r {{filename}}

# Sort a file using numeric rather than alphabetic order
sort -n {{filename}}

# Sort the passwd file by the 3rd field, numerically
sort -t: -k 3n /etc/passwd

# Sort a file preserving only unique lines
sort -u {{filename}}

# Sort human-readable numbers (in this case the 5th field of `ls -lh`)
ls -lh | sort -h -k 5

# Evaluate contents of a given file
source {{path/to/file}}

# Merge two audio files into one
sox -m {{input_audiofile1}} {{input_audiofile2}} {{output_audiofile}}

# Trim an audio file to the specified times
sox {{input_audiofile}} {{output_audiofile}} trim {{start}} {{end}}

# Normalize an audio file (adjust volume to the maximum peak level, without clipping)
sox --norm {{input_audiofile}} {{output_audiofile}}

# Reverse and save an audio file
sox {{input_audiofile}} {{output_audiofile}} reverse

# Print statistical data of an audio file
sox {{input_audiofile}} -n stat

# Increase the volume of an audio file by 2x
sox -v 2.0 {{input_audiofile}} {{output_audiofile}}

# Run this when you use a project for the first time
spatial worker build

# Build workers for local deployment on Unity on macOS
spatial worker build --target=development --target=Osx

# Build workers for local deployment on Unreal on Windows
spatial worker build --target=local --target=Windows

# Deploy locally
spatial local launch {{launch_config}} --snapshot={{snapshot_file}}

# Launch a local worker to connect to your local deployment
spatial local worker launch {{worker_type}} {{launch_config}}

# Upload an assembly to use for cloud deployments
spatial cloud upload {{assembly_name}}

# Launch a cloud deployment
spatial cloud launch {{assembly_name}} {{launch_config}} {{deployment_name}}

# Clean worker directories
spatial worker clean

# Run a speed test
speedtest-cli

# Run a speed test and generate a shareable result picture
speedtest-cli --share

# Print a list of all speedtest.net servers, sorted by distance, to file
speedtest-cli --list > speedtest_servers.txt

# Run a speed test to the given speedtest.net server id
speedtest-cli --server {{server_id}}

# Create a new project using the default template
spike new {{project_name}}

# Compile your project, watch for changes, and auto-reload the browser
spike watch

# Compile your project once to the "public" folder
spike compile

# Remove the output directory
spike clean

# Split a file, each split having 10 lines (except the last split)
split -l {{10}} {{filename}}

# Split a file into 5 files. File is split such that each split has same size (except the last split)
split -n {{5}} {{filename}}

# Split a file with 512 bytes in each split (except the last split; use 512k for kilobytes and 512m for megabytes)
split -b {{512}} {{filename}}

# Split a file with at most 512 bytes in each split without breaking lines
split -C {{512}} {{filename}}

# Start an interactive shell with a new database
sqlite3

# Open an interactive shell against an existing database
sqlite3 {{path/to/database.sqlite3}}

# Execute an SQL statement against a database and then exit
sqlite3 {{path/to/database.sqlite3}} '{{SELECT * FROM some_table;}}'

# Run sqlmap against a single target URL
python sqlmap.py -u {{"http://www.target.com/vuln.php?id=1"}}

# Send data in a POST request (`--data` implies POST request)
python sqlmap.py -u {{"http://www.target.com/vuln.php" --data={{"id=1"}}

# Change the parameter delimiter (& is the default)
python sqlmap.py -u {{"http://www.target.com/vuln.php"}} --data={{"query=foobar;id=1"}} --param-del={{";"}}

# Select a random `User-Agent` from `./txt/user-agents.txt` and use it
python sqlmap.py -u {{"http://www.target.com/vuln.php"}} --random-agent

# Provide user credentials for HTTP protocol authentication
python sqlmap.py -u {{"http://www.target.com/vuln.php"}} --auth-type {{Basic}} --auth-cred {{"testuser:testpass"}}

# List all queues
sqsc lq {{queue_prefix}}

# List all messages in a queue
sqsc ls {{queue_name}}

# Copy all messages from one queue to another
sqsc cp {{source_queue}} {{destination_queue}}

# Move all messages from one queue to another
sqsc mv {{source_queue}} {{destination_queue}}

# Describe a queue
sqsc describe {{queue_name}}

# Query a queue with SQL syntax
sqsc query "SELECT body FROM {{queue_name}} WHERE body LIKE '%user%'"

# Pull all messages from a queue into a local sqlite database in your present working directory
sqsc pull {{queue_name}}

# Remove a file after a single-pass overwriting with random data
srm -s {{/path/to/file}}

# Remove a file after seven passes of overwriting with random data
srm -m {{/path/to/file}}

# Recursively remove a directory and its contents overwriting each file with a single-pass of random data
srm -r -s {{/path/to/folder}}

# Prompt before every removal
srm -i {{\*}}

# Copy your keys to the remote machine
ssh-copy-id {{username@remote_host}}

# Copy the given public key to the remote
ssh-copy-id -i {{path/to/certificate}} {{username}}@{{remote_host}}

# Copy the given public key to the remote with specific port
ssh-copy-id -i {{path/to/certificate}} -p {{port}} {{username}}@{{remote_host}}

# Generate a key interactively
ssh-keygen

# Specify file in which to save the key
ssh-keygen -f ~/.ssh/{{filename}}

# Generate an ed25519 key with 100 key derivation function rounds
ssh-keygen -t ed25519 -a 100

# Generate an RSA 4096 bit key with your email as a comment
ssh-keygen -t rsa -b 4096 -C "{{email}}"

# Retrieve the key fingerprint from a host (useful for confirming the authenticity of the host when first connecting to it via SSH)
ssh-keygen -l -F {{remote_host}}

# Retrieve the fingerprint of a key in MD5 Hex
ssh-keygen -l -E md5 -f ~/.ssh/{{filename}}

# Change the password of a key
ssh-keygen -p -f ~/.ssh/{{filename}}

# Connect to a remote server
ssh {{username}}@{{remote_host}}

# Connect to a remote server with a specific identity (private key)
ssh -i {{path/to/key_file}} {{username}}@{{remote_host}}

# Connect to a remote server using a specific port
ssh {{username}}@{{remote_host}} -p {{2222}}

# Run a command on a remote server
ssh {{remote_host}} {{command -with -flags}}

# SSH tunneling: Dynamic port forwarding (SOCKS proxy on localhost:9999)
ssh -D {{9999}} -C {{username}}@{{remote_host}}

# SSH tunneling: Forward a specific port (localhost:9999 to slashdot.org:80) along with disabling pseudo-[t]ty allocation and executio[n] of remote commands
ssh -L {{9999}}:{{slashdot.org}}:{{80}} -N -T {{username}}@{{remote_host}}

# SSH jumping: Connect through a jumphost to a remote server (Multiple jump hops may be specified separated by comma characters)
ssh -J {{username}}@{{jump_host}} {{username}}@{{remote_host}}

# Agent forwarding: Forward the authentication information to the remote machine (see `man ssh_config` for available options)
ssh -A {{username}}@{{remote_host}}

# Mount remote directory
sshfs {{username}}@{{remote_host}}:{{remote_directory}} {{mountpoint}}

# Unmount remote directory
umount {{mountpoint}}

# Mount remote directory from server with specific port
sshfs {{username}}@{{remote_host}}:{{remote_directory}} -p {{2222}}

# Use compression
sshfs {{username}}@{{remote_host}}:{{remote_directory}} -C

# Follow symbolic links
sshfs -o follow_symlinks {{username}}@{{remote_host}}:{{remote_directory}} {{mountpoint}}

# Connect to a remote server using a password supplied on a file descriptor (in this case, stdin)
sshpass -d {{0}} ssh {{user}}@{{hostname}}

# Connect to a remote server with the password supplied as an option, and automatically accept unknown ssh keys
sshpass -p {{password}} ssh -o StrictHostKeyChecking=no {{user}}@{{hostname}}

# Connect to a remote server using the first line of a file as the password, automatically accept unknown ssh keys, and launch a command
sshpass -f {{file}} ssh -o StrictHostKeyChecking=no {{user}}@{{hostname}} "{{command}}"

# Read 4096 bytes from the device starting from 0x8000000
st-flash read {{firmware}}.bin {{0x8000000}} {{4096}}

# Write firmware to device starting from 0x8000000
st-flash write {{firmware}}.bin {{0x8000000}}

# Erase firmware from device
st-flash erase

# Display amount of program memory available
st-info --flash

# Display amount of sram memory available
st-info --sram

# Display summarized information of the device
st-info --probe

# Run GDB server on port 4500
st-util -p {{4500}}

# Connect to GDB server
(gdb) target extended-remote {{localhost}}:{{4500}}

# Write firmware to device
(gdb) load {{firmware.elf}}

# Create a new project
stack new {{project_name}}

# Install all packages needed by a project
stack install

# Compile a project
stack build

# Run tests inside a project
stack test

# Compile a project and re-compile every time a file changes
stack build --file-watch

# Compile a project and execute a command after compilation
stack build --exec "{{command}}"

# Run a program and pass an argument to it
stack exec {{program_name}} -- {{argument}}

# Lint all JavaScript source files in the current directory
standard

# Lint specific JavaScript file(s)
standard {{path/to/file(s)}}

# Apply automatic fixes during linting
standard --fix

# Declare any available global variables
standard --global {{variable}}

# Use a custom ESLint plugin when linting
standard --plugin {{plugin}}

# Use a custom JS parser when linting
standard --parser {{parser}}

# Use a custom ESLint environment when linting
standard --env {{environment}}

# Show file properties such as size, permissions, creation and access dates among others
stat {{file}}

# Same as above but in a more concise way
stat -t {{file}}

# Show filesystem information
stat -f {{file}}

# Show only octal file permissions
stat -c "%a %n" {{file}}

# Show owner and group of the file
stat -c "%U %G" {{file}}

# Show the size of the file in bytes
stat -c "%s %n" {{file}}

# Get cluster status
stolonctl --cluster-name {{cluster_name}} --store-backend {{store_backend}} --store-endpoints {{store_endpoints}} status

# Get cluster data
stolonctl --cluster-name {{cluster_name}} --store-backend {{store_backend}} --store-endpoints {{store_endpoints}} clusterdata

# Get cluster specification
stolonctl --cluster-name {{cluster_name}} --store-backend {{store_backend}} --store-endpoints {{store_endpoints}} spec

# Update cluster specification with a patch in json format
stolonctl --cluster-name {{cluster_name}} --store-backend {{store_backend}} --store-endpoints {{store_endpoints}} update --patch '{{cluster_spec}}'

# Symlink all files recursively to a given directory
stow --target={{path/to/target_directory}} {{file1 folder1 file2 folder2}}

# Delete symlinks recursively from a given directory
stow --delete --target={{path/to/target_directory}} {{file1 folder1 file2 folder2}}

# Simulate to see what the result would be like
stow --simulate --target={{path/to/target_directory}} {{file1 folder1 file2 folder2}}

# Delete and resymlink
stow --restow --target={{path/to/target_directory}} {{file1 folder1 file2 folder2}}

# Exclude files matching a regular expression
stow --ignore={{regex}} --target={{path/to/target_directory}} {{file1 folder1 file2 folder2}}

# Print all strings in a binary
strings {{file}}

# Limit results to strings at least *length* characters long
strings -n {{length}} {{file}}

# Prefix each result with its offset within the file
strings -t d {{file}}

# Prefix each result with its offset within the file in hexadecimal
strings -t x {{file}}

# Display all settings for the current terminal
stty -a

# Set the number of rows
stty rows {{rows}}

# Set the number of columns
stty cols {{cols}}

# Get the actual transfer speed of a device
stty -f {{path/to/device_file}} speed

# Reset all modes to reasonable values for the current terminal
stty sane

# Switch to user {{username}} (password required)
su {{username}}

# Switch to superuser (admin password required)
su

# Switch to user {{username}} and simulate a full login shell
su - {{username}}

# Find subdomains for a specific domain
subfinder -d {{example.com}}

# Show only the subdomains found
subfinder --silent -d {{example.com}}

# Use bruteforcing to find subdomains
subfinder -d {{example.com}} -b

# Remove wildcard subdomains
subfinder -nW -d {{example.com}}

# Use a given comma-separated list of resolvers
subfinder -r {{8.8.8.8}},{{1.1.1.1}} -d {{example.com}}

# Open the current directory in Sublime Text
subl {{.}}

# Open a file or directory in Sublime Text
subl {{path/to/file_or_folder}}

# Open a file or directory in the currently open window
subl -a {{path/to/file}}

# Open a file or directory in a new window
subl -n {{path/to/file}}

# Download English subtitles for a video
subliminal download -l {{en}} {{video.ext}}

# List the contents of an unreadable directory
sudo {{ls}} {{/usr/local/scrt}}

# Edit a file as the user www
sudo -u {{www}} {{vi}} {{/var/www/index.html}}

# Shut down the machine
sudo {{shutdown}} -h +10 {{"Cya soon!"}}

# Repeat the last command as sudo
sudo !!

# Launch the default shell with root privileges
sudo -i

# Compute a checksum with BSD-compatible algorithm and 1024-byte blocks
sum {{file}}

# Compute a checksum with System V-compatible algorithm and 512-byte blocks
sum --sysv {{file}}

# Start/stop/restart a process
supervisorctl {{start|stop|restart}} {{process_name}}

# Start/stop/restart all processes in a group
supervisorctl {{start|stop|restart}} {{group_name}}:*

# Show last 100 **bytes** of process stderr
supervisorctl tail -100 {{process_name}} stderr

# Keep displaying stdout of a process
supervisorctl tail -f {{process_name}} stdout

# Reload process config file to add/remove processes as necessary
supervisorctl update

# Start supervisord with specified configuration file
supervisord -c {{path/to/file}}

# Run supervisord in the foreground
supervisord -n

# Upload a new site to surge.sh
surge {{path/to/my_project}}

# Deploy site to custom domain (note that the DNS records must point to the surge.sh subdomain)
surge {{path/to/my_project}} {{my_custom_domain.com}}

# List your surge projects
surge list

# Remove a project
surge teardown {{my_custom_domain.com}}

# Optimize an SVG image
svgcleaner {{input.svg}} {{output.svg}}

# Optimize an SVG image multiple times
svgcleaner --multipass {{input.svg}} {{output.svg}}

# Optimize a file using the default plugins (overwrites the original file)
svgo {{test.svg}}

# Optimize a file and save the result to another file
svgo {{test.svg}} {{test.min.svg}}

# Optimize all SVG files within a folder (overwrites the original files)
svgo -f {{path/to/folder/with/svg/files}}

# Optimize all SVG files within a folder and save the resulting files to another folder
svgo -f {{path/to/input/folder}} -o {{path/to/output/folder}}

# Optimize SVG content passed from another command, and save the result to a file
{{cat test.svg}} | svgo -i - -o {{test.min.svg}}

# Optimize a file and print out the result
svgo {{test.svg}} -o -

# Optimize a file making sure a given plugin is enabled
svgo --enable={{plugin_name}}

# Show available plugins
svgo --show-plugins

# Check out a working copy from a repository
svn co {{url/to/repository}}

# Bring changes from the repository into the working copy
svn up

# Put files and directories under version control, scheduling them for addition to repository. They will be added in next commit
svn add PATH...

# Send changes from your working copy to the repository
svn ci -m {{commit log message}} {{[PATH...]}}

# Show detailed help
svn help

# Generate documentation and code from an OpenAPI/swagger file
swagger-codegen generate -i {{swagger_file}} -l {{language}}

# Generate java code using the library retrofit2 and the option useRxJava2
swagger-codegen generate -i {{http://petstore.swagger.io/v2/swagger.json}} -l {{java}} --library {{retrofit2}} -D{{useRxJava2}}={{true}}

# List available languages
swagger-codegen langs

# Display help options for the generate command
swagger-codegen help {{generate}}

# Invoke the interactive interpreter (REPL)
swift

# Execute a program
swift {{file.swift}}

# Start a new project with the package manager
swift package init

# Generate an Xcode project file
swift package generate-xcodeproj

# Update dependencies
swift package update

# Compile project for release
swift build -c release

# Flush all pending write operations on all disks
sync

# Flush all pending write operations on a single file to disk
sync {{path/to/file}}

# Extract all tables from a PDF to a CSV file
tabula -o {{file.csv}} {{file.pdf}}

# Extract all tables from a PDF to a JSON file
tabula --format JSON -o {{file.json}} {{file.pdf}}

# Extract tables from pages 1, 2, 3, and 6 of a PDF
tabula --pages {{1-3,6}} {{file.pdf}}

# Extract tables from page 1 of a PDF, guessing which portion of the page to examine
tabula --guess --pages {{1}} {{file.pdf}}

# Extract all tables from a PDF, using ruling lines to determine cell boundaries
tabula --spreadsheet {{file.pdf}}

# Extract all tables from a PDF, using blank space to determine cell boundaries
tabula --no-spreadsheet {{file.pdf}}

# Print the contents of *file1* reversed to the standard output
tac {{file1}}

# Concatenate several files reversed into the target file
tac {{file1}} {{file2}} > {{target_file}}

# Show last 'num' lines in file
tail -n {{num}} {{file}}

# Show all file since line 'num'
tail -n +{{num}} {{file}}

# Show last 'num' bytes in file
tail -c {{num}} {{file}}

# Keep reading file until `Ctrl + C`
tail -f {{file}}

# Keep reading file until `Ctrl + C`, even if the file is rotated
tail -F {{file}}

# Create an archive from files
tar cf {{target.tar}} {{file1 file2 file3}}

# Create a gzipped archive
tar czf {{target.tar.gz}} {{file1 file2 file3}}

# Extract an archive in a target folder
tar xf {{source.tar}} -C {{folder}}

# Extract a gzipped archive in the current directory
tar xzf {{source.tar.gz}}

# Extract a bzipped archive in the current directory
tar xjf {{source.tar.bz2}}

# Create a compressed archive, using archive suffix to determine the compression program
tar caf {{target.tar.xz}} {{file1 file2 file3}}

# List the contents of a tar file
tar tvf {{source.tar}}

# Extract files matching a pattern
tar xf {{source.tar}} --wildcards {{"*.html"}}

# Add new task
task add {{thing_to_do}}

# List tasks
task list

# Mark task as completed
task {{task_id}} done

# Modify task
task {{task_id}} modify {{new_thing_to_do}}

# Delete task
task {{task_id}} delete

# List available network interfaces
tcpdump -D

# Capture the traffic of a specific interface
tcpdump -i {{eth0}}

# Capture all TCP traffic showing contents (ASCII) in console
tcpdump -A tcp

# Capture the traffic from or to a host
tcpdump host {{www.example.com}}

# Capture the traffic from a specific interface, source, destination and destination port
tcpdump -i {{eth0}} src {{192.168.1.1}} and dst {{192.168.1.2}} and dst port {{80}}

# Capture the traffic of a network
tcpdump net {{192.168.1.0/24}}

# Capture all traffic except traffic over port 22 and save to a dump file
tcpdump -w {{dumpfile.pcap}} not port {{22}}

# Read from a given dump file
tcpdump -r {{dumpfile.pcap}}

# Copy standard input to each FILE, and also to standard output
echo "example" | tee {{FILE}}

# Append to the given FILEs, do not overwrite
echo "example" | tee -a {{FILE}}

# Print standard input to the terminal, and also pipe it into another program for further processing
echo "example" | tee {{/dev/tty}} | {{xargs printf "[%s]"}}

# Create a folder called "example", count the number of characters in "example" and write "example" to the terminal
echo "example" | tee >(xargs mkdir) >(wc -c)

# Telnet to the default port of a host
telnet {{host}}

# Telnet to a specific port of a host
telnet {{ip_address}} {{port}}

# Exit a telnet session
quit

# Emit the default escape character combination for terminating the session
Ctrl + ]

# Start telnet with "x" as the session termination character
telnet -e {{x}} {{ip_address}} {{port}}

# Initialize a new or existing Terraform configuration
terraform init

# Generate and show an execution plan
terraform plan

# Build or change infrastructure
terraform apply

# Destroy Terraform-managed infrastructure
terraform destroy

# Recognize text in an image and save it to `output.txt` (the '.txt' extension is added automatically)
tesseract {{image.png}} {{output}}

# Specify a custom language (default is English) with an ISO 639-2 code (e.g. deu = Deutsch = German)
tesseract -l deu {{image.png}} {{output}}

# List the ISO 639-2 codes of available languages
tesseract --list-langs

# Specify a custom page segmentation mode (default is 3)
tesseract -psm {{0_to_10}} {{image.png}} {{output}}

# List page segmentation modes and their descriptions
tesseract --help-psm

# Test if given variable is equal to given string
test $MY_VAR == '/bin/zsh'

# Test if given variable is empty
test -z $GIT_BRANCH

# Test if file exists
test -e {{filename}}

# Test if directory not exists
test ! -d {{path/to/directory}}

# If-else statement
test {{condition}} && echo "true" || echo "false"

# Show the sequence of commits starting from the current one in reverse chronological order
tig

# Show the history of a specific branch
tig {{branch}}

# Show the history of specific files or directories
tig {{path1}} {{path2}} ...

# Show the difference between two references (such as branches or tags)
tig {{base_ref}}..{{compared_ref}}

# Display commits from all branches and stashes
tig --all

# Start in stash view, displaying all saved stashes
tig stash

# Time "ls"
time ls

# Run `sleep 10` and kill it, if it's running after 3 seconds
timeout {{3s}} {{sleep 10}}

# Specify the signal to be sent to the command after the time limit expires. (By default, TERM is sent)
timeout --signal {{INT}} {{5s}} {{sleep 10}}

# Start a new stopwatch, giving a tag name to the activity being tracked
timew start {{activity_tag}}

# View running stopwatches
timew

# Stop the stopwatch with a given tag name
timew stop {{activity_tag}}

# Stop all running stopwatches
timew stop

# View tracked items
timew summary

# Get typical usages of a command (hint: this is how you got here!)
tldr {{command}}

# Lint all pages
tldrl {{pages_directory}}

# Format a specific page to stdout
tldrl -f {{page.md}}

# Format all pages in place
tldrl -fi {{pages_directory}}

# Start a new tmux session
tmux

# Start a new named tmux session
tmux new -s {{name}}

# List sessions
tmux ls

# Attach to a session
tmux a

# Attach to a named session
tmux a -t {{name}}

# Detach from session
Ctrl + B, D

# Kill session
tmux kill-session -t {{name}}

# Kill session when attached
Ctrl + B, x (then hit 'y' for yes)

# Create a new empty file(s) or change the times for existing file(s) to current time
touch {{filename}}

# Set the times on a file to a specific date and time
touch -t {{YYYYMMDDHHMM.SS}} {{filename}}

# Use the times from a file to set the times on a second file
touch -r {{filename}} {{filename2}}

# Run tests on all test environments
tox

# Create a tox.ini configuration
tox-quickstart

# List the available environments
tox --listenvs-all

# Run tests on a specific environment (e.g. python 3.6)
tox -e {{py36}}

# Force the virtual environment to be recreated
tox --recreate -e {{py27}}

# View a presentation
tpp {{filename}}

# Output a presentation
tpp -t {{type}} -o {{outputname}} {{filename}}

# Move the cursor to a screen location
tput cup {{y_coordinate}} {{x_coordinate}}

# Set foreground (af) or background (ab) color
tput {{setaf|setab}} {{ansi_color_code}}

# Show number of columns, lines, or colors
tput {{cols|lines|colors}}

# Ring the terminal bell
tput bel

# Reset all terminal attributes
tput sgr0

# Enable / Disable word wrap
tput {{smam|rmam}}

# Replace all occurrences of a character in a file, and print the result
tr {{find_characters}} {{replace_characters}} < {{filename}}

# Map each character of the first set to the corresponding character of the second set
tr 'abcd' 'jkmn' < {{filename}}

# Delete all occurrences of the specified set of characters from the input
tr -d '{{input_characters}}'

# Compress a series of identical characters to a single character
tr -s '{{input_characters}}'

# Translate the contents of the file to upper-case and print result
tr "[:lower:]" "[:upper:]" < {{filename}}

# Strip out non-printable characters from the file and print result
tr -cd "[:print:]" < {{filename}}

# Traceroute to a host
traceroute {{host}}

# Disable IP address and host name mapping
traceroute -n {{host}}

# Specify wait time for response
traceroute -w {{0.5}} {{host}}

# Specify number of queries per hop
traceroute -q {{5}} {{host}}

# Specify size in bytes of probing packet
traceroute {{host}} {{42}}

# Start server with default config
traefik

# Start server with a custom config file
traefik --c {{config_file}}.toml

# Start server with cluster mode enabled
traefik --cluster

# Start server with web UI enabled
traefik --web

# Translate a word (language is detected automatically)
trans "{{word_or_sentence_to_translate}}"

# Get a brief translation
trans --brief "{{word_or_sentence_to_translate}}"

# Translate a word into french
trans :{{fr}} {{word}}

# Translate a word from German to English
trans {{de}}:{{en}} {{Schmetterling}}

# Behave like a dictionary to get the meaning of a word
trans -d {{word}}

# Create stabilisation file to be able to remove camera shakes
transcode -J stabilize -i {{input_file}}

# Remove camera shakes after creating stabilisation file, transform video using xvid
transcode -J transform -i {{input_file}} -y xvid -o {{output_file}}

# Resize the video to 640x480 pixels and convert to MPEG4 codec using xvid
transcode -Z 640x480 -i {{input_file}} -y xvid -o {{output_file}}

# Trash files and directories
trash-put {{file_name}}

# Empty the trashcan
trash-empty

# List trashed files
trash-list

# Restore a trashed file by choosing a number from the list that results from this command
trash-restore

# Remove individual files from the trashcan
trash-rm {{file_name}}

# Return a successful exit code
true

# Set a size of 10 GB to an exsting file, or create a new file with the specified size
truncate -s {{10G}} {{filename}}

# Extend the file size by 50M, fill with holes (which reads as zero bytes)
truncate -s +{{50M}} {{filename}}

# Shrink the file by 2GiB, by removing data from the end of file
truncate -s -{{2G}} {{filename}

# Perform a topological sort consistent with a partial sort per line of input separated by blanks
tsort {{file}}

# Print the file name of this terminal
tty

# Simply convert RAW files to jpg
ufraw-batch --out-type=jpg {{input_file(s)}}

# Simply convert RAW files to png
ufraw-batch --out-type=png {{input_file(s)}}

# Extract the preview image from the raw file
ufraw-batch --embedded-image {{input_file(s)}}

# Save the file with size up to the given maximums MAX1 and MAX2
ufraw-batch --size=MAX1,MAX2 {{input_file(s)}}

# Unmount a filesystem, by passing the path to the source it is mounted from
umount {{path/to/device_file}}

# Unmount a filesystem, by passing the path to the target where it is mounted
umount {{path/to/mounted_directory}}

# Unmount all mounted filesystems (except the `proc` filesystem)
umount -a

# Print hardware-related information: machine and processor
uname -mp

# Print software-related information: operating system, release number, and version
uname -srv

# Print the nodename (hostname) of the system
uname -n

# Print all available system information (hardware, software, nodename)
uname -a

# Extract an archive to the current directory
unar {{archive}}

# Extract an archive to the specified directory
unar -o {{path/to/directory}} {{archive}}

# Force overwrite if files to be unpacked already exist
unar -f {{archive}}

# Force rename if files to be unpacked already exist
unar -r {{archive}}

# Force skip if files to be unpacked already exist
unar -s {{archive}}

# Convert blanks in each file to tabs, writing to standard output
unexpand {{file}}

# Convert blanks to tabs, reading from standard output
unexpand

# Convert all blanks, instead of just initial blanks
unexpand -a {{file}}

# Convert only leading sequences of blanks (overrides -a)
unexpand --first-only {{file}}

# Have tabs a certain number of characters apart, not 8 (enables -a)
unexpand -t {{number}} {{file}}

# Display each line once
sort {{file}} | uniq

# Display only unique lines
sort {{file}} | uniq -u

# Display only duplicate lines
sort {{file}} | uniq -d

# Display number of occurrences of each line along with that line
sort {{file}} | uniq -c

# Display number of occurrences of each line, sorted by the most frequent
sort {{file}} | uniq -c | sort -nr

# Remove the specified file if it is the last link
unlink {{path/to/file}}

# Extract files with original directory structure
unrar x {{compressed.rar}}

# Extract files into current directory, losing directory structure in the archive
unrar e {{compressed.rar}}

# Test integrity of each file inside the archive file
unrar t {{compressed.rar}}

# List files inside the archive file without decompressing it
unrar l {{compressed.rar}}

# Extract zip file(s) (for multiple files, separate file paths by spaces)
unzip {{file(s)}}

# Extract zip files(s) to given path
unzip {{compressed_file(s)}} -d {{/path/to/put/extracted_file(s)}}

# List the contents of a zip file without extracting
unzip -l {{file.zip}}

# Extract the contents of the file(s) to stdout alongside the extracted file names
unzip -c {{file.zip}}

# Extract a zip file created in windows, containing files with non-ascii (chinese) filenames
unzip -O {{gbk}} {{file.zip}}

# Print current time, uptime, number of logged-in users and other information
uptime

# Show only the amount of time the system has been booted for
uptime --pretty

# Print the date and time the system booted up at
uptime --since

# Show version information
uptime --version

# Compress executable
upx {{file}}

# Decompress executable
upx -d {{file}}

# Detailed help
upx --help

# Display a list of logged in users
users

# Display a list of logged in users according to a specific file
users {{/var/log/wmtp}}

# Create Vagrantfile in current folder with the base Vagrant box
vagrant init

# Create Vagrantfile with the Ubuntu 14.04 (Trusty Tahr) box from HashiCorp Atlas
vagrant init ubuntu/trusty32

# Start and provision the vagrant environment
vagrant up

# Suspend the machine
vagrant suspend

# Connect to machine via SSH
vagrant ssh

# Use the (default) Memcheck tool to show a diagnostic of memory usage by `program`
valgrind {{program}}

# Use Memcheck to report all possible memory leaks of `program` in full detail
valgrind --leak-check=full --show-leak-kinds=all {{program}}

# Use the Cachegrind tool to profile and log CPU cache operations of `program`
valgrind --tool=cachegrind {{program}}

# Use the Massif tool to profile and log heap memory and stack usage of `program`
valgrind --tool=massif --stacks=yes {{program}}

# Connect to a Vault server and initialize a new encrypted data store
vault init

# Unseal (unlock) the vault, by providing one of the key shares needed to access the encrypted data store
vault unseal {{key-share-x}}

# Authenticate the CLI client against the Vault server, using an authentication token
vault auth {{authentication_token}}

# Store a new secret in the vault, using the generic back-end called "secret"
vault write secret/{{hello}} value={{world}}

# Read a value from the vault, using the generic back-end called "secret"
vault read secret/{{hello}}

# Seal (lock) the Vault server, by removing the encryption key of the data store from memory
vault seal

# Initialize an (empty) repository
vcsh init {{repository_name}}

# Clone a repository into a custom directory name
vcsh clone {{git_url}} {{repository_name}}

# List all managed repositories
vcsh list

# Execute a git command on a managed repository
vcsh {{repository_name}} {{git_command}}

# Push/pull all managed repositories to/from remotes
vcsh {{push|pull}}

# Write a custom .gitignore file for a managed repository
vcsh write-gitignore {{repository_name}}

# Open a file
view {{file}}

# Open a file
vim {{file}}

# Enter text editing mode (insert mode)
<Esc>i

# Copy ("yank") or cut ("delete") the current line (paste it with `P`)
<Esc>{{yy|dd}}

# Undo the last operation
<Esc>u

# Search for a pattern in the file (press `n`/`N` to go to next/previous match)
<Esc>/{{search_pattern}}<Enter>

# Perform a regex substitution in the whole file
<Esc>:%s/{{pattern}}/{{replacement}}/g<Enter>

# Save (write) the file, and quit
<Esc>:wq<Enter>

# Quit without saving
<Esc>:q!<Enter>

# Open two files and show the differences (up to four files can be compared)
vimdiff {{file1}} {{file2}}

# Open two files using a horizontal window split instead of the default vertical split
vimdiff -o {{file1}} {{file2}}

# Move the cursor to the window on the left|right|up|down
Ctrl + w {{h|l|k|j}}

# Launch the vim tutor using the given language (en, fr, de, ...)
vimtutor {{language}}

# Exit the tutor
<Esc> :q <Enter>

# Create a new environment
virtualenv {{path/to/venv}}

# Customize the prompt prefix
virtualenv --prompt={{prompt_prefix}}  {{path/to/venv}}

# Start (select) the environment
source {{path/to/venv}}/bin/activate

# Stop the environment
deactivate

# Edit sudoers file
sudo visudo

# Check sudoers file for errors
sudo visudo -c

# List all the extensions created by a publisher
vsce list {{publisher}}

# Publish an extension as major, minor or patch version
vsce publish {{major|minor|patch}}

# Unpublish an extension
vsce unpublish {{extension_id}}

# Package the current working directory as .vsix file
vsce package

# Show the metadata associated with an extension
vsce show {{extension_id}}

# Create a new vue project
vue init {{template}} {{project_name}}

# Create a new project with a local template
vue init {{path/to/template_folder}} {{project_name}}

# Create project using template on GitHub
vue init {{username}}/{{repo}} {{project_name}}

# Show logged-in users info
w

# Show logged-in users info without a header
w -h

# Open an URL
w3m {{http://example.com}}

# Quit w3m
'q' then 'y'

# Wait for a process to finish given its process ID (PID) and return its exit status
wait {{pid}}

# Wait for all processes known to the invoking shell to finish
wait

# Run a Python web app
waitress-serve {{import.path:wsgi_func}}

# Listen on port 8080 on localhost
waitress-serve --listen={{localhost}}:{{8080}} {{import.path:wsgi_func}}

# Start waitress on a Unix socket
waitress-serve --unix-socket={{path/to/socket}} {{import.path:wsgi_func}}

# Use 4 threads to process requests
waitress-serve --threads={{4}} {{import.path:wsgifunc}}

# Call a factory method that returns a WSGI object
waitress-serve --call {{import.path.wsgi_factory}}

# Set the URL scheme to https
waitress-serve --url-scheme={{https}} {{import.path:wsgi_func}}

# Display the section headers of a given binary
wasm-objdump -h {{file.wasm}}

# Display the entire disassembled output of a given binary
wasm-objdump -d {{file.wasm}}

# Display the details of each section
wasm-objdump --details {{file.wasm}}

# Display the details of a given section
wasm-objdump --section '{{import}}' --details {{file.wasm}}

# Apply default optimizations and write to a given file
wasm-opt -O {{input.wasm}} -o {{output.wasm}}

# Apply all optimizations and write to a given file (takes more time, but generates optimal code)
wasm-opt -O4 {{input.wasm}} -o {{output.wasm}}

# Optimize a file for size
wasm-opt -Oz {{input.wasm}} -o {{output.wasm}}

# Print the textual representation of the binary to console
wasm-opt {{input.wasm}} --print

# Convert a file to a C source file and header and display it to the console
wasm2c {{file.wasm}}

# Write the output to a given file (file.h gets additionally generated)
wasm2c {{file.wasm}} -o {{file.c}}

# Convert a file to the text format and display it to the console
wasm2wat {{file.wasm}}

# Write the output to a given file
wasm2wat {{file.wasm}} -o {{file.wat}}

# Parse and check a file for errors
wat2wasm {{file.wat}}

# Write the output binary to a given file
wat2wasm {{file.wat}} -o {{file.wasm}}

# Display simplified representation of every byte
wat2wasm -v {{file.wat}}

# Repeatedly run a command and show the result
watch {{command}}

# Re-run a command every 60 seconds
watch -n {{60}} {{command}}

# Monitor the contents of a directory, highlighting differences as they appear
watch -d {{ls -l}}

# Count lines in file
wc -l {{file}}

# Count words in file
wc -w {{file}}

# Count characters (bytes) in file
wc -c {{file}}

# Count characters in file (taking multi-byte character sets into account)
wc -m {{file}}

# Render a HTML file to PDF
weasyprint {{path/to/input.html}} {{path/to/output}}.pdf

# Render a HTML file to PNG, including an additional user stylesheet
weasyprint {{path/to/input.html}} {{path/to/output}}.png --stylesheet {{path/to/stylesheet.css}}

# Output additional debugging information when rendering
weasyprint {{path/to/input.html}} {{path/to/output}}.pdf --verbose

# Specify a custom resolution when outputting to PNG
weasyprint {{path/to/input.html}} {{path/to/output}}.png --resolution {{300}}

# Specify a base url for relative urls in the input HTML file
weasyprint {{path/to/input.html}} {{path/to/output}}.png --base-url {{url_or_filename}}

# Create a single output file from an entry point file
webpack {{app.js}} {{bundle.js}}

# Load css files too from the js file (this uses the css loader for .css files)
webpack {{app.js}} {{bundle.js}} --module-bind 'css=css'

# Pass a config file (with eg. the entry script and the output filename) and show compilation progress
webpack --config {{webpack.config.js}} --progress

# Automatically recompile on changes to project files
webpack --watch {{app.js}} {{bundle.js}}

# Download the contents of an URL to a file (named "foo" in this case)
wget {{https://example.com/foo}}

# Download the contents of an URL to a file (named "bar" in this case)
wget -O {{bar}} {{https://example.com/foo}}

# Download a single web page and all its resources (scripts, stylesheets, images, etc.)
wget --page-requisites --convert-links {{https://example.com/somepage.html}}

# Download a full website, with 3-second intervals between requests
wget --mirror --page-requisites --convert-links --wait=3 {{https://example.com}}

# Download all listed files within a directory and its sub-directories (does not download embedded page elements)
wget --mirror --no-parent {{https://example.com/somepath/}}

# Download the contents of an URL via authenticated FTP
wget --ftp-user={{username}} --ftp-password={{password}} {{ftp://example.com}}

# Continue an incomplete download
wget -c {{https://example.com}}

# Enable quiet mode to suppress output
wget -q {{https://example.com}}

# Find all instances of a command
where {{command}}

# Search the PATH environment variable and display the location of any matching executables
which {{executable}}

# If there are multiple executables which match, display all
which -a {{executable}}

# Read stdin and perform an action on every line
while read line; do echo "$line"; done

# Execute a command forever once every second
while :; do {{command}}; sleep 1; done

# Display the username, line, and time of all currently logged-in sessions
who

# Display information only for the current terminal session
who am i

# Display all available information
who -a

# Display all available information with table headers
who -a -H

# Display currently logged username
whoami

# Display the username after a change in the user ID
sudo whoami

# Start wordgrinder (loads a blank document by default)
wordgrinder

# Open a given file
wordgrinder {{filename}}

# Show the menu
Alt + M

# Join a protected wireless network
wpa_supplicant -i {{interface}} -c {{path/to/wpa_supplicant_conf.conf}}

# Join a protected wireless network and run it in a daemon
wpa_supplicant -B -i {{interface}} -c {{path/to/wpa_supplicant_conf.conf}}

# Start wuzz
wuzz

# Display help information
F1

# Send an HTTP request
Ctrl + R

# Switch to the next view
Ctrl + J, Tab

# Switch to the previous view
Ctrl + K, Shift + Tab

# View an XLSX or CSV file
x_x {{file.xlsx|file.csv}}

# View an XLSX or CSV file, using the first row as table headers
x_x -h {{0}} {{file.xlsx|file.csv}}

# View a CSV file with unconventional delimiters
x_x --delimiter={{';'}} --quotechar={{'|'}} {{file.csv}}

# Main usage pattern
{{arguments_source}} | xargs {{command}}

# Delete all files with a `.backup` extension. `-print0` on find uses a null character to split the files, and `-0` changes the delimiter to the null character (useful if there's whitespace in filenames)
find . -name {{'*.backup'}} -print0 | xargs -0 rm -v

# Execute the command once for each input line, replacing any occurrences of the placeholder (here marked as `_`) with the input line
{{arguments_source}} | xargs -I _ {{command}} _ {{optional_extra_arguments}}

# Cut a file
xcv x {{input_file}}

# Copy a file
xcv c {{input_file}}

# Paste a file
xcv v {{output_file}}

# List files available for pasting
xcv l

# Return all nodes (tags) named "foo"
xmllint --xpath "//{{foo}}" {{source_file.xml}}

# Return the contents of the first node named "foo" as a string
xmllint --xpath "string(//{{foo}})" {{source_file.xml}}

# Return the href attribute of the second anchor element in an html file
xmllint --html --xpath "string(//a[2]/@href)" webpage.xhtml

# Return human-readable (indented) XML from file
xmllint --format {{source_file.xml}}

# Check that a XML file meets the requirements of its DOCTYPE declaration
xmllint --valid {{source_file.xml}}

# Validate XML against DTD schema hosted online
xmllint --dtdvalid {{URL}} {{source_file.xml}}

# Inspect the headers of a file
xsv headers {{path/to/file.csv}}

# Count the number of entries
xsv count {{path/to/file.csv}}

# Get an overview of the shape of entries
xsv stats {{path/to/file.csv}} | xsv table

# Select a few columns
xsv select {{column_a,column_b}} {{path/to/file.csv}}

# Show 10 random entries
xsv sample {{10}} {{path/to/file.csv}}

# Join a column from one file to another
xsv join --no-case {{column_a}} {{path/to/file/a.csv}} {{column_b}} {{path/to/file/b.csv}} | xsv table

# Generate a hexdump from a binary file and display the output
xxd {{input_file}}

# Generate a hexdump from a binary file and save it as a text file
xxd {{input_file}} {{output_file}}

# Display the output with 10 columns of one octet (byte) each
xxd -c {{10}} {{input_file}}

# Display output only upto a length of 32 bytes
xxd -l {{32}} {{input_file}}

# Display the output in plain mode, without any gaps between the columns
xxd -p {{input_file}}

# Revert a plaintext hexdump back into binary, and save it as a binary file
xxd -r -p {{input_file}} {{output_file}}

# Compress a file
xz {{file}}

# Decompress a file
xz -d {{file.xz}}

# Decompress a file and write to stdout
xz -dc {{file.xz}}

# Compress a file, but don't delete the original
xz -k {{file}}

# Compress a file using the fastest compression
xz -0 {{file}}

# Compress a file using the best compression
xz -9 {{file}}

# Install a module globally
yarn global add {{module_name}}

# Install all dependencies referenced in the package.json file
yarn

# Install a module and save it as a dependency to the package.json file (add --dev to save as a dev dependency)
yarn add {{module_name}}@{{version}}

# Uninstall a module and remove it from the package.json file
yarn remove {{module_name}}

# Interactively create a package.json file
yarn init

# Identify whether a module is a dependency and list other modules that depend upon it
yarn why {{module_name}}

# Repeatedly output "message"
yes {{message}}

# Repeatedly output "y"
yes

# Create a new scaffolded site, with sqlite as backend, in the "my-project" directory
stack new {{my-project}} {{yesod-sqlite}}

# Install the Yesod CLI tool within a Yesod scaffolded site
stack build yesod-bin cabal-install --install-ghc

# Start development server
stack exec -- yesod devel

# Touch files with altered Template Haskell dependencies
stack exec -- yesod touch

# Deploy application using Keter (Yesod's deployment manager)
stack exec -- yesod keter

# Download a video or playlist
youtube-dl {{https://www.youtube.com/watch?v=oHg5SJYRHA0}}

# Download the audio from a video and convert it to an MP3
youtube-dl -x --audio-format {{mp3}} {{url}}

# Download video(s) as MP4 files with custom filenames
youtube-dl --format {{mp4}} --output {{"%(title) by %(uploader) on %(upload_date) in %(playlist).%(ext)"}} {{url}}

# Download a video and save its description, metadata, annotations, subtitles, and thumbnail
youtube-dl --write-description --write-info-json --write-annotations --write-sub --write-thumbnail {{url}}

# From a playlist, download all "Let's Play" videos that aren't marked "NSFW" or age-restricted for 7 year-olds
youtube-dl --match-title {{"let's play"}} --age-limit {{7}} --reject-title {{"nsfw"}} {{playlist_url}}

# Go to a directory that contains "foo" in the name
z {{foo}}

# Go to a directory that contains "foo" and then "bar"
z {{foo}} {{bar}}

# Go to the highest-ranked directory matching "foo"
z -r {{foo}}

# Go to the most recently accessed directory matching "foo"
z -t {{foo}}

# List all directories in `z`'s database matching "foo"
z -l {{foo}}

# Remove the current directory from `z`'s database
z -x .

# Process an image file
zbarimg {{image_file}}

# Print the uncompressed contents of a gzipped file to the standard output
zcat {{file.txt.gz}}

# Show detailed configuration of all mounted ZFS zpools
zdb

# Show detailed configuration for a specific ZFS pool
zdb -C {{poolname}}

# Show statistics about number, size and deduplication of blocks
zdb -b {{poolname}}

# List all available zfs filesystems
zfs list

# Create a new ZFS filesystem
zfs create {{pool_name/filesystem_name}}

# Delete a ZFS filesystem
zfs destroy {{pool_name/filesystem_name}}

# Create a Snapshot of a ZFS filesystem
zfs snapshot {{pool_name/filesystem_name}}@{{snapshot_name}}

# Enable compression on a filesystem
zfs set compression=on {{pool_name/filesystem_name}}

# Change mountpoint for a filesystem
zfs set mountpoint={{/my/mount/path}} {{pool_name/filesystem_name}}

# Package and compress a directory and its contents, [r]ecursively
zip -r {{compressed.zip}} {{/path/to/dir}}

# E[x]clude unwanted files from being added to the compressed archive
zip -r {{compressed.zip}} {{path/to/dir}} -x {{path/to/exclude}}

# Archive a directory and its contents with the highest level [9] of compression
zip -r -{{9}} {{compressed.zip}} {{/path/to/dir}}

# Package and compress multiple directories and files
zip -r {{compressed.zip}} {{/path/to/dir1 /path/to/dir2 /path/to/file}}

# Create an encrypted archive (user will be prompted for a password)
zip -e -r {{compressed.zip}} {{path/to/dir}}

# Add files to an existing zip file
zip {{compressed.zip}} {{path/to/file}}

# Delete files from an existing zip file
zip -d {{compressed.zip}} "{{foo/*.tmp}}"

# Archive a directory and its contents to a multi-part [s]plit zip file (e.g. 3GB parts)
zip -r -s {{3g}} {{compressed.zip}} {{path/to/dir}}

# Page through a compressed archive with `less`
zless {{file.txt.gz}}

# Optimize a PNG image
zopflipng {{input.png}} {{output.png}}

# Optimize several PNG images and save with given prefix
zopflipng --prefix={{prefix}} {{image1.png}} {{image2.png}} {{image3.png}}

# Show the configuration and status of all ZFS zpools
zpool status

# Check a ZFS pool for errors (verifies the checksum of EVERY block). Very CPU and disk intensive
zpool scrub {{pool_name}}

# List zpools available for import
zpool import

# Import a zpool
zpool import {{pool_name}}

# Export a zpool (unmount all filesystems)
zpool export {{pool_name}}

# Show the history of all pool operations
zpool history {{pool_name}}

# Create a mirrored pool
zpool create {{pool_name}} mirror {{disk1}} {{disk2}} mirror {{disk3}} {{disk4}}

# Start interactive command line interpreter
zsh

# Execute command passed as parameter
zsh -c {{command}}

# Run commands from file (script)
zsh {{file}}

# Run commands from file and print them as they are executed
zsh -x {{file}}

# Add a new apt repository
add-apt-repository {{repository_spec}}

# Remove an apt repository
add-apt-repository --remove {{repository_spec}}

# Update the package cache after adding a repository
add-apt-repository --update {{repository_spec}}

# Enable source packages
add-apt-repository --enable-source {{repository_spec}}

# Create a new user with a default home directory and prompt the user to set a password
adduser {{username}}

# Create a new user without a home directory
adduser --no-create-home {{username}}

# Create a new user with a home directory at the specified path
adduser --home {{path/to/home}} {{username}}

# Create a new user with the specified shell set as the login shell
adduser --shell {{path/to/shell}} {{username}}

# Create a new user belonging to the specified group
adduser --ingroup {{group}} {{username}}

# Open alpine normally
alpine

# Open alpine directly to the message composition screen to send an email to a given email address
alpine {{email@example.net}}

# Quit alpine
'q' then 'y'

# Start the Apache daemon. Throw a message if it is already running
sudo apache2ctl start

# Stop the Apache daemon
sudo apache2ctl stop

# Restart the Apache daemon
sudo apache2ctl restart

# Test syntax of the configuration file
sudo apache2ctl -t

# List loaded modules
sudo apache2ctl -M

# Update repository indexes from all remote repositories
apk update

# Install a new package
apk add {{package}}

# Remove a package
apk del {{package}}

# Repair package or upgrade it without modifying main dependencies
apk fix {{package}}

# Search package via keyword
apk search {{keyword}}

# Get info about a specific package
apk info {{package}}

# Search for a package in your current sources
apt-cache search {{query}}

# Show information about a package
apt-cache show {{package}}

# Show whether a package is installed and up to date
apt-cache policy {{package}}

# Show dependencies for a package
apt-cache depends {{package}}

# Show packages that depend on a particular package
apt-cache rdepends {{package}}

# Update the list of available packages and versions (it's recommended to run this before other `apt-get` commands)
apt-get update

# Install a package, or update it to the latest available version
apt-get install {{package}}

# Remove a package
apt-get remove {{package}}

# Upgrade all installed packages to their newest available versions
apt-get upgrade

# Remove all packages that are no longer needed
apt-get autoremove

# Upgrade installed packages (like `upgrade`), but remove obsolete packages and install additional packages to meet new dependencies
apt-get dist-upgrade

# List trusted keys
apt-key list

# Add a key to the trusted keystore
apt-key add {{public_key_file.asc}}

# Delete a key from the trusted keystore
apt-key del {{key_id}}

# Add a remote key to the trusted keystore
wget -qO - {{https://host.tld/filename.key}} | apt-key add -

# Add a key from keyserver with only key id
apt-key adv --keyserver {{pgp.mit.edu}} --recv {{KEYID}}

# Mark a package as automatically installed
sudo apt-mark auto {{package_name}}

# Hold a package at its current version and prevent updates to it
sudo apt-mark hold {{package_name}}

# Allow a package to be updated again
sudo apt-mark unhold {{package_name}}

# Show manually installed packages
apt-mark showmanual

# Show held packages that aren't being updated
apt-mark showhold

# Update the list of available packages and versions (it's recommended to run this before other `apt` commands)
sudo apt update

# Search for a given package
apt search {{package}}

# Show information for a package
apt show {{package}}

# Install a package, or update it to the latest available version
sudo apt install {{package}}

# Remove a package (using `purge` instead also removes its configuration files)
sudo apt remove {{package}}

# Upgrade all installed packages to their newest available versions
sudo apt upgrade

# Synchronize list of packages and versions available. This should be run first, before running subsequent aptitude commands
aptitude update

# Install a new package and its dependencies
aptitude install {{package}}

# Search for a package
aptitude search {{package}}

# Remove a package and all packages depending on it
aptitude remove {{package}}

# Upgrade installed packages to newest available versions
aptitude upgrade

# Upgrade installed packages (like `aptitude upgrade`) including removing obsolete packages and installing additional packages to meet new package dependencies
aptitude full-upgrade

# Display the system's architecture
arch

# Show system information
archey

# Scan the current local network
arp-scan --localnet

# Scan an IP network with a custom bitmask
arp-scan {{192.168.1.1}}/{{24}}

# Scan an IP network within a custom range
arp-scan {{127.0.0.0}}-{{127.0.0.31}}

# Scan an IP network with a custom net mask
arp-scan {{10.0.0.0}}:{{255.255.255.0}}

# Assemble a file, writing the output to a.out
as {{file.s}}

# Assemble the output to a given file
as {{file.s}} -o {{out.o}}

# Generate output faster by skipping whitespace and comment preprocessing. (Should only be used for trusted compilers)
as -f {{file.s}}

# Include a given path to the list of directories to search for files specified in .include directives
as -I {{path/to/directory}} {{file.s}}

# Spell check a single file
aspell check {{path/to/file}}

# List mispelled words from standard input
cat {{file}} | aspell list

# Show available dictionary languages
aspell dicts

# Run aspell with different language (takes two letter ISO 639 language code)
aspell --lang={{cs}}

# List mispelled words from standard input and ignore words from personal word list
cat {{file}} | aspell --personal={{personal-word-list.pws}} {{list}}

# Open an `at` prompt to create a new set of scheduled commands, press `Ctrl + D` to save and exit
at {{hh:mm:ss}}

# Execute the commands and email the result using a local mailing program such as sendmail
at {{hh:mm:ss}} -m

# Execute a script at the given time
at {{hh:mm:ss}} -f {{path/to/file}}

# Display the current configuration (or dry run)
authconfig --test

# Configure the server to use a different password hashing algorithm
authconfig --update --passalgo={{algorithm}}

# Enable LDAP authentication
authconfig --update --enableldapauth

# Disable LDAP authentication
authconfig --update --disableldapauth

# Enable Network Information Service (NIS)
authconfig --update --enablenis

# Enable Kerberos
authconfig --update --enablekrb5

# Enable Winbind (Active Directory) authentication
authconfig --update --enablewinbindauth

# Enable local authorization
authconfig --update --enablelocauthorize

# Play a beep
beep

# Play a beep that repeats
beep -r {{repetitions}}

# Play a beep at a specified frequency (Hz) and duration (milliseconds)
beep -f {{frequency}} -l {{duration}}

# Play each new frequency and duration as a distinct beep
beep -f {{frequency}} -l {{duration}} -n -f {{frequency} -l {{duration}}

# Play the C major scale
beep -f 262 -n -f 294 -n -f 330 -n -f 349 -n -f 392 -n -f 440 -n -f 494 -n -f 523

# Display the list of all the interfaces
bmon -a

# Display data transfer rates in bits per second
bmon -b

# Set policy to define which network interface(s) is/are displayed
bmon -p {{interface_1,interface_2,interface_3}}

# Set interval (in seconds) in which rate per counter is calculated
bmon -R {{2.0}}

# Search for available formulas
brew search {{text}}

# Install the latest stable version of a formula (use `--devel` for development versions)
brew install {{formula}}

# List all installed formulae
brew list

# Update an installed formula (if no formula name is given, all installed formulae are updated)
brew upgrade {{formula}}

# Fetch the newest version of Linuxbrew and all formulae from GitHub
brew update

# Show formulae that have a more recent version available
brew outdated

# Display information about a formula (version, installation path, dependencies, etc.)
brew info {{formula}}

# Check your Linuxbrew installation for potential problems
brew doctor

# Compress file
bzip2 {{path/to/file_to_compress}}

# Decompress file
bzip2 -d {{path/to/compressed_file.bz2}}

# Decompress to console
bzip2 -dc {{path/to/compressed_file.bz2}}

# Display a calendar for the current month
cal

# Display previous, current and next month
cal --three

# Use monday as the first day of the week
cal --monday

# Display a calendar for a specific year (4 digits)
cal {{year}}

# Display a calendar for a specific month and year
cal {{month}} {{year}}

# Start calc in interactive mode
calc

# Perform a calculation in non-interactive mode
calc -p '{{85 * (36 / 4)}}'

# Obtain a new certificate via webroot authorization, but do not install it automatically
sudo certbot certonly --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}}

# Obtain a new certificate via nginx authorization, installing the new certificate automatically
sudo certbot --nginx --domain {{subdomain.example.com}}

# Obtain a new certificate via apache authorization, installing the new certificate automatically
sudo certbot --apache --domain {{subdomain.example.com}}

# Renew all Let's Encrypt certificates that expire in 30 days or less (don't forget to restart any servers that use them afterwards)
sudo certbot renew

# Simulate the obtaining of a new certificate, but don't actually save any new certificates to disk
sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --dry-run

# Obtain an untrusted test certificate instead
sudo certbot --webroot --webroot-path {{path/to/webroot}} --domain {{subdomain.example.com}} --test-cert

# List password information for the user
chage -l {{user_name}}

# Enable password expiration in 10 days
sudo chage -M {{10}} {{user_name}}

# Disable password expiration
sudo chage -M -1 {{user_name}}

# Set account expiration date
sudo chage -E {{YYYY-MM-DD}}

# Force user to change password on next log in
sudo chage -d 0

# Make a file or folder immutable to changes and deletion, even by superuser
chattr +i {{path}}

# Make a file or folder mutable
chattr -i {{path}}

# Recursively make an entire folder and contents immutable
chattr -R +i {{folder}}

# List services with runlevel
chkconfig --list

# Show a service's runlevel
chkconfig --list {{ntpd}}

# Enable service at boot
chkconfig {{sshd}} on

# Enable service at boot for runlevels 2, 3, 4, and 5
chkconfig --level {{2345}} {{sshd}} on

# Disable service at boot
chkconfig {{ntpd}} off

# Disable service at boot for runlevel 3
chkconfig --level {{3}} {{ntpd}} off

# Open cmus from specified directory
cmus {{path/to/directory}}

# Add file/directory to library
:add {{path/to/file_or_directory}}

# Pause/unpause current song
c

# Toggle shuffle mode on/off
s

# Quit cmus
q

# Execute the ls program literally, even if an ls alias exists
command {{ls}}

# List all commands that you could run
compgen -c

# List all aliases
compgen -a

# List all functions that you could run
compgen -A function

# Show shell reserved key words
compgen -k

# See all available commands/aliases starting with 'ls'
compgen -ac {{ls}}

# Compose action can be used to compose any existing file or new  on default mailcap edit tool
compose {{filename}}

# With `run-mailcap`
run-mailcap --action=compose {{filename}}

# Launch with default, built-in config
conky

# Create a new default config
conky -C > ~/.conkyrc

# Launch conky with a given config file
conky -c {{path/to/config}}

# Start in the background (daemonize)
conky -d

# Align conky on the desktop
conky -a {{{top,bottom,middle}_{left,right,middle}}}

# Pause for 5 seconds at startup before launching
conky -p {{5}}

# Start calculating, defaulting to all CPU cores and 1 second refresh interval
sudo cpufreq-aperf

# Start calculating for CPU 1 only
sudo cpufreq-aperf -c {{1}}

# Start calculating with a 3 seconds refresh interval for all CPU cores
sudo cpufreq-aperf -i {{3}}

# Calculate only once
sudo cpufreq-aperf -o

# Show CPU frequency information for all CPUs
cpufreq-info

# Show CPU frequency information for the specified CPU
cpufreq-info -c {{cpu_number}}

# Show the allowed minimum and maximum CPU frequency
cpufreq-info -l

# Show the current minimum and maximum CPU frequency and policy in table format
cpufreq-info -o

# Show available CPU frequency policies
cpufreq-info -g

# Show current CPU work frequency in a human-readable format, according to the cpufreq kernel module
cpufreq-info -f -m

# Show current CPU work frequency in a human-readable format, by reading it from hardware (only available to root)
sudo cpufreq-info -w -m

# Set the CPU frequency policy of CPU 1 to "userspace"
sudo cpufreq-set -c {{1}} -g {{userspace}}

# Set the current minimum CPU frequency of CPU 1
sudo cpufreq-set -c {{1}} --min {{min_frequency}}

# Set the current maximum CPU frequency of CPU 1
sudo cpufreq-set -c {{1}} --max {{max_frequency}}

# Set the current work frequency of CPU 1
sudo cpufreq-set -c {{1}} -f {{work_frequency}}

# Display information for all CPUs
cpuid

# Display information only for the current CPU
cpuid -1

# Display raw hex information with no decoding
cpuid -r

# Initialize a LUKS volume (overwrites all data on the partition)
cryptsetup luksFormat {{/dev/sda1}}

# Open a LUKS volume and create a decrypted mapping at /dev/mapper/{{target}}
cryptsetup luksOpen {{/dev/sda1}} {{target}}

# Remove an existing mapping
cryptsetup luksClose {{target}}

# Change the LUKS volume's passphrase
cryptsetup luksChangeKey {{/dev/sda1}}

# Start interactive shell
dash

# Execute a command
dash -c "{{command}}"

# Run commands from a file
dash {{file.sh}}

# Run commands from a file, logging all commands executed to the terminal
dash -x {{file.sh}}

# Get max, min, mean and median of a single column of numbers
seq 3 | datamash max 1 min 1 mean 1 median 1

# Get the mean of a single column of float numbers (floats must use "," and not ".")
echo -e '1.0\n2.5\n3.1\n4.3\n5.6\n5.7' | tr '.' ',' | datamash mean 1

# Get the mean of a single column of numbers with a given decimal precision
echo -e '1\n2\n3\n4\n5\n5' | datamash -R {{number_of_decimals_wanted}} mean 1

# Get the mean of a single column of numbers ignoring "Na" and "NaN" (literal) strings
echo -e '1\n2\nNa\n3\nNaN' | datamash --narm mean 1

# Run the daemon with a configuration file
dbus-daemon --config-file {{path/to/file}}

# Run the daemon with the standard per-login-session message bus configuration
dbus-daemon --session

# Run the daemon with the standard systemwide message bus configuration
dbus-daemon --system

# Set the address to listen on and override the configuration value for it
dbus-daemon --address {{address}}

# Output the process id to stdout
dbus-daemon --print-pid

# Force the message bus to write to the system log for messages
dbus-daemon --syslog

# Compare files
diff3 {{file1}} {{file2}} {{file3}}

# Show all changes, outlining conflicts
diff3 --show-all {{file1}} {{file2}} {{file3}}

# Disown the current job
disown

# Disown a specific job
disown %{{job_number}}

# Disown all jobs
disown -a

# Show kernel messages
dmesg

# Show kernel error messages
dmesg --level err

# Show kernel messages and keep reading new ones, similar to `tail -f` (available in kernels 3.5.0 and newer)
dmesg -w

# Show how much physical memory is available on this system
dmesg | grep -i memory

# Show kernel messages 1 page at a time
dmesg | less

# Show all DMI table contents
sudo dmidecode

# Show the BIOS version
sudo dmidecode -s bios-version

# Show the system's serial number
sudo dmidecode -s system-serial-number

# Show BIOS information
sudo dmidecode -t bios

# Show CPU information
sudo dmidecode -t processor

# Show memory information
sudo dmidecode -t memory

# Install a new package
sudo dnf install {{package}}

# Install a new package and assume yes to all questions
sudo dnf -y install {{package}}

# Remove a package
sudo dnf remove {{package}}

# Upgrade installed packages to newest available versions
sudo dnf upgrade

# List all installed packages
dpkg-query -l

# List installed packages matching a pattern
dpkg-query -l '{{pattern}}'

# List all files installed by a package
dpkg-query -L {{package_name}}

# Show information about a package
dpkg-query -s {{package_name}}

# Install a package
dpkg -i {{path/to/file.deb}}

# Remove a package
dpkg -r {{package_name}}

# List installed packages
dpkg -l {{pattern}}

# List package contents
dpkg -L {{package_name}}

# List contents of a local package file
dpkg -c {{path/to/file.deb}}

# Find out which package owns a file
dpkg -S {{file_name}}

# Create or update the package manifest
ebuild {{path/to/file.ebuild}} manifest

# Clean the temporary build directories for the build file
ebuild {{path/to/file.ebuild}} clean

# Fetch sources if they do not exist
ebuild {{path/to/file.ebuild}} fetch

# Extract the sources to a temporary build directory
ebuild {{path/to/file.ebuild}} unpack

# Compile the extracted sources
ebuild {{path/to/file.ebuild}} compile

# Install the package to a temporary install directory
ebuild {{path/to/file.ebuild}} install

# Install the temporary files to the live filesystem
ebuild {{path/to/file.ebuild}} qmerge

# Fetch, unpack, compile, install and qmerge the specified ebuild file
ebuild {{path/to/file.ebuild}} merge

# Edit action can be used to view any file on default mailcap explorer
edit {{filename}}

# With `run-mailcap`
run-mailcap --action=edit {{filename}}

# Edit quota of the current user
edquota --user $(whoami)

# Edit quota of a specific user
sudo edquota --user {{username}}

# Edit quota for a group
sudo edquota --group {{group}}

# Restrict operations to a given filesystem (by default edquota operates on all filesystems with quotas)
sudo edquota --file-system {{filesystem}}

# Edit the default grace period
sudo edquota -t

# Duplicate a quota to other users
sudo edquota -p {{reference_user}} {{destination_user1}} {{destination_user2}}

# Display the default device
eject -d

# Eject the default device
eject

# Eject a specific device (the default order is cd-rom, scsi, floppy and tape)
eject {{/dev/cdrom}}

# Toggle whether a device's tray is open or closed
eject -T {{/dev/cdrom}}

# Eject a cd drive
eject -r {{/dev/cdrom}}

# Eject a floppy drive
eject -f {{/mnt/floppy}}

# Eject a tape drive
eject -q {{/mnt/tape}}

# Synchronize all packages
emerge --sync

# Update all packages, including dependencies
emerge -uDNav @world

# Resume a failed updated, skipping the failing package
emerge --resume --skipfirst

# Install a new package, with confirmation
emerge -av {{package_name}}

# Remove a package, with confirmation
emerge -Cav {{package_name}}

# Remove orphaned packages (that were installed only as dependencies)
emerge -avc

# Search the package database for a keyword
emerge -S {{keyword}}

# Replace environment variables in stdin and output to stdout
echo '{{$HOME}}' | envsubst

# Replace environment variables in an input file and output to stdout
envsubst < {{path/to/input}}

# Replace environment variables in an input file and output to a file
envsubst < {{path/to/input}} > {{path/to/output}}

# Replace environment variables in input from a space-separated list
envsubst {{variables}} < {{path/to/input}}

# List all installed packages
equery list '*'

# Search for installed packages in the Portage tree and in overlays
equery list -po {{package_name}}

# List all packages that depend on a given package
equery depends {{package_name}}

# List all packages that a given package depends on
equery depgraph {{package_name}}

# List all files installed by a package
equery files --tree {{package_name}}

# Call `echo` with the "foo" argument
eval "{{echo foo}}"

# Set a variable in the current shell
eval "{{foo=bar}}"

# Set a new environment variable
export {{VARIABLE}}={{value}}

# Remove an environment variable
export -n {{VARIABLE}}

# Append something to the PATH variable
export PATH=$PATH:{{path/to/append}}

# View information about an MP3 file
eyeD3 {{filename.mp3}}

# Set the title of an MP3 file
eyeD3 --title {{"A Title"}} {{filename.mp3}}

# Set the album of all the MP3 files in a directory
eyeD3 --album {{"Album Name"}} {{*.mp3}}

# Set the front cover art for an MP3 file
eyeD3 --add-image {{front_cover.jpeg}}:FRONT_COVER: {{filename.mp3}}

# Open a new VPN connection
sudo f5fpc --start

# Open a new VPN connection to a specific host
sudo f5fpc --start --host {{host.example.com}}

# Specify a username (user will be prompted for a password)
sudo f5fpc --start --host {{host.example.com}} --username {{user}}

# Show the current VPN status
sudo f5fpc --info

# Shutdown the VPN connection
sudo f5fpc --stop

# Reserve a file taking up 700MB of disk space
fallocate --length {{700M}} {{path/to/file}}

# Shrink an already allocated file by 200MB
fallocate --collapse-range --length {{200M}} {{path/to/file}}

# Shrink 20MB of space after 100MB in a file
fallocate --collapse-range --offset {{100M}} --length {{20M}} {{path/to/file}}

# Get the label of a FAT32 partition
fatlabel {{/dev/sda1}}

# Set the label of a FAT32 partition
fatlabel {{/dev/sdc3}} "{{new_label}}"

# Return a list of installed fonts with given name
fc-list | grep '{{DejaVu Serif}}'

# Return a sorted list of best matching fonts
fc-match -s '{{DejaVu Serif}}'

# Display default information about a font
fc-pattern -d '{{DejaVu Serif}}'

# List partitions
fdisk -l

# Start the partition manipulator
fdisk {{/dev/sda}}

# View images locally or using a URL
feh {{path/to/images}}

# View images recursively
feh --recursive {{path/to/images}}

# View images without window borders
feh --borderless {{path/to/images}}

# Exit after the last image
feh --cycle-once {{path/to/images}}

# Set the slideshow cycle delay
feh --slideshow-delay {{seconds}} {{path/to/images}}

# Set your wallpaper (centered, filled, maximized, scaled or tiled)
feh --bg-{{center|fill|max|scale|tile}} {{path/to/image}}

# Generate by directly inputting text
figlet {{input_text}}

# Use a custom font file
figlet {{input_text}} -f {{font_file_name}}

# Pipe command output through figlet
{{command}} | figlet

# Show available figlet fonts
showfigfonts {{optional_string_to_display}}

# Give a description of the type of the specified file. Works fine for files with no file extension
file {{filename}}

# Look inside a zipped file and determine the file type(s) inside
file -z {{foo.zip}}

# Allow file to work with special or device files
file -s {{filename}}

# Don't stop at first file type match; keep going until the end of the file
file -k {{filename}}

# Determine the mime encoding type of a file
file -i {{filename}}

# List all mounted filesystems
findmnt

# Search for a device
findmnt {{/dev/sdb1}}

# Search for a mountpoint
findmnt {{/}}

# Find filesystems in specific type
findmnt -t {{ext4}}

# Find filesystems with specific label
findmnt LABEL={{BigStorage}}

# Integrate firejail with your desktop environment
sudo firecfg

# Open a restricted Mozilla Firefox
firejail {{firefox}}

# Start a restricted Apache server on a known interface and address
firejail --net={{eth0}} --ip={{192.168.1.244}} {{/etc/init.d/apache2}} {{start}}

# List running sandboxes
firejail --list

# List network activity from running sandboxes
firejail --netstats

# Shutdown a running sandbox
firejail --shutdown={{7777}}

# View the available firewall zones
firewall-cmd --get-active-zones

# View the rules which are currently applied
firewall-cmd --list-all

# Permanently open the port for a service in the specified zone (like port `443` when in the `public` zone)
firewall-cmd --permanent --zone={{public}} --add-service={{https}}

# Permanently close the port for a service in the specified zone (like port `80` when in the `public` zone)
firewall-cmd --permanent --zone={{public}} --remove-service={{http}}

# Reload firewalld to force rule changes to take effect
firewall-cmd --reload

# Run an installed application
flatpak run {{name}}

# Install an application from a remote source
flatpak install {{remote}} {{name}}

# List all installed applications and runtimes
flatpak list

# Update all installed applications and runtimes
flatpak update

# Add a remote source
flatpak remote-add --if-not-exists {{remote_name}} {{remote_url}}

# List all configured remote sources
flatpak remote-list

# Start an application with the Procfile in the current directory
foreman start

# Start an application with a specified Procfile
foreman start -f {{Procfile}}

# Start a specific application
foreman start {{process}}

# Validate Procfile format
foreman check

# Run one-off commands with the process's environment
foreman run {{command}}

# Start all processes except the one named "worker"
foreman start -m all=1,{{worker}}=0

# Display system memory
free

# Display memory in Bytes/KB/MB/GB
free -{{b|k|m|g}}

# Display memory in human readable units
free -h

# Refresh the output every 2 seconds
free -s {{2}}

# Check filesystem /dev/sda, reporting any damaged blocks
fsck {{/dev/sda}}

# Check filesystem /dev/sda, reporting any damaged blocks and interactively letting the user choose to repair each one
fsck -r {{/dev/sda}}

# Check filesystem /dev/sda, reporting any damaged blocks and automatically repairing them
fsck -a {{/dev/sda}}

# Identify process using a TCP socket
fuser -n tcp {{port}}

# Automatically compile and install a generic kernel
sudo genkernel all

# Build and install the bzImage|initramfs|kernel|ramdisk only
sudo genkernel {{bzImage|initramfs|kernel|ramdisk}}

# Apply changes to the kernel configuration before compiling and installing
sudo genkernel --menuconfig all

# Generate a kernel with a custom name
sudo genkernel --kernname={{custom_name}} all

# Use a kernel source outside of the default directory /usr/src/linux
sudo genkernel --kerneldir={{path/to/directory}} all

# Get list of all groups
getent group

# See the members of a group
getenet group {{group_name}}

# Get list of all services
getent services

# Find a username by UID
getent passwd 1000

# Perform a reverse DNS lookup
getent hosts {{host}}

# Display the file access control list
getfacl {{path/to/file_or_folder}}

# Display the file access control list with numeric user and group IDs
getfacl -n {{path/to/file_or_folder}}

# Display the file access control list with tabular output format
getfacl -t {{path/to/file_or_folder}}

# Open a new GNOME terminal window
gnome-terminal

# Run a specific command in a new terminal window
gnome-terminal -- {{command}}

# Open a new tab in the last opened window instead
gnome-terminal --tab

# Set the title of the new tab
gnome-terminal --tab --title "{{title}}"

# Define group administrators
sudo gpasswd -A {{user1,user2}} {{group}}

# Set the list of group members
sudo gpasswd -M {{user1,user2}} {{group}}

# Create a password for the named group
gpasswd {{group}}

# Add a user to the named group
gpasswd -a {{user}} {{group}}

# Remove a user from the named group
gpasswd -d {{user}} {{group}}

# Create a new Linux group
groupadd {{group_name}}

# Create new group with a specific groupid
groupadd {{group_name}} -g {{group_id}}

# Delete an existing group
groupdel {{group_name}}

# Change the group name
groupmod -n {{new_group_name}} {{old_group_name}}

# Change the group id
groupmod -g {{new_group_id}} {{old_group_name}}

# To view a file
gs -dQUIET -dBATCH {{file.pdf}}

# Reduce PDF file size to 150 dpi images for reading on a ebook device
gs -dNOPAUSE -dQUIET -dBATCH -sDEVICE=pdfwrite -dPDFSETTINGS=/ebook -sOutputFile={{output.pdf}} {{input.pdf}}

# Convert PDF file (pages 1 through 3) to an image with 150 dpi resolution
gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=jpeg -r150 -dFirstPage={{1}} -dLastPage={{3}} -sOutputFile={{output_%d.jpg}} {{input.pdf}}

# Extract pages from a PDF file
gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.pdf}}

# Merge PDF files
gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input1.pdf}} {{input2.pdf}}

# Convert from PostScript file to PDF file
gs -dQUIET -dBATCH -dNOPAUSE -sDEVICE=pdfwrite -sOutputFile={{output.pdf}} {{input.ps}}

# Install a new package
guix package -i {{package_name}}

# Remove a package
guix package -r {{package_name}}

# Search the package database for a regular expression
guix package -s "{{search_pattern}}"

# List installed packages
guix package -I

# List generations
guix package -l

# Roll back to the previous generation
guix package --roll-back

# Run Python web app
gunicorn {{import.path:app_object}}

# Listen on port 8080 on localhost
gunicorn --bind {{localhost}}:{{8080}} {{import.path:app_object}}

# Turn on live reload
gunicorn --reload {{import.path:app_object}}

# Use 4 worker processes for handling requests
gunicorn --workers {{4}} {{import.path:app_object}}

# Use 4 worker threads for handling requests
gunicorn --threads {{4}} {{import.path:app_object}}

# Run app over HTTPS
gunicorn --certfile {{cert.pem}} --keyfile {{key.pem}} {{import.path:app_object}}

# Power the machine off
halt

# Reboot the machine
halt --reboot

# Start hardinfo
hardinfo

# Print report to standard output
hardinfo -r

# Save report to HTML file
hardinfo -r -f html > hardinfo.html

# Print the hexadecimal representation of a file
hexdump {{file}}

# Display the input offset in hexadecimal and its ASCII representation in two columns
hexdump -C {{file}}

# Display the hexadecimal representation of a file, but interpret only n bytes of the input
hexdump -C -n{{number_of_bytes}} {{file}}

# Show current host name
hostname

# Show the network address of the host name
hostname -i

# Show all network addresses of the host
hostname -I

# Show the FQDN (Fully Qualified Domain Name)
hostname --fqdn

# Set current host name
hostname {{new_hostname}}

# Get the hostname of the computer
hostnamectl

# Set the hostname of the computer
sudo hostnamectl set-hostname "{{some_hostname}}"

# Start htop
htop

# Start htop displaying only processes owned by given user
htop -u {{user_name}}

# Get help about interactive commands
?

# Launch a session targeting the default url of http://localhost:8000 or the previous session
http-prompt

# Launch a session with a given url
http-prompt {{http://example.com}}

# Launch a session with some initial options
http-prompt {{localhost:8000/api}} --auth {{username:password}}

# Send a GET request (default method with no request data)
http {{https://example.com}}

# Send a POST request (default method with request data)
http {{https://example.com}} {{hello=World}}

# Send a POST request with redirected input
http {{https://example.com}} < {{file.json}}

# Send a PUT request with a given json body
http PUT {{https://example.com/todos/7}} {{hello=world}}

# Send a DELETE request with a given request header
http DELETE {{https://example.com/todos/7}} {{API-Key:foo}}

# Show the whole HTTP exchange (both request and response)
http -v {{https://example.com}}

# Download a file
http --download {{https://example.com}}

# Display the current time as reported by the hardware clock
hwclock

# Write the current software clock time to the hardware clock (sometimes used during system setup)
hwclock --systohc

# Write the current hardware clock time to the software clock
hwclock --hctosys

# Start i7z (needs to be run in super user mode)
sudo i7z

# Disable interface eth0
ifdown {{eth0}}

# Disable all interfaces which are enabled
ifdown -a

# Enable interface eth0
ifup {{eth0}}

# Enable all the interfaces defined with "auto" in /etc/network/interfaces
ifup -a

# Convert single images and/or whole directories containing valid image formats
imgp -x {{1366x1000}} {{path/to/dir}} {{path/to/file}}

# Scale an image by 75% and overwrite the source image to a target resolution
imgp -x {{75}} -w {{path/to/file}}

# Rotate an image clockwise by 90 degrees
imgp -o {{90}} {{path/to/file}}

# Print a short summary of CPU, memory, hard drive and kernel information
inxi

# Print a full description of CPU, memory, disk, network and process information
inxi -Fz

# Display a report of CPU and disk statistics since system startup
iostat

# Display a report of CPU and disk statistics with units converted to megabytes
iostat -m

# Display CPU statistics
iostat -c

# Display disk statistics with disk names (including LVM)
iostat -N

# Display extended disk statistics with disk names for device "sda"
iostat -xN {{sda}}

# Display incremental reports of CPU and disk statistics every 2 seconds
iostat {{2}}

# List interfaces with detailed info
ip a

# Display the routing table
ip r

# Show neighbors (ARP table)
ip n

# Make an interface up/down
ip link set {{interface}} up/down

# Add/Delete an ip address to an interface
ip addr add/del {{ip}}/{{mask}} dev {{interface}}

# Add a default route
ip route add default via {{ip}} dev {{interface}}

# Show information about an address or network with a given subnet mask
ipcalc {{1.2.3.4}} {{255.255.255.0}}

# Show information about an address or network in CIDR notation
ipcalc {{1.2.3.4}}/{{24}}

# Show the broadcast address of an address or network
ipcalc -b {{1.2.3.4}}/{{30}}

# Show the network address of provided IP address and netmask
ipcalc -n {{1.2.3.4}}/{{24}}

# Display geographic information about a given IP address
ipcalc -g {{1.2.3.4}}

# View chains, rules, and packet/byte counters for all tables
sudo iptables -vnL

# Set chain policy rule
sudo iptables -P {{chain}} {{rule}}

# Append rule to chain policy for IP
sudo iptables -A {{chain}} -s {{ip}} -j {{rule}}

# Append rule to chain policy for IP considering protocol and port
sudo iptables -A {{chain}} -s {{ip}} -p {{protocol}} --dport {{port}} -j {{rule}}

# Delete chain rule
sudo iptables -D {{chain}} {{rule_line_number}}

# Save iptables configuration of a given table to a file
sudo iptables-save -t {{tablename}} > {{path/to/iptables_file}}

# Restore iptables configuration from a file
sudo iptables-restore < {{path/to/iptables_file}}

# List all the files included in an ISO image
isoinfo -f -i {{path/to/image.iso}}

# E[x]tract a specific file from an ISO image and send it out stdout
isoinfo -i {{path/to/image.iso}} -x {{/PATH/TO/FILE/INSIDE/ISO.EXT}}

# Show header information for an ISO disk image
isoinfo -d -i {{path/to/image.iso}}

# Scan for available wireless networks
iw dev {{wlp}} scan

# Join an open wireless network
iw dev {{wlp}} connect {{SSID}}

# Close the current connection
iw dev {{wlp}} disconnect

# Show information about the current connection
iw dev {{wlp}} link

# View jobs spawned by the current shell
jobs

# List jobs and their process ids
jobs -l

# Display information about jobs with changed status
jobs -n

# Display process id of process group leader
jobs -p

# Display running processes
jobs -r

# Display stopped processes
jobs -s

# Show all messages from this boot
journalctl -b

# Show all messages from last boot
journalctl -b -1

# Follow new messages (like `tail -f` for traditional syslog)
journalctl -f

# Show all messages by a specific unit
journalctl -u {{unit}}

# Show all messages by a specific process
journalctl _PID={{pid}}

# Show all messages by a specific executable
journalctl {{path/to/executable}}

# Load a new kernel
kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --command-line={{arguments}}

# Load a new kernel with current boot parameters
kexec -l {{path/to/kernel}} --initrd={{path/to/initrd}} --reuse-cmdline

# Execute a currently loaded kernel
kexec -e

# Unload current kexec target kernel
kexec -u

# Display the most recent login of all users
lastlog

# Display lastlog record of the specified user
lastlog -u {{username}}

# Display records before than 7 days
lastlog -b {{7}}

# Display records more recent than 3 days
lastlog -t {{3}}

# Update symlinks and rebuild the cache (usually run when a new library is installed)
sudo ldconfig

# Update the symlinks for a given directory
sudo ldconfig -n {{path/to/directory}}

# Print the libraries in the cache and check whether a given library is present
ldconfig -p | grep {{library_name}}

# Display shared library dependencies of a binary
ldd {{path/to/binary}}

# Display unused direct dependencies
ldd -u {{path/to/binary}}

# Get the current backlight value in percent
light

# Set the backlight value to 50 percent
light -S {{50}}

# Reduce 20 percent from the current backlight value
light -U {{20}}

# Add 20 percent to the current backlight value
light -A {{20}}

# Debug an executable
lldb {{executable}}

# Attach `lldb` to a running process with a given PID
lldb -p {{pid}}

# Wait for a new process to launch with a given name, and attach to it
lldb -w -n {{process_name}}

# Look for pattern in the database. Note: the database is recomputed periodically (usually weekly or daily)
locate {{pattern}}

# Look for a file by its exact filename (a pattern containing no globbing characters is interpreted as `*pattern*`)
locate */{{filename}}

# Recompute the database. You need to do it if you want to find recently added files
sudo updatedb

# Log a message to syslog
logger {{message}}

# Take input from stdin and log to syslog
echo {{log_entry}} | logger

# Send the output to a remote syslog server running at a given port. Default port is 514
echo {{log_entry}} | logger --server {{hostname}} --port {{port}}

# Use a specific tag for every line logged. Default is the name of logged in user
echo {{log_entry}} | logger --tag {{tag}}

# Log messages with a given priority. Default is `user.notice`. See `man logger` for all priority options
echo {{log_entry}} | logger --priority {{user.warning}}

# Analyze logs for a range of dates at certain level of detail
logwatch --range {{yesterday|today|all|help}} --detail {{low|medium|others}}'

# Restrict report to only include information for a selected service
logwatch --range {{all}} --service {{apache|pam_unix|etc}}

# List loop devices with detailed info
losetup -a

# Attach a file to a given loop device
sudo losetup /dev/{{loop}} /{{path/to/file}}

# Detach all loop devices
sudo losetup -D

# Detach a given loop device
sudo losetup -d /dev/{{loop}}

# Decompress a file
lrunzip {{filename.lrz}}

# Decompress a file using a specific number of processor threads
lrunzip -p {{8}} {{filename.lrz}}

# Decompress a file and silently overwrite files if they exist
lrunzip -f {{filename.lrz}}

# Keep broken or damaged files instead of deleting them when decompressing
lrunzip -K {{filename.lrz}}

# Specify output file name and/or path
lrunzip -o {{outfilename}} {{filename.lrz}}

# Compress a file with LZMA - slow compression, fast decompression
lrzip {{filename}}

# Compress a file with BZIP2 - good middle ground for compression/speed
lrzip -b {{filename}}

# Compress with ZPAQ - extreme compression, but very slow
lrzip -z {{filename}}

# Compress with LZO - light compression, extremely fast decompression
lrzip -l {{filename}}

# Compress a file and password protect/encrypt it
lrzip -e {{filename}}

# Override the number of processor threads to use
lrzip -p {{8}} {{filename}}

# Archive a directory with `tar`, then compress
lrztar {{path/to/directory}}

# Same as above, with ZPAQ - extreme compression, but very slow
lrztar -z {{path/to/directory}}

# Specify the output file
lrztar -o {{path/to/file}} {{path/to/directory}}

# Override the number of processor threads to use
lrztar -p {{8}} {{path/to/directory}}

# Force overwriting of existing files
lrztar -f {{path/to/directory}}

# Decompress from a file to the current directory
lrzuntar {{path/to/archive.tar.lrz}}

# Decompress from a file to the current directory using a specific number of processor threads
lrzuntar -p {{8}} {{path/to/archive.tar.lrz}}

# Decompress from a file to the current directory and silently overwrite items that already exist
lrzuntar -f {{archive.tar.lrz}}

# Specify the output path
lrzuntar -O {{path/to/directory}} {{archive.tar.lrz}}

# Delete the compressed file after decompression
lrzuntar -D {{path/to/archive.tar.lrz}}

# Display the attributes of the files in the current directory
lsattr

# List the attributes of files in a particular path
lsattr {{path}}

# List file attributes recursively in the current and subsequent directories
lsattr -R

# Show attributes of all the files in the current directory, including hidden ones
lsattr -a

# Display attributes of directories in the current directory
lsattr -d

# Print all available information
lsb_release -a

# Print a description (usually the full name) of the operating system
lsb_release -d

# Print only the operating system name (ID), suppressing the field name
lsb_release -i -s

# Print the release number and codename of the distribution, suppressing the field names
lsb_release -rcs

# List all storage devices in a tree-like format
lsblk

# Also list empty devices
lsblk -a

# Print the SIZE column in bytes rather than in a human-readable format
lsblk -b

# Output info about filesystems
lsblk -f

# Use ASCII characters for tree formatting
lsblk -i

# Output info about block-device topology
lsblk -t

# Display information about all CPUs
lscpu

# Display information in a table
lscpu --extended

# Display only information about offline CPUs in a table
lscpu --extended --offline

# Launch the GUI
sudo lshw -X

# List all hardwares in tabular format
sudo lshw -short

# List all disks and storage controllers in tabular format
sudo lshw -class disk -class storage -short

# Save all network interfaces to an HTML file
sudo lshw -class network -html > {{interfaces.html}}

# List all currently loaded kernel modules
lsmod

# Show a brief list of devices
lspci

# Display additional info
lspci -v

# Display drivers and modules handling each device
lspci -k

# Show a specific device
lspci -s {{00:18.3}}

# Dump info in a readable form
lspci -vm

# List all SCSI devices
lsscsi

# List all SCSI devices with detailed attributes
lsscsi -L

# List all SCSI devices with human readable disk capacity
lsscsi -s

# List all the USB devices available
lsusb

# List the USB hierarchy as a tree
lsusb -t

# List verbose information about USB devices
lsusb --verbose

# List detailed information about a USB device
lsusb -D {{device}}

# List devices with a specified vendor and product id only
lsusb -d {{vendor}}:{{product}}

# Print (trace) library calls of a program binary
ltrace ./{{program}}

# Count library calls. Print a handy summary at the bottom
ltrace -c {{/path/to/program}}

# Trace calls to malloc and free, omit those done by libc
ltrace -e malloc+free-@libc.so* {{/path/to/program}}

# Write to file instead of terminal
ltrace -o {{file}} {{/path/to/program}}

# Create a logical volume of 10 gigabytes in the volume group vg1
lvcreate -L {{10G}} {{vg1}}

# Create a 1500 megabyte linear logical volume named mylv in the volume group vg1
lvcreate -L {{1500}} -n {{mylv}} {{vg1}}

# Create a logical volume called mylv that uses 60% of the total space in volume group vg1
lvcreate -l {{60%VG}} -n {{mylv}} {{vg1}}

# Create a logical volume called mylv that uses all of the unallocated space in the volume group vg1
lvcreate -l {{100%FREE}} -n {{mylv}} {{vg1}}

# List local containers matching a string. Omit the string to list all local containers
lxc list {{match_string}}

# List images matching a string. Omit the string to list all images
lxc image list [{{remote}}:]{{match_string}}

# Create a new container from an image
lxc launch [{{remote}}:]{{image}} {{container}}

# Start a container
lxc start [{{remote}}:]{{container}}

# Stop a container
lxc stop [{{remote}}:]{{container}}

# Show detailed info about a container
lxc info [{{remote}}:]{{container}}

# Take a snapshot of a container
lxc snapshot [{{remote}}:]{{container}} {{snapshot}}

# Create array
mdadm --create {{/path/to/raid_device_file}} --level {{raid_level}} --raid-devices {{number_of_disks}} {{/path/to/disk_device_file}}

# Stop array
mdadm -S {{/path/to/raid_device_file}}

# Mark disk as failed
mdadm {{/path/to/raid_device_file}} -f {{/path/to/disk_device_file}}

# Remove disk
mdadm {{/path/to/raid_device_file}} -r {{/path/to/disk_device_file}}

# Add disk to array
mdadm {{/path/to/raid_device_file}} -a {{/path/to/disk_device_file}}

# Show RAID info
mdadm -D {{/path/to/raid_device_file}}

# Open a serial port using the specified baud rate
microcom --port {{path/to/serial_port}} --speed {{baud_rate}}

# Establish a telnet connection to the specified host
microcom --telnet {{hostname}}:{{port}}

# Create an ext2 filesystem in partition 1 of device b (`sdb1`)
mkfs.ext2 {{/dev/sdb1}}

# Create an ext3 filesystem in partition 1 of device b (`sdb1`)
mkfs.ext3 {{/dev/sdb1}}

# Create an ext3 filesystem in partition 1 of device b (`sdb1`)
mkfs.ext3 {{/dev/sdb1}}

# Create a ROM filesystem inside partition 1 on device b (`sdb1`)
mkfs.cramfs {{/dev/sdb1}}

# Create a ROM filesystem with a volume-name
mkfs.cramfs -n {{volume_name}} {{/dev/sdb1}}

# Create an exfat  filesystem inside partition 1 on device b (`sdb1`)
mkfs.exfat {{/dev/sdb1}}

# Create filesystem with a volume-name
mkfs.exfat -n {{volume_name}} {{/dev/sdb1}}

# Create filesystem with a volume-id
mkfs.exfat -i {{volume_id}} {{/dev/sdb1}}

# Create a fat filesystem inside partition 1 on device b (`sdb1`)
mkfs.fat {{/dev/sdb1}}

# Create filesystem with a volume-name
mkfs.fat -n {{volume_name}} {{/dev/sdb1}}

# Create filesystem with a volume-id
mkfs.fat -i {{volume_id}} {{/dev/sdb1}}

# Use 5 instead of 2 file allocation tables
mkfs.fat -f 5 {{/dev/sdb1}}

# Create a Minix filesystem inside partition 1 on device b (`sdb1`)
mkfs.minix {{/dev/sdb1}}

# Create a NTFS filesystem inside partition 1 on device b (`sdb1`)
mkfs.ntfs {{/dev/sdb1}}

# Create filesystem with a volume-label
mkfs.ntfs -L {{volume_label}} {{/dev/sdb1}}

# Create filesystem with specific UUID
mkfs.ntfs -U {{UUID}} {{/dev/sdb1}}

# Create a.vfat filesystem inside partition 1 on device b (`sdb1`)
mkfs.vfat {{/dev/sdb1}}

# Create filesystem with a volume-name
mkfs.vfat -n {{volume_name}} {{/dev/sdb1}}

# Create filesystem with a volume-id
mkfs.vfat -i {{volume_id}} {{/dev/sdb1}}

# Use 5 instead of 2 file allocation tables
mkfs.vfat -f 5 {{/dev/sdb1}}

# Create an ISO from a folder
mkisofs -o {{filename.iso}} {{path/to/source_folder}}

# Set the disc label when creating an ISO
mkisofs -o {{filename.iso}} -V {{"label_name"}} {{path/to/source_folder}}

# Create a block device
sudo mknod {{path/to/device_file}} b {{major_device_number}} {{minor_device_number}}

# Create a character device
sudo mknod {{path/to/device_file}} c {{major_device_number}} {{minor_device_number}}

# Create a FIFO (queue) device
sudo mknod {{path/to/device_file}} p

# Create a device file with default SELinux security context
sudo mknod -Z {{path/to/device_file}} {{type}} {{major_device_number}} {{minor_device_number}}

# Setup a given partition as swap area
sudo mkswap {{/dev/sdb7}}

# Use a given file as swap area
sudo mkswap {{path/to/file}}

# Check a partition for bad blocks before creating the swap area
sudo mkswap -c {{/dev/sdb7}}

# Specify a label for the file (to allow `swapon` to use the label)
sudo mkswap -L {{swap1}} {{path/to/file}}

# List all attributes of a kernel module
modinfo {{kernel_module}}

# List the specified attribute only
modinfo -F {{author|description|license|parm|filename}} {{kernel_module}}

# Pretend to load a module into the kernel, but don't actually do it
sudo modprobe --dry-run {{module_name}}

# Load a module into the kernel
sudo modprobe {{module_name}}

# Remove a module from the kernel
sudo modprobe --remove {{module_name}}

# Remove a module and those that depend on it from the kernel
sudo modprobe --remove-dependencies {{module_name}}

# Show a kernel module's dependencies
sudo modprobe --show-depends {{module_name}}

# Display CPU statistics every 2 seconds
mpstat {{2}}

# Display 5 reports, one by one, at 2 second intervals
mpstat {{2}} {{5}}

# Display 5 reports, one by one, from a given processor, at 2 second intervals
mpstat -P {{0}} {{2}} {{5}}

# Connect to a database with the currently logged in user
mycli {{database_name}}

# Connect to a database with the specified user
mycli -u {{user}} {{database_name}}

# Connect to a database on the specified host with the specified user
mycli -u {{user}} -h {{host}} {{database_name}}

# Install a given version of node. If the version is already installed, it will be activated
n {{version}}

# Display installed versions and interactively activate one of them
n

# Remove a version
n rm {{version}}

# Execute a file with a given version
n use {{version}} {{file.js}}

# Output binary path for a version
n bin {{version}}

# Resolve the pathnames specified as the argument parameters
namei {{path/to/a}} {{path/to/b}} {{path/to/c}}

# Display the results in a long-listing format
namei --long {{path/to/a}} {{path/to/b}} {{path/to/c}}

# Show the mode bits of each file type in the style of `ls`
namei --modes {{path/to/a}} {{path/to/b}} {{path/to/c}}

# Show owner and group name of each file
namei --owners {{path/to/a}} {{path/to/b}} {{path/to/c}}

# Don't follow symlinks while resolving
namei --nosymlinks {{path/to/a}} {{path/to/b}} {{path/to/c}}

# Listen for input on the specified port and write it to the specified file
ncat -l {{port}} > {{path/to/file}}

# Accept multiple connections and keep ncat open after they have been closed
ncat -lk {{port}}

# Write output of specified file to the specified host on the specified port
ncat {{address}} {{port}} < {{path/to/file}}

# Analyze the current working directory
ncdu

# Analyze a given directory
ncdu {{path/to/directory}}

# Save results to a file
ncdu -o {{path/to/file}}

# Exclude files that match a pattern, argument can be given multiple times to add more patterns
ncdu --exclude '{{*.txt}}'

# Create an 'fsdax' mode namespace
ndctl create-namespace --mode={{fsdax}}

# Change the mode of a namespace to 'raw'
ndctl create-namespace --reconfigure={{namespaceX.Y}} --mode={{raw}}

# Check a sector mode namespace for consistency, and repair if needed
ndctl check-namespace --repair {{namespaceX.Y}}

# List all namespaces, regions, and buses (including disabled ones)
ndctl list --namespaces --regions --buses --idle

# List a specific namespace and include lots of additional information
ndctl list -vvv --namespace={{namespaceX.Y}}

# Run a monitor to watch for SMART health events for NVDIMMs on the 'ACPI.NFIT' bus
ndctl monitor --bus={{ACPI.NFIT}}

# Remove a namespace (when applicable) or reset it to an initial state
ndctl destroy-namespace --force {{namespaceX.Y}}

# Start nethogs as root (default device is eth0)
sudo nethogs

# Monitor bandwidth on specific device
sudo nethogs {{device}}

# Monitor bandwidth on multiple devices
sudo nethogs {{device1}} {{device2}}

# Specify refresh rate
sudo nethogs -t {{seconds}}

# List all ports
netstat -a

# List all listening ports
netstat -l

# List listening TCP ports
netstat -t

# Display PID and program names
netstat -p

# List information continuously
netstat -c

# List routes and do not resolve IP to hostname
netstat -rn

# List listening TCP and UDP ports (+ user and process if you're root)
netstat -lepunt

# View current configuration
sudo nft list ruleset

# Add a new table with family "inet" and table "filter"
sudo nft add table {{inet}} {{filter}}

# Add a new chain to accept all inbound traffic
sudo nft add chain {{inet}} {{filter}} {{input}} \{ type {{filter}} hook {{input}} priority {{0}} \; policy {{accept}} \}

# Add a new rule to accept several TCP ports
sudo nft add rule {{inet}} {{filter}} {{input}} {{tcp}} {{dport \{ telnet, ssh, http, https \} accept}}

# Show rule handles
sudo nft --handle --numeric list chain {{family}} {{table}} {{chain}}

# Delete a rule
sudo nft delete rule {{inet}} {{filter}} {{input}} handle {{3}}

# Save current configuration
sudo nft list ruleset > {{/etc/nftables.conf}}

# List global (extern) functions in a file (prefixed with T)
nm -g {{file.o}}

# Demangle C++ symbols (make them readable)
nm --demangle {{file.o}}

# List only undefined symbols in a file
nm -u {{file.o}}

# List all symbols, even debugging symbols
nm -a {{file.o}}

# List all NetworkManager connections (shows name, uuid, type and device)
nmcli connection

# Print the available Wi-Fi access points
nmcli device wifi

# Connect to the Wi-Fi network with a specified name and password
nmcli device wifi connect {{name}} {{password}}

# Activate a connection by specifying an uuid
nmcli connection up uuid {{uuid}}

# Deactivate a connection
nmcli connection down uuid {{uuid}}

# Print statuses of network interfaces
nmcli device status

# Start nmon
nmon

# Save records to file ("-s 300 -c 288" by default)
nmon -f

# Save records to file with a total of 240 measurements, by taking 30 seconds between each measurement
nmon -f -s {{30}} -c {{240}}

# Open the user interface
nmtui

# Show a list of available connections, with the option to activate or deactivate them
nmtui connect

# Connect to a given network
nmtui connect {{name|uuid|device|SSID}}

# Edit/Add/Delete a given network
nmtui edit {{name|id}}

# Set the system hostname
nmtui hostname

# Show a notification with the title "Test" and the content "This is a test"
notify-send {{"Test"}} {{"This is a test"}}

# Show a notification with a custom icon
notify-send -i {{icon.png}} {{"Test"}} {{"This is a test"}}

# Show a notification for 5 seconds
notify-send -t 5000 {{"Test"}} {{"This is a test"}}

# Fix a given NTFS partition
sudo ntfsfix {{/dev/sdb2}}

# Display the file header information
objdump -f {{binary}}

# Display the dis-assembled output of executable sections
objdump -d {{binary}}

# Display a complete binary hex dump of all sections
objdump -s {{binary}}

# Install a package
opkg install {{package}}

# Remove a package
opkg remove {{package}}

# Update the list of available packages
opkg update

# Upgrade all the installed packages
opkg upgrade

# Upgrade one or more specific package(s)
opkg upgrade {{package(s)}}

# Display informations for a specific package
opkg info {{package}}

# List all the available packages
opkg list

# Synchronize and update all packages (includes AUR)
pacaur -Syu

# Synchronize and update only AUR packages
pacaur -Syua

# Install a new package (includes AUR)
pacaur -S {{package_name}}

# Remove a package and its dependencies (includes AUR packages)
pacaur -Rs {{package_name}}

# Search the package database for a keyword (includes AUR)
pacaur -Ss {{keyword}}

# List all currently installed packages (includes AUR packages)
pacaur -Qs

# Synchronize and update all packages
pacman -Syu

# Install a new package
pacman -S {{package_name}}

# Remove a package and its dependencies
pacman -Rs {{package_name}}

# Search the package database for a regular expression or keyword
pacman -Ss "{{search_pattern}}"

# List installed packages and versions
pacman -Q

# List only the explicitly installed packages and versions
pacman -Qe

# Find which package owns a certain file
pacman -Qo {{filename}}

# Empty package cache to free up space
pacman -Scc

# Suspend pulseaudio while running `jackd`
pasuspender -- {{jackd -d alsa --device hw:0}}

# Find lines that match pattern in a PDF
pdfgrep {{pattern}} {{file.pdf}}

# Include file name and page number for each matched line
pdfgrep --with-filename --page-number {{pattern}} {{file.pdf}}

# Do a case insensitive search for lines that begin with "foo" and return the first 3 matches
pdfgrep --max-count {{3}} --ignore-case {{'^foo'}} {{file.pdf}}

# Find pattern in files with a .pdf extension in the current directory recursively
pdfgrep --recursive {{pattern}}

# Find pattern on files that match a specific glob in the current directory recursively
pdfgrep --recursive --include {{'*book.pdf'}} {{pattern}}

# Display basic performance counter stats for a command
perf stat {{gcc hello.c}}

# Display system-wide real time performance counter profile
sudo perf top

# Run a command and record its profile into "perf.data"
sudo perf record {{command}}

# Read "perf.data" (created by `perf record`) and display the profile
sudo perf report

# Add space-separated files or directories to a Phar file
phar add -f {{path/to/phar_file}} {{files_or_directories}}

# Display the contents of a Phar file
phar list -f {{path/to/phar_file}}

# Delete the specified file or directory from a Phar file
phar delete -f {{path/to/phar_file}} -e {{file_or_directory}}

# Display full usage information and available hashing/compression algorithms
phar help

# Compress or uncompress files and directories in a Phar file
phar compress -f {{path/to/phar_file}} -c {{algorithm}}

# Get information about a Phar file
phar info -f {{path/to/phar_file}}

# Sign a Phar file with a specific hash algorithm
phar sign -f {{path/to/phar_file}} -h {{algorithm}}

# Sign a Phar file with an OpenSSL private key
phar sign -f {{path/to/phar_file}} -h openssl -y {{path/to/private_key}}

# Install a local software package
pkgadd {{package_name}}

# Update an already installed package from a local package
pkgadd -u {{package_name}}

# List installed packages and their versions
pkginfo -i

# List files owned by a package
pkginfo -l {{package_name}}

# List the owner(s) of files matching a pattern
pkginfo -o {{pattern}}

# Print the footprint of a file
pkginfo -f {{file}}

# Make and download a package
pkgmk -d

# Install the package after making it
pkgmk -d -i

# Upgrade the package after making it
pkgmk -d -u

# Ignore the footprint when making a package
pkgmk -d -if

# Ignore the MD5 sum when making a package
pkgmk -d -im

# Update the package's footprint
pkgmk -uf

# Remove an installed package
pkgrm {{package_name}}

# Toggle play
playerctl play-pause

# Next media
playerctl next

# Previous media
playerctl previous

# List all players
playerctl --list-all

# Send a command to a specific player
playerctl --player={{player_name}} {{command}}

# Send a command to all players
playerctl --all-players {{command}}

# Remove the top directory from the stack and cd to it
popd

# Remove the Nth directory (starting from zero to the left from the list printed with `dirs`)
popd +N

# Remove the Nth directory (starting from zero to the right from the list printed with `dirs`)
popd -N

# Update the ports tree
ports -u

# List the ports in the current tree
ports -l

# Check the differences between installed packages and the ports tree
ports -d

# Print action can be used to print any file on default run-mailcap tool
print {{filename}}

# With `run-mailcap`
run-mailcap --action=print {{filename}}

# Install a package
prt-get install {{package_name}}

# Install a package with dependency handling
prt-get depinst {{package_name}}

# Update a package manually
prt-get upgrade {{package_name}}

# Remove a package
prt-get remove {{package_name}}

# Upgrade the system from the local ports tree
prt-get sysup

# Search the ports tree
prt-get search {{package_name}}

# Search for a file in a package
prt-get fsearch {{file}}

# Display a tree of processes
pstree

# Display a tree of processes with PIDs
pstree -p

# Display all process trees rooted at processes owned by specified user
pstree {{user}}

# Check if pulseaudio is running (a non-zero exit code means it is not running)
pulseaudio --check

# Start the pulseaudio daemon in the background
pulseaudio --start

# Kill the running pulseaudio daemon
pulseaudio --kill

# List available modules
pulseaudio --dump-modules

# Load a module into the currently running daemon with the specified arguments
pulseaudio --load="{{module_name}} {{arguments}}"

# Switch to directory and push it on the stack
pushd < {{directory}}

# Switch first and second directories on the stack
pushd

# Rotate stack by making the 5th element the top of the stack
pushd +4

# Initialize the `/dev/sda1` volume for use by LVM
pvcreate {{/dev/sda1}}

# Force the creation without any confirmation prompts
pvcreate --force {{/dev/sda1}}

# Generate random password with s[y]mbols
pwgen -y {{length}}

# Generate secure, hard-to-memorize passwords
pwgen -s {{length}}

# Generate password with at least one capital letter in them
pwgen -c {{length}}

# Submit a script with default settings (depends on TORQUE settings)
qsub {{script.sh}}

# Submit a script with a specified wallclock runtime limit of 1 hour, 2 minutes and 3 seconds
qsub -l walltime={{1}}:{{2}}:{{3}} {{script.sh}}

# Submit a script that is executed on 2 nodes using 4 cores per node
qsub -l nodes={{2}}:ppn={{4}} {{script.sh}}

# Submit a script to a specific queue. Note that different queues can have different maximum and minimum runtime limits
qsub -q {{queue_name}} {{script.sh}}

# Check quotas on all mounted non-NFS filesystems
sudo quotacheck --all

# Force check even if quotas are enabled (this can cause damage or loss to quota files)
sudo quotacheck --force {{mountpoint}}

# Check quotas on a given filesystem in debug mode
sudo quotacheck --debug {{mountpoint}}

# Check quotas on a given filesystem, displaying the progress
sudo quotacheck --verbose {{mountpoint}}

# Check user quotas
sudo quotacheck --user {{user}} {{mountpoint}}

# Check group quotas
sudo quotacheck --group {{group}} {{mountpoint}}

# Connect to a remote computer (default port is 3389)
rdesktop -u {{username}} -p {{password}} {{host:port}}

# Simple Examples
rdesktop -u Administrator -p passwd123 192.168.1.111:3389

# Connect to a remote computer with full screen (press `Ctrl + Alt + Enter` to exist)
rdesktop -u {{username}} -p {{password}} -f {{host:port}}

# Use the customed resolution (use the letter 'x' between the number)
rdesktop -u {{username}} -p {{password}} -g 1366x768 {{host:port}}

# Connect to a remote computer using domain user
rdesktop -u {{username}} -p {{password}} -d {{domainname}} {{host:port}}

# Use the 16 bit color (speed up)
rdesktop -u {{username}} -p {{password}} -a 16 {{host:port}}

# Reboot immediately
reboot

# Reboot immediately without gracefully shutdown
reboot -f

# Report stats for all quotas in use
sudo repquota -all

# Report quota stats for all users, even those who aren't using any of their quota
sudo repquota -v {{filesystem}}

# Report on quotas for users only
repquota --user {{filesystem}}

# Report on quotas for groups only
sudo repquota --group {{filesystem}}

# Report on used quota and limits in a human-readable format
sudo repquota --human-readable {{filesystem}}

# Report on all quotas for users and groups in a human-readable format
sudo repquota -augs

# Reinitialise the current terminal
reset

# Display the terminal type instead
reset -q

# List devices
rfkill

# Filter by columns
rfkill -o {{ID,TYPE,DEVICE}}

# Block devices by type (e.g. bluetooth, wlan)
rfkill block {{bluetooth}}

# Unblock devices by type (e.g. bluetooth, wlan)
rfkill unblock {{wlan}}

# Output in JSON format
rfkill -J

# Show the list of apps
rofi -show drun

# Show the list of all commands
rofi -show run

# Switch between windows
rofi -show window

# Show full table of all RPC services registered on localhost
rpcinfo

# Show concise table of all RPC services registered on localhost
rpcinfo -s {{localhost}}

# Display table of statistics of rpcbind operations on localhost
rpcinfo -m

# Display list of entries of given service name (mountd) and version number (2) on a remote nfs share
rpcinfo -l {{remote_nfs_server_ip}} {{mountd}} {{2}}

# Delete the registration for version 1 of the mountd service for all transports
rpcinfo -d {{mountd}} {{1}}

# Show version of httpd package
rpm -q {{httpd}}

# List versions of all matching packages
rpm -qa '{{mariadb*}}'

# Identify owner of a file and show version of the package
rpm -qf {{/etc/postfix/main.cf}}

# List package-owned files
rpm -ql {{kernel}}

# Show scriptlets from an RPM file
rpm -qp --scripts {{some.rpm}}

# Show changed, missing and/or incorrectly installed files of matching packages
rpm -Va '{{php-*}}'

# Train the bayesian filter to recognise an email as spam
rspamc learn_spam {{path/to/email_file}}

# Train the bayesian filter to recognise an email as ham
rspamc learn_ham {{path/to/email_file}}

# Generate a manual report on an email
rspamc symbols {{path/to/email_file}}

# Show server statistics
rspamc stat

# Show whether an alarm is set or not
sudo rtcwake -m show -v

# Suspend to ram and wakeup after 10 seconds
sudo rtcwake -m mem -s {{10}}

# Suspend to disk (higher power saving) and wakeup 15 minutes later
sudo rtcwake -m disk --date +{{15}}min

# Freeze the system (more efficient than suspend-to-ram but linux > 3.9 required) and wakeup at a given date and time
sudo rtcwake -m freeze --date {{YYYYMMDDhhmm}}

# Disable a previously set alarm
sudo rtc -m disable

# Perform a dry run to wakup the computer at a given time. (Press Ctrl + C to abort)
sudo rtcwake -m on --date {{hh:ss}}

# Add a torrent file or magnet to be downloaded
rtorrent {{torrent_or_magnet}}

# Start the download
<Ctrl>S

# View details about downloading torrent
->

# Close rtorrent safely
<Ctrl>Q

# Individual actions/programs on run-mailcap can be invoked with action flag
run-mailcap --action=ACTION [--option[=value]]

# In simple language
run-mailcap --action=ACTION {{filename}}

# Turn on extra information
run-mailcap  --action=ACTION --debug {{filename}}

# Ignore any "copiousoutput" directive and forward output to STD‐OUT
run-mailcap --action=ACTION --nopager {{filename}}

# Display the found command without actually executing it
run-mailcap --action=ACTION --norun {{filename}}

# Start runit's 3-stage init scheme
runit

# Shut down runit
kill --CONT {{runit_pid}}

# Start a runit service as the current user
runsv {{path/to/service}}

# Start a runit service as root
sudo runsv {{path/to/service}}

# Switch `runsvdir` directories
sudo runsvchdir {{/path/to/directory}}

# Start and manage all services in a directory as the current user
runsvdir {{path/to/services}}

# Start and manage all services in a directory as root
sudo runsvdir {{path/to/services}}

# Start services in separate sessions
runsvdir -P {{path/to/services}}

# Report I/O and transfer rate issued to physical devices, one per second (press CTRL+C to quit)
sar -b {{1}}

# Report a total of 10 network device statistics, one per 2 seconds
sar -n DEV {{2}} {{10}}

# Report CPU utilization, one per 2 seconds
sar -u ALL {{2}}

# Report a total of 20 memory utilization statistics, one per second
sar -r ALL {{1}} {{20}}

# Report the run queue length and load averages, one per second
sar -q {{1}}

# Report paging statistics, one per 5 seconds
sar -B {{5}}

# See action can be used to view any file (usually image) on default mailcap explorer
see {{filename}}

# Using with `run-mailcap`
run-mailcap --action=view {{filename}}

# Open a new window of the default browser
sensible-browser

# Open a url in the default browser
sensible-browser {{url}}

# Start/Stop/Restart/Reload service (start/stop should always be available)
service {{init_script}} {{start|stop|restart|reload}}

# Do a full restart (runs script twice with start and stop)
service {{init_script}} --full-restart

# Show the current status of a service
service {{init_script}} status

# List the status of all services
service --status-all

# Modify ACL of a file for user with read and write access
setfacl -m u:{{username}}:rw {{file}}

# Modify default ACL of a file for all users
setfacl -d -m u::rw {{file}}

# Remove ACL of a file for an user
setfacl -x u:{{username}} {{file}}

# Remove all ACL entries of a file
setfacl -b {{file}}

# Calculate the SHA1 checksum for a file
shasum {{filename}}

# Calculate the SHA256 checksum for a file
shasum --algorithm 256 {{filename}}

# Calculate the SHA512 checksum for multiple files
shasum --algorithm 512 {{filename1}} {{filename2}}

# Check a file with a list of sums against the directory's files
shasum --check {{list_file}}

# Calculate the SHA1 checksum from stdin
{{somecommand}} | shasum

# Power off (halt) immediately
shutdown -h now

# Reboot immediately
shutdown -r now

# Reboot in 5 minutes
shutdown -r +{{5}} &

# Shutdown at 1:00 pm (Uses 24h clock)
shutdown -h 13:00

# Cancel a pending shutdown/reboot operation
shutdown -c

# Update the list of available packages and versions
slapt-get --update

# Install a package, or update it to the latest available version
slapt-get --install {{package_name}}

# Remove a package
slapt-get --remove {{package_name}}

# Upgrade all installed packages to their latest available versions
slapt-get --upgrade {{package_name}}

# Locate packages of interest by the package name, disk set, or version
slapt-get --search {{package_name}}

# Show information about a package
slapt-get --show {{package_name}}

# Connect to a share (user will be prompted for password; `exit` to quit the session)
smbclient {{//server/share}}

# Connect with a different username
smbclient {{//server/share}} --user {{username}}

# Connect with a username and password
smbclient {{//server/share}} --user {{username%password}}

# Download a file from the server
smbclient {{//server/share}} --directory {{path/to/folder}} --command "get {{file.txt}}"

# Upload a file to the server
smbclient {{//server/share}} --directory {{path/to/folder}} --command "put {{file.txt}}"

# Search for a package
snap find {{package_name}}

# Install a package
snap install {{package_name}}

# Update all packages
snap refresh

# Display basic information about installed snap software
snap list

# Uninstall a package
snap remove {{package_name}}

# Check for recent snap changes in the system
snap changes

# List snapshot configs
snapper list-configs

# Create snapper config
snapper -c {{config}} create-config {{path/to/directory}}

# List snapshots for a config
snapper -c {{config}} list

# Create a new snapshot
snapper -c {{config}} snapshot

# Delete a snapshot
snapper -c {{config}} delete {{snapshot_number}}

# Delete a range of snapshots
snapper -c {{config}} delete {{snapshot_X}}-{{snapshot_Y}}

# Show all TCP/UDP/RAW/UNIX sockets
ss -a {{-t|-u|-w|-x}}

# Filter TCP sockets by states, only/exclude
ss {{state/exclude}} {{bucket/big/connected/synchronized/...}}

# Show all TCP sockets connected to the local HTTPS port (443)
ss -t src :{{443}}

# Show all TCP sockets along with processes connected to a remote ssh port
ss -pt dst :{{ssh}}

# Show all UDP sockets connected on specific source and destination ports
ss -u 'sport == :{{source_port}} and dport == :{{destination_port}}'

# Show all TCP IPv4 sockets locally connected on the subnet 192.168.0.0/16
ss -4t src {{192.168/16}}

# Add the default ssh keys in "~/.ssh" to the ssh-agent
ssh-add

# Add a specific key to the ssh-agent
ssh-add {{path/to/private_key}}

# List fingerprints of currently loaded keys
ssh-add -l

# Delete a key from the ssh-agent
ssh-add -d {{path/to/private_key}}

# Delete all currently loaded keys from the ssh-agent
ssh-add -D

# Forward all IPv4 TCP traffic via a remote SSH server
sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}

# Forward all IPv4 TCP and DNS traffic
sshuttle --dns --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}

# Use the tproxy method to forward all IPv4 and IPv6 traffic
sudo sshuttle --method=tproxy --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} {{::/0}} --exclude={{your_local_ip_address}} --exclude={{ssh_server_ip_address}}

# Start tracing a specific process by its PID
strace -p {{pid}}

# Trace a process and filter output by system call
strace -p {{pid}} -e {{system_call_name}}

# Count time, calls, and errors for each system call and report a summary on program exit
strace -p {{pid}} -c

# Show the time spent in every system call
strace -p {{pid}} -T

# Start tracing a program by executing it
strace {{program}}

# Start tracing file operations of a program
strace -e trace=file {{program}}

# Start a service
sudo sv up {{path/to/service}}

# Stop a service
sudo sv down {{path/to/service}}

# Get service status
sudo sv status {{path/to/service}}

# Disable a given swap partition
swapoff {{/dev/sdb7}}

# Disable a given swap file
swapoff {{path/to/file}}

# Disable all swap areas
swapoff -a

# Disable swap by label of a device or file
swapoff -L {{swap1}}

# Get swap information
swapon -s

# Enable a given swap partition
swapon {{/dev/sdb7}}

# Enable a given swap file
swapon {{path/to/file}}

# Enable all swap areas
swapon -a

# Enable swap by label of a device or file
swapon -L {{swap1}}

# Show all available variables and their values
sysctl -a

# Set a changeable kernel state variable
sysctl -w {{section.tunable}}={{value}}

# Get currently open file handlers
sysctl fs.file-nr

# Get limit for simultaneous open files
sysctl fs.file-max

# Apply changes from /etc/sysctl.conf
sysctl -p

# List failed units
systemctl --failed

# Start/Stop/Restart/Reload a service
systemctl start/stop/restart/reload {{unit}}

# Show the status of a unit
systemctl status {{unit}}

# Enable/Disable a unit to be started on bootup
systemctl enable/disable {{unit}}

# Mask/Unmask a unit, prevent it to be started on bootup
systemctl mask/unmask {{unit}}

# Reload systemd, scanning for new or changed units
systemctl daemon-reload

# List time of each unit to start up
systemd-analyze blame

# Print a tree of the time critical chain of units
systemd-analyze critical-chain

# Show all data on the given interface and port
tcpflow -c -i {{eth0}} port {{80}}

# Start terminator window
terminator

# Start with a fullscreen window
terminator -f

# Split terminals horizontally
Ctrl + Shift + O

# Split terminals vertically
Ctrl + Shift + E

# Open new tab
Ctrl + Shift + T

# To check the current system clock time
timedatectl

# To set the local time of the system clock directly
timedatectl set-time {{"yyyy-MM-dd hh:mm:ss"}}

# To list available timezones
timedatectl list-timezones

# To change timezones
timedatectl set-timezone {{timezone}}

# To enable Network Time Protocol (NTP) syncing
timedatectl set-ntp on

# Create a new tomb with an initial size of 100MB
tomb dig -s {{100}} {{encrypted_folder.tomb}}

# Create a new key file that can be used to lock a tomb; user will be prompted for a password for the key
tomb forge {{encrypted_folder.tomb.key}}

# Initialize and lock an empty tomb using a key made with `forge`
tomb lock {{encrypted_folder.tomb}} -k {{encrypted_folder.tomb.key}}

# Mount a tomb (by default in /media) using its key, making it usable as a regular filesystem folder
tomb open {{encrypted_folder.tomb}} -k {{encrypted_folder.tomb.key}}

# Close a tomb (fails if the tomb is being used by a process)
tomb close {{encrypted_folder.tomb}}

# Forcefully close all open tombs, killing any applications using them
tomb slam all

# List all open tombs
tomb list

# Start top
top

# Do not show any idle or zombie processes
top -i

# Show only processes owned by given user
top -u {{user_name}}

# Show only the processes with the given PID(s), passed as a comma-separated list. (Normally you wouldn't know PIDs off hand. This example picks the PIDs from the process name)
top -p $(pgrep -d ',' {{process_name}})

# Get help about interactive commands
?

# List available signals to set traps for
trap -l

# List active traps for the current shell
trap -p

# Set a trap to execute commands when one or more signals are detected
trap 'echo "Caught signal {{SIGHUP}}"' {{SIGHUP}}

# Remove active traps
trap - {{SIGHUP}} {{SIGINT}}

# Show files and directories up to 'num' levels of depth (where 1 means the current directory)
tree -L {{num}}

# Show directories only
tree -d

# Show hidden files too
tree -a

# Print the tree without indentation lines, showing the full path instead (use `-N` to not escape whitespace and special characters)
tree -i -f

# Print the size of each node next to it, in human-readable format
tree -s -h

# Filter the tree using a wildcard (glob) pattern
tree -P {{*.txt}}

# Ignore entries that match a wildcard (glob) pattern
tree -I {{*.txt}}

# Synchronize and update all AUR packages
trizen -Syua

# Install a new package
trizen -S {{package}}

# Remove a package and its dependencies
trizen -Rs {{package}}

# Search the package database for a keyword
trizen -Ss {{keyword}}

# Show information about a package
trizen -Si {{package}}

# List installed packages and versions
trizen -Qe

# Enable ufw
ufw enable

# Disable ufw
ufw disable

# Show ufw rules, along with their numbers
ufw status numbered

# Allow incoming traffic on port 5432 on this host with a comment identifying the service
ufw allow {{5432}} comment {{"Service"}}

# Allow only TCP traffic from 192.168.0.4 to any address on this host, on port 22
ufw allow proto {{tcp}} from {{192.168.0.4}} to {{any}} port {{22}}

# Deny traffic on port 80 on this host
ufw deny {{80}}

# Deny all UDP traffic to port 22
ufw deny proto {{udp}} from {{any}} to {{any}} port {{22}}

# Delete a particular rule. The rule number can be retrieved from the `ufw status numbered` command
ufw delete {{rule_number}}

# Get the properties of all the user limits
ulimit -a

# Get hard limit for the number of simultaneously opened files
ulimit -H -n

# Get soft limit for the number of simultaneously opened files
ulimit -S -n

# Set max per-user process limit
ulimit -u 30

# Display the current mask in octal notation
umask

# Display the current mask in symbolic (human-readable) mode
umask -S

# Change the mask symbolically to allow read permission for all users (the rest of the mask bits are unchanged)
umask {{a+r}}

# Set the mask (using octal) to restrict no permissions for the file's owner, and restrict all permissions for everyone else
umask {{077}}

# Run in interactive mode
units

# Show the conversion between two simple units
units {{quarts}} {{tablespoons}}

# Convert between units with quantities
units {{15 pounds}} {{kilograms}}

# Show the conversion between two compound units
units {{"meters / second"}} {{"inches / hour"}}

# Show the conversion between units with different dimensions
units {{"acres"}} {{"ft^2"}}

# Add a symbolic link
sudo update-alternatives --install {{path/to/symlink}} {{command_name}} {{path/to/command_binary}} {{priority}}

# Configure a symbolic link for "java"
sudo update-alternatives --config {{java}}

# Remove a symbolic link
sudo update-alternatives --remove {{java}} {{/opt/java/jdk1.8.0_102/bin/java}}

# Display information about a specified command
update-alternatives --display {{java}}

# Display all commands and their current selection
update-alternatives --get-selections

# Install a service
update-rc.d {{mysql}} defaults

# Enable a service
update-rc.d {{mysql}} enable

# Disable a service
update-rc.d {{mysql}} disable

# Forcibly remove a service
update-rc.d -f {{mysql}} remove

# Refresh database content
sudo updatedb

# Display file names as soon as they are found
sudo updatedb --verbose

# Create new user
useradd {{name}}

# Create new user with a default home directory
useradd --create-home {{name}}

# Create new user with specified shell
useradd --shell {{/path/to/shell}} {{name}}

# Create new user belonging to additional groups (mind the lack of whitespace)
useradd --groups {{group1,group2}} {{name}}

# Create new system user without a home directory
useradd --no-create-home --system {{name}}

# Remove a user and their home directory
userdel -r {{name}}

# Change a user's name
usermod -l {{newname}} {{user}}

# Add user to supplementary groups (mind the whitespace)
usermod -a -G {{group1,group2}} {{user}}

# Create a new home directory for a user and move their files to it
usermod -m -d {{/path/to/home}} {{user}}

# Create a new volume group called vg1 using the `/dev/sda1` device
vgcreate {{vg1}} {{/dev/sda1}}

# Create a new volume group called vg1 using multiple devices
vgcreate {{vg1}} {{/dev/sda1}} {{/dev/sdb1}} {{/dev/sdc1}}

# View an image
viewnior {{path/to/image.ext}}

# View in fullscreen mode
viewnior --fullscreen {{path/to/image.ext}}

# View fullscreen in slideshow mode
viewnior --slideshow {{path/to/image.ext}}

# Launch a VNC Server on next available display
vncserver

# Launch a VNC Server with specific screen geometry
vncserver --geometry {{width}}x{{height}}

# Kill an instance of VNC Server running on a specific display
vncserver --kill :{{display_number}}

# Launch a VNC client which connects to a host on a given display
vncviewer {{host}}:{{display_number}}

# Launch in full-screen mode
vncviewer -FullScreen {{host}}:{{display_number}}

# Launch a VNC client with a specific screen geometry
vncviewer --geometry {{width}}x{{height}} {{host}}:{{display_number}}

# Launch a VNC client which connects to a host on a given port
vncviewer {{host}}::{{port}}

# Send a message
echo "{{message}}" | wall

# Send a message from a file
wall {{file}}

# Send a message with timeout (default 300)
wall -t {{seconds}} {{file}}

# Monitor files in the current folder
watch {{ls}}

# Monitor disk space and highlight the changes
watch -d {{df}}

# Monitor "node" processes, refreshing every 3 seconds
watch -n {{3}} "{{ps aux | grep node}}"

# Display a description from a man page
whatis {{command}}

# Don't cut the description off at the end of the line
whatis --long {{command}}

# Display descriptions for all commands matching a glob
whatis --wildcard {{net*}}

# Search man page descriptions with a regular expression
whatis --regex '{{wish[0-9]\.[0-9]}}'

# Locate binary, source and man pages for ssh
whereis {{ssh}}

# Locate binary and man pages for ls
whereis -bm {{ls}}

# Locate source of gcc and man pages for git
whereis -s {{gcc}} -m {{git}}

# Locate binaries for gcc in /usr/bin/ only
whereis -b -B {{/usr/bin/}} -f {{gcc}}

# Display optical drives available to `wodim`
wodim --devices

# Record ("burn") an audio-only disc
wodim dev=/dev/{{optical_drive}} -audio {{track*.cdaudio}}

# Burn a file to a disc, ejecting the disc once done (some recorders require this)
wodim -eject dev=/dev/{{optical_drive}} -data {{file.iso}}

# Burn a file to the disc in an optical drive, potentially writing to multiple discs in succession
wodim -tao dev=/dev/{{optical_drive}} -data {{file.iso}}

# Scan for available networks
wpa_cli scan

# Show scan results
wpa_cli scan_results

# Add a network
wpa_cli add_network {{number}}

# Set a network's SSID
wpa_cli set_network {{number}} ssid "{{SSID}}"

# Enable network
wpa_cli enable_network {{number}}

# Save config
wpa_cli save_config

# Send a message to a given user on a given terminal id
write {{username}} {{terminal_id}}

# Send message to "testuser" on terminal "/dev/tty/5"
write {{testuser}} {{tty/5}}

# Send message to "jhondoe" on pseudo terminal "/dev/pts/5"
write {{jhondoe}} {{pts/5}}

# Launch a VNC server that allows multiple clients to connect
x11vnc -shared

# Launch a VNC server in view-only mode, and which won't terminate once the last client disconnects
x11vnc -forever -viewonly

# Launch a VNC server on a specific display and screen (both starting at index zero)
x11vnc -display :{{display}}.{{screen}}

# Launch a VNC server on the third display's default screen
x11vnc -display :{{2}}

# Launch a VNC server on the first display's second screen
x11vnc -display :{{0}}.{{1}}

# Create a xar archive of all files in a given directory
xar -cf {{archive.xar}} {{path/to/directory}}

# List the contents of a given xar archive
xar -tf {{archive.xar}}

# Extract the contents of a given xar archive to the current directory
xar -xf {{archive.xar}}

# Install packages and synchronize them with the remote repository
xbps-install --synchronize {{package_name1}} {{package_name2}}

# Search for a package in the remote repository
xbps-query --repository -s {{package_name}}

# Remove a package, leaving all of its dependencies installed
xbps-remove {{package_name}}

# Remove a package and all of its dependencies recursively that are not required by other packages
xbps-remove --recursive {{package_name}}

# Synchronize your repository databases and update your system and dependencies
xbps-install --synchronize -u

# Copy the output from a command to the X11 primary selection area (clipboard)
echo 123 | xclip

# Copy the output from a command to a given X11 selection area
echo 123 | xclip -selection {{primary|secondary|clipboard}}

# Copy the contents of a file to the system clipboard, using short notation
echo 123 | xclip -sel clip

# Copy the contents of a file into the system clipboard
xclip -sel clip {{input_file.txt}}

# Paste the contents of the X11 primary selection area to the console
xclip -o

# Paste the contents of the system clipboard to the console
xclip -o -sel clip

# Paste the contents of the system clipboard into a file
xclip -o -sel clip > {{output_file.txt}}

# Retrieve the X-Windows window ID of the running Firefox window(s)
xdotool search --onlyvisible --name {{firefox}}

# Click the right mouse button
xdotool click {{3}}

# Get the id of the currently active window
xdotool getactivewindow

# Focus on the window with id of 12345
xdotool windowfocus --sync {{12345}}

# Type a message, with a 500ms delay for each letter
xdotool type --delay {{500}} "Hello world"

# Press the enter key
xdotool key {{KP_Enter}}

# Launch xeyes on the local machine's default display
xeyes

# Launch xeyes on a remote machine's display 0, screen 0
xeyes -display {{remote_host}}:{{0}}.{{0}}

# List all input devices
xinput list

# Disconnect an input from its master
xinput float {{id}}

# Reattach an input as slave to a master
xinput reattach {{id}} {{master_id}}

# Start xman in three-button window
xman

# Open the manual page output stored in a given file
xman -helpfile {{filename}}

# Show both manual page and directory
xman -bothshown

# Display the current state of the system (known screens, resolutions, ...)
xrandr --query

# Disable disconnected outputs and enable connected ones with default settings
xrandr --auto

# Change the resolution and update frequency of DisplayPort 1 to 1920x1080, 60Hz
xrandr --output {{DP1}} --mode {{1920x1080}} --rate {{60}}

# Set the resolution of HDMI2 to 1280x1024 and put it on the right of DP1
xrandr --output {{HDMI2}} --mode {{1280x1024}} --right-of {{DP1}}

# Disable the VGA1 output
xrandr --output {{VGA1}} --off

# Use a command's output as input of the clip[b]oard (equivalent to `Ctrl + C`)
echo 123 | xsel -ib

# Use the contents of a file as input of the clipboard
cat {{file}} | xsel -ib

# Output the clipboard's contents into the terminal (equivalent to `Ctrl + V`)
xsel -ob

# Output the clipboard's contents into a file
xsel -ob > {{file}}

# Clear the clipboard
xsel -cb

# Output the X11 primary selection's contents into the terminal (equivalent to a mouse middle-click)
xsel -op

# List all the available wacom devices. The device name is in the first column
xsetwacom list

# Set Wacom area to specific screen. Get name of the screen with `xrandr`
xsetwacom set "{{device_name}}" MapToOutput {{screen}}

# Set mode to relative (like a mouse) or absolute (like a pen) mode
xsetwacom set "{{device_name}}" Mode "{{Relative|Absolute}}"

# Rotate the input (useful for tablet-PC when rotating screen) by 0|90|180|270 degrees from "natural" rotation
xsetwacom set "{{device_name}}" Rotate {{none|half|cw|ccw}}

# Set button to only work when the tip of the pen is touching the tablet
xsetwacom set "{{device_name}}" TabletPCButton "on"

# Lock the display and show a padlock instead of the cursor
xtrlock

# Display a blank screen as well as the padlock cursor
xtrlock -b

# Fork the xtrlock process and return immediately
xtrlock -f

# Yank using the default delimiters (\f, \n, \r, \s, \t)
{{sudo dmesg}} | yank

# Yank an entire line
{{sudo dmesg}} | yank -l

# Yank using a specific delimiter
{{echo hello=world}} | yank -d {{=}}

# Only yank fields matching a specific pattern
{{ps ux}} | yank -g {{"[0-9]+"}}

# Synchronize and update all packages (including AUR)
yaourt -Syua

# Install a new package (includes AUR)
yaourt -S package-name

# Remove a package and its dependencies (includes AUR packages)
yaourt -Rs package-name

# Search the package database for a keyword (including AUR)
yaourt -Ss package-name

# List installed packages, versions, and repositories (AUR packages will be listed under the repository name 'local')
yaourt -Q

# Interactively search and install packages from the repos and AUR
yay {{package_name|search_term}}

# Synchronize and update all packages from the repos and AUR
yay

# Synchronize and update only AUR packages
yay -Sua

# Install a new package from the repos and AUR
yay -S {{package_name}}

# Search the package database for a keyword from the repos and AUR
yay -Ss {{keyword}}

# Show statistics for installed packages and system health
yay -Ps

# Synchronize list of packages and versions available. This should be run first, before running subsequent yum commands
yum update

# Install a new package
yum install {{package}}

# Install a new package and assume yes to all questions (also works with update, great for automated updates)
yum -y install {{package}}

# Find the package that provides a particular command
yum provides {{command}}

# Remove a package
yum remove {{package}}

# Upgrade installed packages to newest available versions
yum upgrade

# Display the default question dialog
zenity --question

# Display an info dialog displaying the text "Hello!"
zenity --info --text="{{Hello!}}"

# Display a name/password form and output the data separated by ";"
zenity --forms --add-entry="{{Name}}" --add-password="{{Password}}" --separator="{{;}}"

# Display a file selection form in which the user can only select directories
zenity --file-selection --directory

# Display a progress bar which updates its message every second and show a progress percent
{{(echo "#1"; sleep 1; echo "50"; echo "#2"; sleep 1; echo "100")}} | zenity --progress

# Check if zram is enabled
lsmod | grep -i zram

# Enable zram with 2 devices (use `zramctl` to configure the devices further)
sudo modprobe zram num_devices={{2}}

# Find and initialise the next free zram device to a 2GB virtual drive using LZ4 compression
sudo zramctl --find --size {{2GB}} --algorithm {{lz4}}

# List currently initialised devices
zramctl

# Synchronize list of packages and versions available
zypper refresh

# Install a new package
zypper install {{package}}

# Remove a package
zypper remove {{package}}

# Upgrade installed packages to newest available versions
zypper update

# Search package via keyword
zypper search {{keyword}}

# Show current wireless status information
airport -I

# Sniff wireless traffic on channel 1
airport sniff {{1}}

# Scan for available wireless networks
airport -s

# Disassociate from current airport network
sudo airport -z

# Start the org.apache.httpd launchd job
apachectl start

# Stop the launchd job
apachectl stop

# Stop, then start launchd job
apachectl restart

# Show system information
archey

# Show system information without colored output
archey --nocolor

# Show system information, using MacPorts instead of Homebrew
archey --macports

# Show system information without IP address check
archey --offline

# Assemble a file, writing the output to a.out
as {{file.s}}

# Assemble the output to a given file
as {{file.s}} -o {{out.o}}

# Generate output faster by skipping whitespace and comment preprocessing. (Should only be used for trusted compilers)
as -f {{file.s}}

# Include a given path to the list of directories to search for files specified in .include directives
as -I {{path/to/directory}} {{file.s}}

# Restore a disk image to a target volume
sudo asr restore --source {{image_name}}.dmg --target {{path/to/volume}}

# Erase the target volume before restoring
sudo asr restore --source {{image_name}}.dmg --target {{path/to/volume}} --erase

# Skip verification after restoring
sudo asr restore --source {{image_name}}.dmg --target {{path/to/volume}} --noverify

# Clone volumes without the use of an intermediate disk image
sudo asr restore --source {{path/to/volume}} --target {{path/to/cloned_volume}}

# Encode a file
base64 -i {{plain_file}}

# Decode a file
base64 -D -i {{base64_file}}

# Encode from stdin
echo -n {{plain_text}} | base64

# Decode from stdin
echo -n {{base64_text}} | base64 -D

# Search for formulas and casks
brew search {{text}}

# Install a cask
brew cask install {{cask_name}}

# List all installed casks
brew cask list

# List installed casks that have newer versions available
brew cask outdated

# Upgrade an installed cask to its latest version
brew cask upgrade {{cask_name}}

# Uninstall a cask
brew cask uninstall {{cask_name}}

# Uninstall a cask and remove related settings and files
brew cask zap {{cask_name}}

# Display information about a given cask
brew cask info {{cask_name}}

# Search the Mac App Store by app name and return matching identifiers
mas search {{app_name}}

# Install or update a previously purchased application
mas install {{app_name}} {{app_identifier}}

# Show all installed applications and their product identifiers
mas list

# List installed apps with pending updates
mas outdated

# Install all pending updates
mas upgrade

# Install updates for a specific app
mas upgrade {{app_identifier}}

# Search for available formulas and casks
brew search {{text}}

# Install the latest stable version of a formula (use `--devel` for development versions)
brew install {{formula}}

# List all installed formulae
brew list

# Update an installed formula (if no formula name is given, all installed formulae are updated)
brew upgrade {{formula}}

# Fetch the newest version of Homebrew and all formulae from GitHub
brew update

# Show formulae that have a more recent version available
brew outdated

# Display information about a formula (version, installation path, dependencies, etc.)
brew info {{formula}}

# Check your Homebrew installation for potential problems
brew doctor

# Prevent from sleeping for 1 hour (3600 seconds)
caffeinate -u -t {{3600}}

# Prevent from sleeping until a command completes
caffeinate -s {{command}}

# Prevent from sleeping until you type Ctrl-C
caffeinate -i

# Display a calendar for the current month
cal

# Display a calendar for a specific month (1-12 or name)
cal -m {{month}}

# Display a calendar for the current year
cal -y

# Display a calendar for a specific year (4 digits)
cal {{year}}

# Display a calendar for a specific month and year
cal {{month}} {{year}}

# Display date of Easter (Western Christian churches) in a given year
ncal -e {{year}}

# Download the latest version of all dependencies mentioned in Cartfile, and build them
carthage update

# Update dependencies, but only build for iOS
carthage update --platform ios

# Update dependencies, but don't build any of them
carthage update --no-build

# Download and rebuild the current version of dependencies (without updating them)
carthage bootstrap

# Rebuild a specific dependency
carthage build {{dependency}}

# Sign an application with a certificate
codesign -s {{"My Company Name"}} {{/path/to/App.app}}

# Verify the certificate of an application
codesign -v {{/path/to/App.app}}

# Execute the ls program literally, even if an ls alias exists
command {{ls}}

# List all commands that you could run
compgen -c

# List all aliases
compgen -a

# List all functions that you could run
compgen -A function

# Show shell reserved key words
compgen -k

# See all available commands/aliases starting with 'ls'
compgen -ac {{ls}}

# Display the current date using the default locale's format
date +"%c"

# Display the current date in UTC and ISO 8601 format
date -u +"%Y-%m-%dT%H:%M:%SZ"

# Display the current date as a Unix timestamp (seconds since the Unix epoch)
date +%s

# Display a specific date (represented as a Unix timestamp) using the default format
date -r 1473305798

# Make a bootable usb drive from an isohybrid file (such like archlinux-xxx.iso)
dd if={{file.iso}} of=/dev/{{usb_drive}}

# Clone a drive to another drive with 4MB block and ignore error
dd if=/dev/{{source_drive}} of=/dev/{{dest_drive}} bs=4m conv=noerror

# Generate a file of 100 random bytes by using kernel random driver
dd if=/dev/urandom of={{random_file}} bs=100 count=1

# Benchmark the write performance of a disk
dd if=/dev/zero of={{file_1GB}} bs=1024 count=1000000

# Read system defaults for an application option
defaults read {{application}} {{option}}

# Read default values for an application option
defaults read -app {{application}} {{option}}

# Write the default value of an application option
defaults write {{application}} {{option}} {{-type}} {{value}}

# Speed up Mission Control animations
defaults write com.apple.Dock expose-animation-duration -float 0.1

# Delete all defaults of an application
defaults delete {{application}}

# List all currently available disks, partitions and mounted volumes
diskutil list

# Repair the file system data structures of a volume
diskutil repairVolume {{/dev/diskX}}

# Unmount a volume
diskutil unmountDisk {{/dev/diskX}}

# Eject a CD/DVD (unmount first)
diskutil eject {{/dev/disk1}}

# Overwrite contents of destination folder with contents of source folder
ditto {{path/to/source}} {{path/to/destination}}

# Print a line to the Terminal window for every file that’s being copied
ditto -V {{path/to/source}} {{path/to/destination}}

# Copy a given file or folder, while retaining the original file permissions
ditto -rsrc {{path/to/source}} {{path/to/destination}}

# Show kernel messages
dmesg

# Show how much physical memory is available on this system
dmesg | grep -i memory

# Show kernel messages 1 page at a time
dmesg | less

# Eject a disk from the drive
drutil eject

# Burn a folder as an ISO9660 filesystem onto a DVD. Don't verify and eject when complete
drutil burn -noverify -eject -iso9660

# List the sizes of a folder and any subfolders, in the given unit (KB/MB/GB)
du -{{k|m|g}} {{path/to/folder}}

# List the sizes of a folder and any subfolders, in human-readable form (i.e. auto-selecting the appropriate unit for each size)
du -h {{path/to/folder}}

# Show the size of a single folder, in human readable units
du -sh {{path/to/folder}}

# List the human-readable sizes of a folder and of all the files and folders within it
du -ah {{path/to/folder}}

# List the human-readable sizes of a folder and any subfolders, up to N levels deep
du -h -d {{N}} {{path/to/folder}}

# List the human-readable size of all .jpg files in subfolders of the current folder, and show a cumulative total at the end
du -ch */*.jpg

# Set Safari as the default handler for HTML documents
duti -s {{com.apple.Safari}} {{public.html}} all

# Set VLC as the default viewer for files with .m4v extensions
duti -s {{org.videolan.vlc}} {{m4v}} viewer

# Set Finder as the default handler for the ftp:// URL scheme
duti -s {{com.apple.Finder}} {{ftp}}

# Display information about the default application for a given extension
duti -x {{ext}}

# Display the default handler for a given UTI
duti -d {{uti}}

# Display all handlers of a given UTI
duti -l {{uti}}

# Call `echo` with the "foo" argument
eval "{{echo foo}}"

# Set a variable in the current shell
eval "{{foo=bar}}"

# Set a new environment variable
export {{VARIABLE}}={{value}}

# Remove an environment variable
export -n {{VARIABLE}}

# Append something to the PATH variable
export PATH=$PATH:{{path/to/append}}

# View images locally or using a URL
feh {{path/to/images}}

# View images recursively
feh --recursive {{path/to/images}}

# View images without window borders
feh --borderless {{path/to/images}}

# Exit after the last image
feh --cycle-once {{path/to/images}}

# Set the slideshow cycle delay
feh --slideshow-delay {{seconds}} {{path/to/images}}

# Set your wallpaper (centered, filled, maximized, scaled or tiled)
feh --bg-{{center|fill|max|scale|tile}} {{path/to/image}}

# Give a description of the type of the specified file. Works fine for files with no file extension
file {{filename}}

# Look inside a zipped file and determine the file type(s) inside
file -z {{foo.zip}}

# Allow file to work with special or device files
file -s {{filename}}

# Don't stop at first file type match; keep going until the end of the file
file -k {{filename}}

# Determine the mime encoding type of a file
file -I {{filename}}

# Check filesystem /dev/sda, reporting any damaged blocks
fsck {{/dev/sda}}

# Check filesystem /dev/sda only if it is clean, reporting any damaged blocks and interactively letting the user choose to repair each one
fsck -f {{/dev/sda}}

# Check filesystem /dev/sda only if it is clean, reporting any damaged blocks and automatically repairing them
fsck -fy {{/dev/sda}}

# Check filesystem /dev/sda, reporting whether it has been cleanly unmounted
fsck -q {{/dev/sda}}

# Run Python web app
gunicorn {{import.path:app_object}}

# Listen on port 8080 on localhost
gunicorn --bind {{localhost}}:{{8080}} {{import.path:app_object}}

# Turn on live reload
gunicorn --reload {{import.path:app_object}}

# Use 4 worker processes for handling requests
gunicorn --workers {{4}} {{import.path:app_object}}

# Use 4 worker threads for handling requests
gunicorn --threads {{4}} {{import.path:app_object}}

# Run app over HTTPS
gunicorn --certfile {{cert.pem}} --keyfile {{key.pem}} {{import.path:app_object}}

# Output the first few lines of a file
head -n {{count_of_lines}} {{filename}}

# Output the first few bytes of a file
head -c {{number_in_bytes}} {{filename}}

# Print the hexadecimal representation of a file
hexdump {{file}}

# Display the input offset in hexadecimal and its ASCII representation in two columns
hexdump -C {{file}}

# Display the hexadecimal representation of a file, but interpret only n bytes of the input
hexdump -C -n{{number_of_bytes}} {{file}}

# Show current host name
hostname

# Set current host name
hostname {{new_hostname}}

# Display an image on the command line
imgcat {{filename}}

# Activate a user-specific agent to be loaded into `launchd` whenever the user logs in
launchctl load ~/Library/LaunchAgents/{{my_script}}.plist

# Activate an agent which requires root privileges to run and/or should be loaded whenever any user logs in (note the absence of `~` in the path)
sudo launchctl load /Library/LaunchAgents/{{root_script}}.plist

# Activate a system-wide daemon to be loaded whenever the system boots up (even if no user logs in)
sudo launchctl load /Library/LaunchDaemons/{{system_daemon}}.plist

# Show all loaded agents/daemons, with the PID if the process they specify is currently running, and the exit code returned the last time they ran
launchctl list

# Unload a currently loaded agent, e.g. to make changes (note: the plist file is automatically loaded into `launchd` after a reboot and/or logging in)
launchctl unload ~/Library/LaunchAgents/{{my_script}}.plist

# Manually run a known (loaded) agent/daemon, even if it isn’t the right time (note: this command uses the agent's label, rather than the filename)
launchctl start {{my_script}}

# Manually kill the process associated with a known agent/daemon, if it's running
launchctl stop {{my_script}}

# Debug an executable
lldb {{executable}}

# Attach `lldb` to a running process with a given PID
lldb -p {{pid}}

# Wait for a new process to launch with a given name, and attach to it
lldb -w -n {{process_name}}

# Look for pattern in the database. Note: the database is recomputed periodically (usually weekly or daily)
locate {{pattern}}

# Look for a file by its exact filename (a pattern containing no globbing characters is interpreted as `*pattern*`)
locate */{{filename}}

# Recompute the database. You need to do it if you want to find recently added files
sudo /usr/libexec/locate.updatedb

# Log a message to syslog
logger {{message}}

# Take input from stdin and log to syslog
echo {{log_entry}} | logger

# Send the output to a remote syslog server running at a given port. Default port is 514
echo {{log_entry}} | logger -h {{hostname}} -P {{port}}

# Use a specific tag for every line logged. Default is the name of logged in user
echo {{log_entry}} | logger -t {{tag}}

# Log messages with a given priority. Default is `user.notice`. See `man logger` for all priority options
echo {{log_entry}} | logger -p {{user.warning}}

# Look for lines which begins with the given prefix
look {{prefix}} {{file}}

# Look for lines ignoring case
look -f {{prefix}} {{file}}

# Get the battery status
m battery status

# Turn off bluetooth
m bluetooth off

# List available filesystems for formatting
m disk filesystems

# Enable Dock's auto hide feature
m dock autohide YES

# Disable the firewall
m firewall disable

# Calculate the MD5 checksum for a file
md5 {{filename}}

# Calculate MD5 checksums for multiple files
md5 {{filename1}} {{filename2}}

# Output only the md5 checksum (no filename)
md5 -q {{filename}}

# Print a checksum of the given string
md5 -s {{string}}

# Find a file by its name
mdfind -name {{file}}

# Find a file by its content
mdfind {{query}}

# Find a file containing a string, in a given directory
mdfind -onlyin {{directory}} {{query}}

# Show the indexing status of the startup volume
mdutil -s {{/}}

# Turn on/off the Spotlight indexing for a given volume
mdutil -i {{on|off}} {{path/to/volume}}

# Erase the metadata stores and restart the indexing process
mdutil -E {{path/to/volume}}

# Create an empty file of 15 kilobytes
mkfile -n {{15k}} {{file_name}}

# Create a file of a given size and unit (bytes, KB, MB, GB)
mkfile -n {{size}}{{b|k|m|g}} {{file_name}}

# Create two files of 4 megabytes each
mkfile -n {{4m}} {{first_file_name}} {{second_file_name}}

# Install a given version of node. If the version is already installed, it will be activated
n {{version}}

# Display installed versions and interactively activate one of them
n

# Remove a version
n rm {{version}}

# Execute a file with a given version
n use {{version}} {{file.js}}

# Output binary path for a version
n bin {{version}}

# List all ports
netstat -a

# List all listening ports
netstat -l

# List listening TCP ports
netstat -t

# Display PID and program names for a specific port
netstat -p {PROTOCOL}

# List information continuously
netstat -c

# List available network service providers (Ethernet, Wi-Fi, Bluetooth, etc)
networksetup -listallnetworkservices

# Show network settings for a particular networking device
networksetup -getinfo {{"Wi-Fi"}}

# Get currently connected Wi-Fi network name (Wi-Fi device usually en0 or en1)
networksetup -getairportnetwork {{en0}}

# Connect to a particular Wi-Fi network
networksetup -setairportnetwork {{en0}} {{"Airport Network SSID"}} {{password}}

# List global (extern) functions in a file (prefixed with T)
nm -g {{file.o}}

# List only undefined symbols in a file
nm -u {{file.o}}

# List all symbols, even debugging symbols
nm -a {{file.o}}

# Demangle C++ symbols
nm {{file.o}} |  c++filt

# Generate TOTP token (behaves like Google Authenticator)
oathtool --totp --base32 {{secret}}

# Generate a TOTP token for a specific time
oathtool --totp --now {{2004−02−29 16:21:42}} --base32 {{secret}}

# Validate a TOTP token
oathtool --totp --base32 {{secret}} {{token}}

# Open a file with the associated application
open {{file.ext}}

# Run a graphical macOS application
open -a {{Application}}

# Run a graphical macOS app based on the bundle identifier (refer to `osascript` for an easy way get this)
open -b {{com.domain.application}}

# Open the current directory in Finder
open .

# Reveal a file in finder
open -R {{path/to/file}}

# Open all the files of a given extension in the current directory with the associated application
open {{*.ext}}

# Print all file opens as they occur
sudo opensnoop

# Track all file opens by a process by name
sudo opensnoop -n {{process_name}}

# Track all file opens by a process by PID
sudo opensnoop -p {{PID}}

# Track which processes open a specified file
sudo opensnoop -f {{path/to/file}}

# Run an AppleScript command
osascript -e '{{say "Hello world"}}'

# Run multiple AppleScript commands
osascript -e '{{say "Hello"}}' -e '{{say "world"}}'

# Run a compiled (`*.scpt`), bundled (`*.scptd`), or plaintext (`*.applescript`) AppleScript file
osascript {{path/to/apple.scpt}}

# Get the bundle identifier of an application (useful for `open -b`)
osascript -e 'id of app "{{Application}}"'

# Run a JavaScript command
osascript -l JavaScript -e '{{console.log("Hello world");}}'

# Run a JavaScript file
osascript -l JavaScript {{path/to/script.js}}

# Place the contents of a file in the clipboard
pbcopy < {{file}}

# Place the results of a command in the clipboard
find . -type t -name "*.png" | pbcopy

# Write the contents of the clipboard to a file
pbpaste > {{file}}

# Use the contents of the clipboard as input to a command
pbpaste | grep foo

# Find lines that match pattern in a PDF
pdfgrep {{pattern}} {{file.pdf}}

# Include file name and page number for each matched line
pdfgrep --with-filename --page-number {{pattern}} {{file.pdf}}

# Do a case insensitive search for lines that begin with "foo" and return the first 3 matches
pdfgrep --max-count {{3}} --ignore-case {{'^foo'}} {{file.pdf}}

# Find pattern in files with a .pdf extension in the current directory recursively
pdfgrep --recursive {{pattern}}

# Find pattern on files that match a specific glob in the current directory recursively
pdfgrep --recursive --include {{'*book.pdf'}} {{pattern}}

# Display the current power management settings
pmset -g

# Display the current power source and battery levels
pmset -g batt

# Set display to never sleep when on charger power
sudo pmset -c displaysleep 0

# Set display to sleep after 15 minutes when on battery power
sudo pmset -b displaysleep 15

# Schedule computer to automatically wake up every weekday at 9 AM
sudo pmset repeat wake MTWRF 09:00:00

# Restore to system defaults
sudo pmset -a displaysleep 10 disksleep 10 sleep 30 womp 1

# Create a Podfile for the current project with the default contents
pod init

# Download and install all pods defined in the Podfile (that haven't been installed before)
pod install

# List all available pods
pod list

# Show the outdated pods (of those currently installed)
pod outdated

# Update all currently installed pods to their newest version
pod update

# Update a specific (previously installed) pod to its newest version
pod update {{pod_name}}

# Remove CocoaPods from a Xcode project
pod deintegrate {{xcode_project}}

# Remove the top directory from the stack and cd to it
popd

# Remove the Nth directory (starting from zero to the left from the list printed with `dirs`)
popd +N

# Remove the Nth directory (starting from zero to the right from the list printed with `dirs`)
popd -N

# Search for a package
port search {{search_term}}

# Install a package
sudo port install {{package_name}}

# List installed packages
port installed

# Update port and fetch latest list of available packages
sudo port selfupdate

# Upgrade outdated packages
sudo port upgrade outdated

# Remove old versions of installed packages
sudo port uninstall inactive

# Switch to directory and push it on the stack
pushd {{directory}}

# Switch first and second directories on the stack
pushd

# Rotate stack by making the 5th element the top of the stack
pushd +4

# Generate random password with s[y]mbols
pwgen -y {{length}}

# Generate secure, hard-to-memorize passwords
pwgen -s {{length}}

# Generate password with at least one capital letter in them
pwgen -c {{length}}

# Display QuickLook for one or multiple files
qlmanage -p {{filename}} {{filename2}}

# Compute 300px wide PNG thumbnails of all JPEGs in the current directory and put them in a directory
qlmanage {{*.jpg}} -t -s {{300}} {{path/to/directory}}

# Reset Quicklook
qlmanage -r

# Add a route to a destination through a gateway
sudo route add {{dest_ip_address}} {{gateway_address}}

# Add a route to a /24 subnet through a gateway
sudo route add {{subnet_ip_address}}/24 {{gateway_address}}

# Run in test mode (does not do anything, just print)
sudo route -t add {{dest_ip_address}}/24 {{gateway_address}}

# Remove all routes
sudo route flush

# Delete a specific route
sudo route delete {{dest_ip_address}}/24

# Lookup and display the route for a destination (hostname or IP address)
sudo route get {{destination}}

# Check all files in the current directory (including subdirectories)
rubocop

# Check one or more specific files or directories
rubocop {{path/to/file}} {{path/to/directory}}

# Write output to file
rubocop --out {{path/to/file}}

# View list of cops (linter rules)
rubocop --show-cops

# Exclude a cop
rubocop --except {{cop_1}} {{cop_2}}

# Run only specified cops
rubocop --only {{cop_1}} {{cop_2}}

# Auto-correct files (experimental)
rubocop --auto-correct

# Start runit's 3-stage init scheme
runit

# Shut down runit
kill --CONT {{runit_pid}}

# Start a runit service as the current user
runsv {{path/to/service}}

# Start a runit service as root
sudo runsv {{path/to/service}}

# Switch `runsvdir` directories
sudo runsvchdir {{/path/to/directory}}

# Start and manage all services in a directory as the current user
runsvdir {{path/to/services}}

# Start and manage all services in a directory as root
sudo runsvdir {{path/to/services}}

# Start services in separate sessions
runsvdir -P {{path/to/services}}

# Say a phrase aloud
say {{"I like to ride my bike."}}

# Read a file aloud
say -f {{filename.txt}}

# Say a phrase with a custom voice and speech rate
say -v {{voice}} -r {{words_per_minute}} {{"I'm sorry Dave, I can't let you do that."}}

# List the available voices
say -v ?

# Create an audio file of the spoken text
say -o {{filename.aiff}} {{"Here's to the Crazy Ones."}}

# Display DNS Configuration
scutil --dns

# Display proxy configuration
scutil --proxy

# Get computer name
scutil --get ComputerName

# Set computer name
sudo scutil --set ComputerName {{computer_name}}

# Get hostname
scutil --get HostName

# Set hostname
scutil --set HostName {{hostname}}

# Replace the first occurrence of a string in a file, and print the result
sed 's/{{find}}/{{replace}}/' {{filename}}

# Replace all occurrences of an extended regular expression in a file
sed -E 's/{{regex}}/{{replace}}/g' {{filename}}

# Replace all occurrences of a string in a file, overwriting the file (i.e. in-place)
sed -i '' 's/{{find}}/{{replace}}/g' {{filename}}

# Replace only on lines matching the line pattern
sed '/{{line_pattern}}/s/{{find}}/{{replace}}/' {{filename}}

# Print only text between n-th line till the next empty line
sed -n '{{line_number}},/^$/p' {{filename}}

# Apply multiple find-replace expressions to a file
sed -e 's/{{find}}/{{replace}}/' -e 's/{{find}}/{{replace}}/' {{filename}}

# Replace separator / by any other character not used in the find or replace patterns, e.g., #
sed 's#{{find}}#{{replace}}#' {{filename}}

# Calculate the SHA1 checksum for a file
shasum {{filename}}

# Calculate the SHA256 checksum for a file
shasum --algorithm 256 {{filename}}

# Calculate the SHA512 checksum for multiple files
shasum --algorithm 512 {{filename1}} {{filename2}}

# Check a file with a list of sums against the directory's files
shasum --check {{list_file}}

# Calculate the SHA1 checksum from stdin
{{somecommand}} | shasum

# Randomize the order of lines in a file and output the result
shuf {{filename}}

# Only output the first 5 entries of the result
shuf -n {{5}} {{filename}}

# Write output to another file
shuf {{filename}} -o {{output_filename}}

# Generate random numbers in range 1-10
shuf -i {{1-10}}

# Power off (halt) immediately
shutdown -h now

# Sleep immediately
shutdown -s now

# Reboot immediately
shutdown -r now

# Reboot in 5 minutes
shutdown -r +{{5}}

# Specify an output directory so that originals do not get modified
sips --out {{path/to/out_dir}}

# Resample image at specified size, Image aspect ratio may be altered
sips -z {{1920}} {{300}} {{image.ext}}

# Resample image so height and width aren't greater than specified size (notice the capital Z)
sips -Z {{1920}} {{300}} {{image.ext}}

# Resample all images in a folder to fit a width of 960px (honoring aspect ratio)
sips --resampleWidth {{960}} {{path/to/images}}

# Convert an image from CMYK to RGB
sips --matchTo '/System/Library/ColorSync/Profiles/Generic RGB Profile.icc' {{path/to/image.ext}} {{path/to/out_dir}}

# Remove ColorSync ICC profile from an image
sips -d profile --deleteColorManagementProperties {{path/to/image.ext}}

# List all available updates
softwareupdate -l

# Download and install all updates
softwareupdate -ia

# Download and install all recommended updates
softwareupdate -ir

# Download and install a specific app
softwareupdate -i {{update_name}}

# Split a file, each split having 10 lines (except the last split)
split -l {{10}} {{filename}}

# Split a file into 5 files. File is split such that each split has same size (except the last split)
split -n {{5}} {{filename}}

# Split a file with 512 bytes in each split (except the last split; use 512k for kilobytes and 512m for megabytes)
split -b {{512}} {{filename}}

# Add the default ssh keys in "~/.ssh" to the ssh-agent
ssh-add

# Add a specific key to the ssh-agent
ssh-add {{path/to/private_key}}

# List fingerprints of currently loaded keys
ssh-add -l

# Delete a key from the ssh-agent
ssh-add -d {{path/to/private_key}}

# Delete all currently loaded keys from the ssh-agent
ssh-add -D

# Add a key to the ssh-agent and the keychain
ssh-add -K {{path/to/private_key}}

# Forward all IPv4 TCP traffic via a remote SSH server
sshuttle --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}

# Forward all IPv4 TCP and DNS traffic
sshuttle --dns --remote={{username}}@{{sshserver}} {{0.0.0.0/0}}

# Use the tproxy method to forward all IPv4 and IPv6 traffic
sudo sshuttle --method=tproxy --remote={{username}}@{{sshserver}} {{0.0.0.0/0}} {{::/0}} --exclude={{your_local_ip_address}} --exclude={{ssh_server_ip_address}}

# Show file properties such as size, permissions, creation and access dates among others
stat {{file}}

# Same as above but verbose (more similar to linux's `stat`)
stat -x {{file}}

# Show only octal file permissions
stat -f %Mp%Lp {{file}}

# Show owner and group of the file
stat -f "%Su %Sg" {{file}}

# Show the size of the file in bytes
stat -f "%z %N" {{file}}

# Display all settings for the current terminal
stty -a

# Set the number of rows
stty rows {{rows}}

# Set the number of columns
stty cols {{cols}}

# Get the actual transfer speed of a device
stty -f {{path/to/device_file}} speed

# Reset all modes to reasonable values for the current terminal
stty sane

# Start a service
sudo sv up {{path/to/service}}

# Stop a service
sudo sv down {{path/to/service}}

# Get service status
sudo sv status {{path/to/service}}

# Print macOS Version
sw_vers -productVersion

# Print macOS Build
sw_vers -buildVersion

# Show all available variables and their values
sysctl -a

# Show Apple model identifier
sysctl -n hw.model

# Show CPU model
sysctl -n machdep.cpu.brand_string

# Show available CPU features (MMX, SSE, SSE2, SSE3, AES, etc)
sysctl -n machdep.cpu.feature

# Set a changeable kernel state variable
sysctl -w {{section.tunable}}={{value}}

# Display a full system profiler report which can be opened by System Profiler.app
system_profiler -xml > MyReport.spx

# Display a hardware overview (Model, CPU, Memory, Serial, etc)
system_profiler SPHardwareDataType

# Print the system serial number
system_profiler SPHardwareDataType|grep "Serial Number (system)" |awk '{print $4}'

# Enable remote login (SSH)
systemsetup -setremotelogin on

# Specify TimeZone, NTP Server and enable network time
systemsetup -settimezone {{US/Pacific}} -setnetworktimeserver {{us.pool.ntp.org}} -setusingnetworktime on

# Make the machine never sleep and automatically restart on power failure or kernel panic
systemsetup -setsleep off -setrestartpowerfailure on -setrestartfreeze on

# List valid startup disks
systemsetup -liststartupdisks

# Specify a new startup disk
systemsetup -setstartupdisk {{path}}

# Start top, all options are available in the interface
top

# Start top sorting processes by internal memory size (default order - process ID)
top -o mem

# Start top sorting processes first by CPU, then by running time
top -o cpu -O time

# Start top displaying only processes owned by given user
top -user {{user_name}}

# Get help about interactive commands
?

# List available signals to set traps for
trap -l

# List active traps for the current shell
trap -p

# Set a trap to execute commands when one or more signals are detected
trap 'echo "Caught signal {{SIGHUP}}"' {{SIGHUP}}

# Remove active traps
trap - {{SIGHUP}} {{SIGINT}}

# Show files and directories up to 'num' levels of depth (where 1 means the current directory)
tree -L {{num}}

# Show directories only
tree -d

# Show hidden files too
tree -a

# Print the tree without indentation lines, showing the full path instead (use `-N` to not escape whitespace and special characters)
tree -i -f

# Print the size of each node next to it, in human-readable format, with folders displaying their cumulative size (as in the `du` command)
tree -s -h --du

# Find files within the tree hierarchy, using a wildcard (glob) pattern, and pruning out directories that don't contain matching files
tree -P '{{*.txt}}' --prune

# Find directories within the tree hierarchy, pruning out directories that aren't ancestors of the wanted one
tree -P {{directory_name}} --matchdirs --prune

# Print hardware-related information: machine and processor
uname -mp

# Print software-related information: operating system, release number, and version
uname -srv

# Print the nodename (hostname) of the system
uname -n

# Print all available system information (hardware, software, nodename)
uname -a

# Run in interactive mode
units

# Show the conversion between two simple units
units {{quarts}} {{tablespoons}}

# Convert between units with quantities
units {{"15 pounds"}} {{kilograms}}

# Show the conversion between two compound units
units {{"meters / second"}} {{"inches / hour"}}

# Show the conversion between units with different dimensions
units {{"acres"}} {{"ft^2"}}

# Show the conversion of byte multipliers
units {{"15 megabytes"}} {{bytes}}

# Show logged-in users info
w

# Show logged-in users info without a header
w -h

# Show info about logged-in users, sorted by their idle time
w -i

# Take a picture from webcam
wacaw {{filename}}

# Record a video
wacaw --video {{filename}} -D {{duration_in_seconds}}

# Take a picture with custom resolution
wacaw -x {{width}} -y {{height}} {{filename}}

# Copy image just taken to clipboard
wacaw --to-clipboard

# List the devices available
wacaw -L

# Locate binary, source and man pages for ssh
whereis {{ssh}}

# List key:value extended attributes for a given file
xattr -l {{file}}

# Write an attribute for a given file
xattr -w {{attribute_key}} {{attribute_value}} {{file}}

# Delete an attribute from a given file
xattr -d {{com.apple.quarantine}} {{file}}

# Delete all extended attributes from a given file
xattr -c {{file}}

# Recursively delete an attribute in a given directory
xattr -rd {{attribute_key}} {{directory}}

# Build workspace
xcodebuild -workspace {{workspace_name.workspace}} -scheme {{scheme_name}} -configuration {{configuration_name}} clean build SYMROOT={{SYMROOT_path}}

# Build project
xcodebuild -target {{target_name}} -configuration {{configuration_name}} clean build SYMROOT={{SYMROOT_path}}

# Show SDKs
xcodebuild -showsdks

# Build a single project without any workspace
xctool -project {{YourProject.xcodeproj}} -scheme {{YourScheme}} build

# Build a project that is part of a workspace
xctool -workspace {{YourWorkspace.xcworkspace}} -scheme {{YourScheme}} build

# Clean, build and execute all the tests
xctool -workspace {{YourWorkspace.xcworkspace}} -scheme {{YourScheme}} clean build test

# Open file in XCode
xed {{file1}}

# Open file(s) in XCode, create if it doesn't exist
xed -c {{filename1}}

# Open a file in XCode and jump to line number 75
xed -l 75 {{filename}}

# Transform an XML file with a specific XSLT stylesheet
xsltproc --output {{output.html}} {{stylesheet.xslt}} {{xmlfile.xml}}

# Pass a value to a parameter in the stylesheet
xsltproc --output {{output.html}} --stringparam {{name}} {{value}} {{stylesheet.xslt}} {{xmlfile.xml}}

# Yank using the default delimiters (\f, \n, \r, \s, \t)
{{sudo dmesg}} | yank

# Yank an entire line
{{sudo dmesg}} | yank -l

# Yank using a specific delimiter
{{echo hello=world}} | yank -d {{=}}

# Only yank fields matching a specific pattern
{{ps ux}} | yank -g {{"[0-9]+"}}

